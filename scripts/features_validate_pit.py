#!/usr/bin/env python
"""
Features MV PIT åŒ–éªŒæ”¶è„šæœ¬

éªŒæ”¶æ ‡å‡†ï¼ˆè§ docs/architecture/features_module_design.md Section 6.2.2ï¼‰ï¼š

D-1: PIT çª—å£æ­£ç¡®æ€§ + æ•°æ®å¥‘çº¦
    - query_start_date = f_ann_date (æˆ– ann_date)
    - query_end_date >= query_start_date
    - report_period = end_dateï¼ˆè´¢æŠ¥ç±»ï¼‰
    - åŒä¸€ ts_code ä¸‹ PIT çª—å£ä¸å…è®¸"æœªæ¥ä¿¡æ¯æ³„æ¼"

D-2: ä¸æ—¢æœ‰ PIT äº§å‡ºå¯¹æ¯”ï¼ˆå¯é‡åŒ–ï¼‰
    - æŠ½æ ·å¯¹æ¯” pgs_factors.pit_income_quarterly / pit_balance_quarterly
    - å…³é”®å­—æ®µä¸€è‡´æ€§æ£€æŸ¥

D-3: å¯è¿ç»´æ€§ä¸å¹‚ç­‰æ€§
    - features_init.py å¯åˆå§‹åŒ–/åˆ·æ–°
    - è¿ç»­æ‰§è¡Œ 2 æ¬¡æ— å‰¯ä½œç”¨
    - è¡€ç¼˜å­—æ®µå®Œå¤‡

ä½¿ç”¨æ–¹æ³•:
    python scripts/features_validate_pit.py --check-d1     # ä»…éªŒè¯ D-1
    python scripts/features_validate_pit.py --check-d2     # ä»…éªŒè¯ D-2
    python scripts/features_validate_pit.py --check-d3     # ä»…éªŒè¯ D-3
    python scripts/features_validate_pit.py --all          # å…¨éƒ¨éªŒæ”¶
"""

import argparse
import asyncio
import logging
import sys
from pathlib import Path
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

from alphahome.common.db_manager import DBManager
from alphahome.common.config_manager import get_database_url

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# ==============================================================================
# PIT MV åˆ—è¡¨
# ==============================================================================

PIT_MVS = [
    {
        "name": "mv_stock_income_quarterly",
        "schema": "features",
        "pit_comparison_table": "pgs_factors.pit_income_quarterly",
        "key_fields": ["ts_code", "end_date", "ann_date", "data_source"],
        "compare_fields": ["n_income", "revenue", "total_profit"],
        "coverage_range": (0.8, 1.2),  # å¯¹æ ‡ååº”æ¥è¿‘ 100%
    },
    {
        "name": "mv_stock_balance_quarterly",
        "schema": "features",
        "pit_comparison_table": "pgs_factors.pit_balance_quarterly",
        "key_fields": ["ts_code", "end_date", "ann_date", "data_source"],
        "compare_fields": ["tot_assets", "tot_liab"],
        "coverage_range": (0.8, 1.2),  # å¯¹æ ‡ååº”æ¥è¿‘ 100%
    },
    {
        "name": "mv_stock_fina_indicator",
        "schema": "features",
        "pit_comparison_table": None,  # æ— ç›´æ¥å¯¹åº”çš„ PIT è¡¨
        "key_fields": ["ts_code", "end_date", "ann_date"],
        "compare_fields": ["roe", "roa", "eps"],
    },
    {
        "name": "mv_stock_industry_monthly_snapshot",
        "schema": "features",
        "pit_comparison_table": "pgs_factors.pit_industry_classification",
        "key_fields": ["ts_code", "obs_date", "data_source"],
        "compare_fields": ["industry_level1", "industry_level2"],
        "coverage_range": (0.95, 1.25),  # MV å¯èƒ½å› æ›´æ–°æ•°æ®è€Œç•¥å¤š
        "d1_mode": "monthly_snapshot",
    },
]


# ==============================================================================
# D-1 éªŒè¯ï¼šPIT çª—å£æ­£ç¡®æ€§ + æ•°æ®å¥‘çº¦
# ==============================================================================

async def check_d1(db_manager: DBManager) -> Dict[str, Any]:
    """
    D-1 éªŒè¯ï¼šæ•°æ®å¥‘çº¦ï¼ˆåŒºåˆ† PIT çª—å£ / æœˆåº¦å¿«ç…§ï¼‰

    æ£€æŸ¥é¡¹ï¼š
    1. query_start_date å­—æ®µå­˜åœ¨ä¸”éç©º
    2. query_end_date >= query_start_date
    3. æ— æœªæ¥ä¿¡æ¯æ³„æ¼ï¼ˆquery_end_date ç”±ä¸‹ä¸€å…¬å‘Šæ—¥æ¨å¯¼ï¼‰
    4. è¡€ç¼˜å­—æ®µå­˜åœ¨
    """
    results = {"passed": [], "failed": [], "skipped": []}

    for mv_config in PIT_MVS:
        mv_name = mv_config["name"]
        schema = mv_config["schema"]
        full_name = f"{schema}.{mv_name}"

        try:
            # æ£€æŸ¥ MV æ˜¯å¦å­˜åœ¨
            exists_sql = f"""
            SELECT EXISTS (
                SELECT 1 FROM pg_matviews
                WHERE schemaname = '{schema}' AND matviewname = '{mv_name}'
            ) AS exists;
            """
            result = await db_manager.fetch(exists_sql)
            if not result or not result[0]["exists"]:
                results["skipped"].append({
                    "mv": mv_name,
                    "reason": "MV ä¸å­˜åœ¨"
                })
                continue

            d1_mode = mv_config.get("d1_mode", "pit_window")

            # æœˆåº¦å¿«ç…§æ¨¡å¼ï¼šæ£€æŸ¥ obs_date / data_source å¥‘çº¦
            if d1_mode == "monthly_snapshot":
                columns_sql = f"""
                SELECT a.attname as column_name
                FROM pg_attribute a
                JOIN pg_class c ON a.attrelid = c.oid
                JOIN pg_namespace n ON c.relnamespace = n.oid
                WHERE n.nspname = '{schema}'
                  AND c.relname = '{mv_name}'
                  AND a.attnum > 0
                  AND NOT a.attisdropped
                  AND a.attname IN ('ts_code', 'obs_date', 'data_source')
                ORDER BY a.attname;
                """
                cols = await db_manager.fetch(columns_sql)
                col_names = {c["column_name"] for c in cols}
                required = {"ts_code", "obs_date", "data_source"}
                missing = sorted(required - col_names)
                if missing:
                    results["failed"].append({
                        "mv": mv_name,
                        "error": f"ç¼ºå°‘å¿«ç…§å­—æ®µ: {missing}",
                    })
                    continue

                null_sql = f"""
                SELECT
                    COUNT(*) FILTER (WHERE ts_code IS NULL) AS null_ts,
                    COUNT(*) FILTER (WHERE obs_date IS NULL) AS null_obs,
                    COUNT(*) FILTER (WHERE data_source IS NULL) AS null_src
                FROM {full_name};
                """
                nulls = await db_manager.fetch(null_sql)
                n = nulls[0]
                if n["null_ts"] or n["null_obs"] or n["null_src"]:
                    results["failed"].append({
                        "mv": mv_name,
                        "error": f"å‘ç°ç©ºå€¼ ts_code={n['null_ts']}, obs_date={n['null_obs']}, data_source={n['null_src']}",
                    })
                    continue

                results["passed"].append({
                    "mv": mv_name,
                    "check": "D-1 monthly_snapshot schema",
                })
                continue

            # PIT çª—å£æ¨¡å¼ï¼šæ£€æŸ¥ query_start_date / query_end_date å­˜åœ¨ä¸”ç±»å‹æ­£ç¡®
            # æ³¨æ„: information_schema ä¸æ”¯æŒ materialized viewï¼Œéœ€ç”¨ pg_catalog
            columns_sql = f"""
            SELECT a.attname as column_name
            FROM pg_catalog.pg_attribute a
            JOIN pg_catalog.pg_class c ON a.attrelid = c.oid
            JOIN pg_catalog.pg_namespace n ON c.relnamespace = n.oid
            WHERE n.nspname = '{schema}'
              AND c.relname = '{mv_name}'
              AND a.attnum > 0
              AND NOT a.attisdropped
              AND a.attname IN ('query_start_date', 'query_end_date', 'report_period',
                                '_source_table', '_processed_at', '_data_version');
            """
            columns = await db_manager.fetch(columns_sql)
            column_names = [c["column_name"] for c in columns]

            required_pit_fields = ["query_start_date", "query_end_date"]
            missing_pit = [f for f in required_pit_fields if f not in column_names]
            if missing_pit:
                results["failed"].append({
                    "mv": mv_name,
                    "check": "PIT å­—æ®µå­˜åœ¨æ€§",
                    "error": f"ç¼ºå°‘å­—æ®µ: {missing_pit}"
                })
                continue

            # æ£€æŸ¥ 2: query_end_date >= query_start_date
            window_check_sql = f"""
            SELECT COUNT(*) AS violation_count
            FROM {full_name}
            WHERE query_end_date < query_start_date;
            """
            window_result = await db_manager.fetch(window_check_sql)
            violations = window_result[0]["violation_count"] if window_result else 0
            if violations > 0:
                results["failed"].append({
                    "mv": mv_name,
                    "check": "PIT çª—å£æœ‰æ•ˆæ€§",
                    "error": f"å‘ç° {violations} æ¡ query_end_date < query_start_date"
                })
                continue

            # æ£€æŸ¥ 3: è¡€ç¼˜å­—æ®µ
            lineage_fields = ["_source_table", "_processed_at", "_data_version"]
            missing_lineage = [f for f in lineage_fields if f not in column_names]
            if missing_lineage:
                results["failed"].append({
                    "mv": mv_name,
                    "check": "è¡€ç¼˜å­—æ®µå®Œå¤‡æ€§",
                    "error": f"ç¼ºå°‘å­—æ®µ: {missing_lineage}"
                })
                continue

            # æ£€æŸ¥ 4: ç©ºå€¼ç‡
            null_check_sql = f"""
            SELECT
                COUNT(*) AS total,
                COUNT(*) FILTER (WHERE query_start_date IS NULL) AS null_start,
                COUNT(*) FILTER (WHERE query_end_date IS NULL) AS null_end
            FROM {full_name};
            """
            null_result = await db_manager.fetch(null_check_sql)
            if null_result:
                total = null_result[0]["total"]
                null_start = null_result[0]["null_start"]
                null_end = null_result[0]["null_end"]
                if total > 0:
                    null_rate = (null_start + null_end) / (total * 2)
                    if null_rate > 0.01:
                        results["failed"].append({
                            "mv": mv_name,
                            "check": "PIT å­—æ®µç©ºå€¼ç‡",
                            "error": f"ç©ºå€¼ç‡ {null_rate:.2%} è¶…è¿‡é˜ˆå€¼ 1%"
                        })
                        continue

            # å…¨éƒ¨æ£€æŸ¥é€šè¿‡
            results["passed"].append({
                "mv": mv_name,
                "row_count": total if null_result else 0,
                "checks": ["PIT å­—æ®µå­˜åœ¨", "çª—å£æœ‰æ•ˆ", "è¡€ç¼˜å®Œå¤‡", "ç©ºå€¼ç‡è¾¾æ ‡"]
            })

        except Exception as e:
            results["failed"].append({
                "mv": mv_name,
                "check": "æ‰§è¡Œå¼‚å¸¸",
                "error": str(e)
            })

    return results


# ==============================================================================
# D-2 éªŒè¯ï¼šä¸æ—¢æœ‰ PIT äº§å‡ºå¯¹æ¯”
# ==============================================================================

async def check_d2(db_manager: DBManager, sample_limit: int = 1000) -> Dict[str, Any]:
    """
    D-2 éªŒè¯ï¼šä¸æ—¢æœ‰ PIT äº§å‡ºå¯¹æ¯”

    å¯¹ income/balance æŠ½æ ·å¯¹æ¯” pgs_factors.pit_* è¡¨
    """
    results = {"passed": [], "failed": [], "skipped": []}

    for mv_config in PIT_MVS:
        mv_name = mv_config["name"]
        schema = mv_config["schema"]
        full_name = f"{schema}.{mv_name}"
        comparison_table = mv_config.get("pit_comparison_table")

        if not comparison_table:
            results["skipped"].append({
                "mv": mv_name,
                "reason": "æ— å¯¹åº”çš„ PIT å¯¹æ¯”è¡¨"
            })
            continue

        try:
            # æ£€æŸ¥ MV æ˜¯å¦å­˜åœ¨
            exists_sql = f"""
            SELECT EXISTS (
                SELECT 1 FROM pg_matviews
                WHERE schemaname = '{schema}' AND matviewname = '{mv_name}'
            ) AS exists;
            """
            result = await db_manager.fetch(exists_sql)
            if not result or not result[0]["exists"]:
                results["skipped"].append({
                    "mv": mv_name,
                    "reason": "MV ä¸å­˜åœ¨"
                })
                continue

            # æ£€æŸ¥å¯¹æ¯”è¡¨æ˜¯å¦å­˜åœ¨
            comparison_schema, comparison_name = comparison_table.split(".")
            comp_exists_sql = f"""
            SELECT EXISTS (
                SELECT 1 FROM information_schema.tables
                WHERE table_schema = '{comparison_schema}' AND table_name = '{comparison_name}'
            ) AS exists;
            """
            comp_result = await db_manager.fetch(comp_exists_sql)
            if not comp_result or not comp_result[0]["exists"]:
                results["skipped"].append({
                    "mv": mv_name,
                    "reason": f"å¯¹æ¯”è¡¨ {comparison_table} ä¸å­˜åœ¨"
                })
                continue

            # å¯¹æ¯”è¡Œæ•°
            mv_count_sql = f"SELECT COUNT(*) AS cnt FROM {full_name};"
            pit_count_sql = f"SELECT COUNT(*) AS cnt FROM {comparison_table};"

            mv_count = (await db_manager.fetch(mv_count_sql))[0]["cnt"]
            pit_count = (await db_manager.fetch(pit_count_sql))[0]["cnt"]

            # è®¡ç®—è¦†ç›–ç‡ï¼ˆä½¿ç”¨é…ç½®çš„èŒƒå›´ï¼Œé»˜è®¤ 80%-150%ï¼‰
            coverage_range = mv_config.get("coverage_range", (0.8, 1.5))
            if pit_count > 0:
                coverage = mv_count / pit_count
                coverage_ok = coverage_range[0] <= coverage <= coverage_range[1]
            else:
                coverage = 0
                coverage_ok = mv_count == 0

            if not coverage_ok:
                results["failed"].append({
                    "mv": mv_name,
                    "check": "è¡Œæ•°è¦†ç›–ç‡",
                    "mv_count": mv_count,
                    "pit_count": pit_count,
                    "coverage": f"{coverage:.2%}",
                    "error": f"è¦†ç›–ç‡ {coverage:.2%} è¶…å‡º {coverage_range[0]*100:.0f}%-{coverage_range[1]*100:.0f}% èŒƒå›´"
                })
                continue

            results["passed"].append({
                "mv": mv_name,
                "comparison_table": comparison_table,
                "mv_count": mv_count,
                "pit_count": pit_count,
                "coverage": f"{coverage:.2%}",
                "status": "è¡Œæ•°è¦†ç›–ç‡è¾¾æ ‡"
            })

        except Exception as e:
            results["failed"].append({
                "mv": mv_name,
                "check": "æ‰§è¡Œå¼‚å¸¸",
                "error": str(e)
            })

    return results


# ==============================================================================
# D-3 éªŒè¯ï¼šå¯è¿ç»´æ€§ä¸å¹‚ç­‰æ€§
# ==============================================================================

async def check_d3(db_manager: DBManager) -> Dict[str, Any]:
    """
    D-3 éªŒè¯ï¼šå¯è¿ç»´æ€§ä¸å¹‚ç­‰æ€§

    æ£€æŸ¥é¡¹ï¼š
    1. features schema å·²åˆå§‹åŒ–
    2. MV å…ƒæ•°æ®è¡¨å­˜åœ¨
    3. è¡€ç¼˜å­—æ®µå®Œå¤‡ï¼ˆå·²åœ¨ D-1 æ£€æŸ¥ï¼‰
    """
    results = {"passed": [], "failed": [], "info": {}}

    try:
        # æ£€æŸ¥ features schema
        schema_sql = """
        SELECT EXISTS (
            SELECT 1 FROM information_schema.schemata
            WHERE schema_name = 'features'
        ) AS exists;
        """
        schema_result = await db_manager.fetch(schema_sql)
        schema_exists = schema_result and schema_result[0]["exists"]

        if not schema_exists:
            results["failed"].append({
                "check": "features schema",
                "error": "schema ä¸å­˜åœ¨"
            })
            return results

        results["passed"].append({"check": "features schema", "status": "å­˜åœ¨"})

        # æ£€æŸ¥å…ƒæ•°æ®è¡¨
        for table_name in ["mv_metadata", "mv_refresh_log"]:
            table_sql = f"""
            SELECT EXISTS (
                SELECT 1 FROM information_schema.tables
                WHERE table_schema = 'features' AND table_name = '{table_name}'
            ) AS exists;
            """
            table_result = await db_manager.fetch(table_sql)
            table_exists = table_result and table_result[0]["exists"]

            if table_exists:
                results["passed"].append({"check": f"å…ƒæ•°æ®è¡¨ {table_name}", "status": "å­˜åœ¨"})
            else:
                results["failed"].append({
                    "check": f"å…ƒæ•°æ®è¡¨ {table_name}",
                    "error": "è¡¨ä¸å­˜åœ¨"
                })

        # ç»Ÿè®¡å·²åˆ›å»ºçš„ MV
        mv_list_sql = """
        SELECT matviewname AS name
        FROM pg_matviews
        WHERE schemaname = 'features'
        ORDER BY matviewname;
        """
        mv_result = await db_manager.fetch(mv_list_sql)
        mvs = [row["name"] for row in mv_result] if mv_result else []
        results["info"]["materialized_views"] = mvs
        results["info"]["mv_count"] = len(mvs)

        # æ£€æŸ¥ PIT ç›¸å…³ MV æ˜¯å¦å…¨éƒ¨åˆ›å»º
        expected_pit_mvs = [mv["name"] for mv in PIT_MVS]
        created_pit_mvs = [mv for mv in expected_pit_mvs if mv in mvs]
        missing_pit_mvs = [mv for mv in expected_pit_mvs if mv not in mvs]

        results["info"]["expected_pit_mvs"] = expected_pit_mvs
        results["info"]["created_pit_mvs"] = created_pit_mvs
        results["info"]["missing_pit_mvs"] = missing_pit_mvs

        if missing_pit_mvs:
            results["failed"].append({
                "check": "PIT MV å®Œæ•´æ€§",
                "error": f"ç¼ºå°‘ MV: {missing_pit_mvs}"
            })
        else:
            results["passed"].append({
                "check": "PIT MV å®Œæ•´æ€§",
                "status": f"å…¨éƒ¨ {len(expected_pit_mvs)} ä¸ª PIT MV å·²åˆ›å»º"
            })

    except Exception as e:
        results["failed"].append({
            "check": "æ‰§è¡Œå¼‚å¸¸",
            "error": str(e)
        })

    return results


# ==============================================================================
# æŠ¥å‘Šè¾“å‡º
# ==============================================================================

def print_results(title: str, results: Dict[str, Any]):
    """æ‰“å°éªŒè¯ç»“æœ"""
    print(f"\n{'=' * 60}")
    print(f"  {title}")
    print(f"{'=' * 60}")

    if results.get("passed"):
        print(f"\nâœ… é€šè¿‡ ({len(results['passed'])} é¡¹):")
        for item in results["passed"]:
            if isinstance(item, dict):
                mv = item.get("mv", item.get("check", ""))
                status = item.get("status", item.get("checks", ""))
                extra = ""
                if "row_count" in item:
                    extra = f" (è¡Œæ•°: {item['row_count']:,})"
                if "coverage" in item:
                    extra = f" (è¦†ç›–ç‡: {item['coverage']})"
                print(f"    âœ“ {mv}: {status}{extra}")
            else:
                print(f"    âœ“ {item}")

    if results.get("skipped"):
        print(f"\nâ­ï¸  è·³è¿‡ ({len(results['skipped'])} é¡¹):")
        for item in results["skipped"]:
            print(f"    - {item['mv']}: {item['reason']}")

    if results.get("failed"):
        print(f"\nâŒ å¤±è´¥ ({len(results['failed'])} é¡¹):")
        for item in results["failed"]:
            mv = item.get("mv", item.get("check", ""))
            error = item.get("error", "")
            print(f"    âœ— {mv}: {error}")

    if results.get("info"):
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        info = results["info"]
        if "mv_count" in info:
            print(f"    å·²åˆ›å»º MV æ•°é‡: {info['mv_count']}")
        if "materialized_views" in info:
            print(f"    MV åˆ—è¡¨: {', '.join(info['materialized_views'])}")
        if "missing_pit_mvs" in info and info["missing_pit_mvs"]:
            print(f"    ç¼ºå°‘çš„ PIT MV: {', '.join(info['missing_pit_mvs'])}")


# ==============================================================================
# ä¸»å‡½æ•°
# ==============================================================================

async def main(args: argparse.Namespace) -> int:
    """ä¸»å‡½æ•°"""
    try:
        db_url = get_database_url()
        db_manager = DBManager(db_url)
        await db_manager.connect()

        all_passed = True

        if args.check_d1 or args.all:
            results = await check_d1(db_manager)
            print_results("D-1: PIT çª—å£æ­£ç¡®æ€§ + æ•°æ®å¥‘çº¦", results)
            if results.get("failed"):
                all_passed = False

        if args.check_d2 or args.all:
            results = await check_d2(db_manager)
            print_results("D-2: ä¸æ—¢æœ‰ PIT äº§å‡ºå¯¹æ¯”", results)
            if results.get("failed"):
                all_passed = False

        if args.check_d3 or args.all:
            results = await check_d3(db_manager)
            print_results("D-3: å¯è¿ç»´æ€§ä¸å¹‚ç­‰æ€§", results)
            if results.get("failed"):
                all_passed = False

        await db_manager.close()

        print(f"\n{'=' * 60}")
        if all_passed:
            print("ğŸ‰ æ‰€æœ‰éªŒæ”¶æ£€æŸ¥é€šè¿‡!")
        else:
            print("âš ï¸  éƒ¨åˆ†éªŒæ”¶æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·æŸ¥çœ‹ä¸Šè¿°è¯¦æƒ…")
        print(f"{'=' * 60}\n")

        return 0 if all_passed else 1

    except Exception as e:
        logger.error(f"éªŒæ”¶è„šæœ¬æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="Features MV PIT åŒ–éªŒæ”¶è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )

    parser.add_argument(
        "--check-d1",
        action="store_true",
        help="éªŒè¯ D-1: PIT çª—å£æ­£ç¡®æ€§ + æ•°æ®å¥‘çº¦"
    )
    parser.add_argument(
        "--check-d2",
        action="store_true",
        help="éªŒè¯ D-2: ä¸æ—¢æœ‰ PIT äº§å‡ºå¯¹æ¯”"
    )
    parser.add_argument(
        "--check-d3",
        action="store_true",
        help="éªŒè¯ D-3: å¯è¿ç»´æ€§ä¸å¹‚ç­‰æ€§"
    )
    parser.add_argument(
        "--all",
        action="store_true",
        help="æ‰§è¡Œå…¨éƒ¨éªŒæ”¶æ£€æŸ¥"
    )

    args = parser.parse_args()

    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•æ£€æŸ¥ï¼Œé»˜è®¤æ‰§è¡Œå…¨éƒ¨
    if not (args.check_d1 or args.check_d2 or args.check_d3 or args.all):
        args.all = True

    return args


if __name__ == "__main__":
    args = parse_args()
    exit_code = asyncio.run(main(args))
    sys.exit(exit_code)
