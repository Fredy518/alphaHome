#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¿®å¤Gå› å­æ’åå’Œè¯„åˆ†è„šæœ¬
æ ¹æ®æ•°æ®åº“ä¸­å·²è®¡ç®—çš„å­å› å­ç»“æœï¼Œé‡æ–°è®¡ç®—rankå’Œg_score

ä½¿ç”¨æ–¹æ³•ï¼š
python scripts/maintenance/fix_g_factor_rankings_and_scores.py --start_date 2020-01-01 --end_date 2024-12-31
"""

import sys
import os
import argparse
import time
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
from typing import List, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from research.tools.context import ResearchContext
from research.pgs_factor.processors.production_g_factor_calculator import ProductionGFactorCalculator


class GFactorRankingFixer:
    """Gå› å­æ’åå’Œè¯„åˆ†ä¿®å¤å™¨"""
    
    def __init__(self, context: ResearchContext):
        self.context = context
        self.calculator = ProductionGFactorCalculator(context)
        self.logger = self.calculator.logger
        
        # å­å› å­æƒé‡é…ç½®
        self.subfactor_weights = {
            'efficiency_surprise': 0.25,
            'efficiency_momentum': 0.25,
            'revenue_momentum': 0.25,
            'profit_momentum': 0.25
        }
    
    def calculate_dynamic_rankings_and_scores(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—åŠ¨æ€æ’åå’Œè¯„åˆ†
        
        Args:
            df: åŒ…å«å­å› å­çš„DataFrame
            
        Returns:
            åŒ…å«æ’åå’Œè¯„åˆ†çš„DataFrame
        """
        # 1. è®¡ç®—æ’åï¼ˆåªå¯¹æœ‰æ•ˆå€¼è¿›è¡Œæ’åï¼‰
        df['rank_es'] = df['g_efficiency_surprise'].rank(pct=True, na_option='keep') * 100
        df['rank_em'] = df['g_efficiency_momentum'].rank(pct=True, na_option='keep') * 100
        df['rank_rm'] = df['g_revenue_momentum'].rank(pct=True, na_option='keep') * 100
        df['rank_pm'] = df['g_profit_momentum'].rank(pct=True, na_option='keep') * 100
        
        # 2. è®¡ç®—åŠ¨æ€æƒé‡Gè¯„åˆ†
        # æ£€æŸ¥å„å­å› å­æ˜¯å¦æœ‰æœ‰æ•ˆå€¼ï¼ˆéç©ºå€¼ï¼‰
        has_es = df['g_efficiency_surprise'].notna()
        has_em = df['g_efficiency_momentum'].notna()
        has_rm = df['g_revenue_momentum'].notna()
        has_pm = df['g_profit_momentum'].notna()
        
        # è®¡ç®—åŠ¨æ€æƒé‡
        w_es = self.subfactor_weights['efficiency_surprise']
        w_em = self.subfactor_weights['efficiency_momentum']
        w_rm = self.subfactor_weights['revenue_momentum']
        w_pm = self.subfactor_weights['profit_momentum']
        
        # åˆå§‹åŒ–ç»“æœSeries
        g_score = pd.Series(index=df.index, dtype=float)
        
        # é€è¡Œè®¡ç®—Gè¯„åˆ†ï¼Œç¡®ä¿æ­£ç¡®å¤„ç†ç©ºå€¼
        for idx in df.index:
            # è·å–è¯¥è¡Œçš„æœ‰æ•ˆå› å­ä¿¡æ¯
            row_has_es = has_es.loc[idx]
            row_has_em = has_em.loc[idx]
            row_has_rm = has_rm.loc[idx]
            row_has_pm = has_pm.loc[idx]
            
            # è®¡ç®—æœ‰æ•ˆå› å­çš„æƒé‡å’Œ
            total_weight = (
                w_es * row_has_es +
                w_em * row_has_em +
                w_rm * row_has_rm +
                w_pm * row_has_pm
            )
            
            # å¦‚æœæ²¡æœ‰ä»»ä½•æœ‰æ•ˆå› å­ï¼ŒGè¯„åˆ†ä¸º0
            if total_weight == 0:
                g_score.loc[idx] = 0.0
                continue
            
            # è®¡ç®—åŠ æƒæ’åå’Œ
            weighted_sum = 0.0
            if row_has_es and pd.notna(df.loc[idx, 'rank_es']):
                weighted_sum += df.loc[idx, 'rank_es'] * w_es
            if row_has_em and pd.notna(df.loc[idx, 'rank_em']):
                weighted_sum += df.loc[idx, 'rank_em'] * w_em
            if row_has_rm and pd.notna(df.loc[idx, 'rank_rm']):
                weighted_sum += df.loc[idx, 'rank_rm'] * w_rm
            if row_has_pm and pd.notna(df.loc[idx, 'rank_pm']):
                weighted_sum += df.loc[idx, 'rank_pm'] * w_pm
            
            # è®¡ç®—æœ€ç»ˆGè¯„åˆ†
            g_score.loc[idx] = weighted_sum / total_weight
        
        df['g_score'] = g_score
        
        return df
    
    def get_g_factor_data_by_date(self, calc_date: str) -> pd.DataFrame:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„Gå› å­æ•°æ®
        
        Args:
            calc_date: è®¡ç®—æ—¥æœŸ
            
        Returns:
            Gå› å­æ•°æ®DataFrame
        """
        query = """
        SELECT 
            ts_code,
            calc_date,
            g_efficiency_surprise,
            g_efficiency_momentum,
            g_revenue_momentum,
            g_profit_momentum,
            rank_es,
            rank_em,
            rank_rm,
            rank_pm,
            g_score
        FROM pgs_factors.g_factor 
        WHERE calc_date = %s
        AND (g_efficiency_surprise IS NOT NULL 
             OR g_efficiency_momentum IS NOT NULL 
             OR g_revenue_momentum IS NOT NULL 
             OR g_profit_momentum IS NOT NULL)
        ORDER BY ts_code
        """
        
        try:
            results = self.context.db_manager.fetch_sync(query, (calc_date,))
            
            if not results:
                self.logger.warning(f"æœªæ‰¾åˆ°Gå› å­æ•°æ®: {calc_date}")
                return pd.DataFrame()
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(results)
            
            self.logger.info(f"è·å–åˆ° {len(df)} æ¡Gå› å­æ•°æ®: {calc_date}")
            return df
            
        except Exception as e:
            self.logger.error(f"è·å–Gå› å­æ•°æ®å¤±è´¥ {calc_date}: {e}")
            return pd.DataFrame()
    
    def update_g_factor_rankings_and_scores(self, df: pd.DataFrame, calc_date: str) -> int:
        """
        æ›´æ–°Gå› å­æ’åå’Œè¯„åˆ†
        
        Args:
            df: åŒ…å«æ–°æ’åå’Œè¯„åˆ†çš„DataFrame
            calc_date: è®¡ç®—æ—¥æœŸ
            
        Returns:
            æˆåŠŸæ›´æ–°çš„è®°å½•æ•°
        """
        if df.empty:
            return 0
        
        try:
            # å‡†å¤‡æ›´æ–°æ•°æ®
            update_data = []
            for _, row in df.iterrows():
                update_data.append((
                    row['rank_es'],
                    row['rank_em'],
                    row['rank_rm'],
                    row['rank_pm'],
                    row['g_score'],
                    row['ts_code'],
                    calc_date
                ))
            
            # æ‰¹é‡æ›´æ–°
            update_query = """
            UPDATE pgs_factors.g_factor 
            SET 
                rank_es = %s,
                rank_em = %s,
                rank_rm = %s,
                rank_pm = %s,
                g_score = %s,
                updated_at = CURRENT_TIMESTAMP
            WHERE ts_code = %s AND calc_date = %s
            """
            
            success_count = 0
            for data_tuple in update_data:
                try:
                    self.context.db_manager.execute_sync(update_query, data_tuple)
                    success_count += 1
                except Exception as e:
                    self.logger.warning(f"æ›´æ–°å¤±è´¥ {data_tuple[5]} {calc_date}: {e}")
            
            self.logger.info(f"æˆåŠŸæ›´æ–° {success_count}/{len(update_data)} æ¡è®°å½•: {calc_date}")
            return success_count
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°Gå› å­æ’åå’Œè¯„åˆ†å¤±è´¥ {calc_date}: {e}")
            return 0
    
    def fix_rankings_and_scores_for_date(self, calc_date: str) -> dict:
        """
        ä¿®å¤æŒ‡å®šæ—¥æœŸçš„æ’åå’Œè¯„åˆ†
        
        Args:
            calc_date: è®¡ç®—æ—¥æœŸ
            
        Returns:
            ä¿®å¤ç»“æœç»Ÿè®¡
        """
        start_time = time.time()
        
        # 1. è·å–æ•°æ®
        df = self.get_g_factor_data_by_date(calc_date)
        if df.empty:
            return {
                'calc_date': calc_date,
                'total_records': 0,
                'updated_records': 0,
                'processing_time': 0,
                'status': 'no_data'
            }
        
        # 2. è®¡ç®—æ–°çš„æ’åå’Œè¯„åˆ†
        df_fixed = self.calculate_dynamic_rankings_and_scores(df.copy())
        
        # 3. æ›´æ–°æ•°æ®åº“
        updated_count = self.update_g_factor_rankings_and_scores(df_fixed, calc_date)
        
        processing_time = time.time() - start_time
        
        return {
            'calc_date': calc_date,
            'total_records': len(df),
            'updated_records': updated_count,
            'processing_time': processing_time,
            'status': 'success' if updated_count > 0 else 'failed'
        }
    
    def fix_rankings_and_scores_batch(self, start_date: str, end_date: str) -> dict:
        """
        æ‰¹é‡ä¿®å¤æ’åå’Œè¯„åˆ†
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            æ‰¹é‡ä¿®å¤ç»“æœç»Ÿè®¡
        """
        self.logger.info(f"å¼€å§‹æ‰¹é‡ä¿®å¤Gå› å­æ’åå’Œè¯„åˆ†: {start_date} ~ {end_date}")
        
        # è·å–éœ€è¦ä¿®å¤çš„æ—¥æœŸåˆ—è¡¨
        date_query = """
        SELECT DISTINCT calc_date 
        FROM pgs_factors.g_factor 
        WHERE calc_date >= %s AND calc_date <= %s
        AND (g_efficiency_surprise IS NOT NULL 
             OR g_efficiency_momentum IS NOT NULL 
             OR g_revenue_momentum IS NOT NULL 
             OR g_profit_momentum IS NOT NULL)
        ORDER BY calc_date
        """
        
        try:
            date_results = self.context.db_manager.fetch_sync(date_query, (start_date, end_date))
            
            # è°ƒè¯•ä¿¡æ¯
            self.logger.info(f"æ•°æ®åº“æŸ¥è¯¢ç»“æœç±»å‹: {type(date_results)}")
            self.logger.info(f"æ•°æ®åº“æŸ¥è¯¢ç»“æœ: {date_results}")
            
            if not date_results:
                self.logger.warning(f"åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æœªæ‰¾åˆ°Gå› å­æ•°æ®: {start_date} ~ {end_date}")
                return {
                    'status': 'no_data',
                    'total_dates': 0,
                    'total_records': 0,
                    'total_updated': 0,
                    'total_time': 0,
                    'results': []
                }
            
            # å¤„ç†æŸ¥è¯¢ç»“æœ
            if isinstance(date_results, list):
                if len(date_results) > 0 and isinstance(date_results[0], (list, tuple)):
                    # ç»“æœæ ¼å¼: [(date1,), (date2,), ...]
                    calc_dates = [row[0] for row in date_results]
                elif len(date_results) > 0 and isinstance(date_results[0], dict):
                    # ç»“æœæ ¼å¼: [{'calc_date': date1}, {'calc_date': date2}, ...]
                    calc_dates = [row['calc_date'] for row in date_results]
                else:
                    # ç»“æœæ ¼å¼: [date1, date2, ...]
                    calc_dates = date_results
            else:
                self.logger.error(f"æ„å¤–çš„æŸ¥è¯¢ç»“æœæ ¼å¼: {type(date_results)}")
                return {'status': 'failed', 'error': f'æ„å¤–çš„æŸ¥è¯¢ç»“æœæ ¼å¼: {type(date_results)}'}
            
            self.logger.info(f"æ‰¾åˆ° {len(calc_dates)} ä¸ªéœ€è¦ä¿®å¤çš„è®¡ç®—æ—¥æœŸ")
            if len(calc_dates) > 0:
                self.logger.info(f"æ—¥æœŸèŒƒå›´: {min(calc_dates)} ~ {max(calc_dates)}")
            
        except Exception as e:
            self.logger.error(f"è·å–è®¡ç®—æ—¥æœŸå¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}
        
        # æ‰¹é‡å¤„ç†
        results = []
        total_records = 0
        total_updated = 0
        total_time = 0
        
        for i, calc_date in enumerate(calc_dates, 1):
            self.logger.info(f"å¤„ç†è¿›åº¦: {i}/{len(calc_dates)} - {calc_date}")
            
            result = self.fix_rankings_and_scores_for_date(calc_date)
            results.append(result)
            
            total_records += result['total_records']
            total_updated += result['updated_records']
            total_time += result['processing_time']
            
            # æ¯å¤„ç†10ä¸ªæ—¥æœŸè¾“å‡ºä¸€æ¬¡è¿›åº¦
            if i % 10 == 0:
                self.logger.info(f"å·²å¤„ç† {i}/{len(calc_dates)} ä¸ªæ—¥æœŸï¼Œæ›´æ–° {total_updated} æ¡è®°å½•")
        
        return {
            'status': 'completed',
            'total_dates': len(calc_dates),
            'total_records': total_records,
            'total_updated': total_updated,
            'total_time': total_time,
            'results': results
        }


def main():
    parser = argparse.ArgumentParser(description='ä¿®å¤Gå› å­æ’åå’Œè¯„åˆ†')
    parser.add_argument('--start_date', type=str, required=True, help='å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--end_date', type=str, required=True, help='ç»“æŸæ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--single_date', type=str, help='å•æ—¥ä¿®å¤ (YYYY-MM-DD)')
    parser.add_argument('--dry_run', action='store_true', help='è¯•è¿è¡Œæ¨¡å¼ï¼Œä¸å®é™…æ›´æ–°æ•°æ®åº“')
    
    args = parser.parse_args()
    
    # éªŒè¯å‚æ•°
    if args.single_date:
        if args.start_date or args.end_date:
            print("âŒ å•æ—¥ä¿®å¤æ¨¡å¼ä¸èƒ½åŒæ—¶æŒ‡å®šæ—¥æœŸèŒƒå›´")
            sys.exit(1)
    else:
        if not args.start_date or not args.end_date:
            print("âŒ æ‰¹é‡ä¿®å¤æ¨¡å¼å¿…é¡»æŒ‡å®šå¼€å§‹å’Œç»“æŸæ—¥æœŸ")
            sys.exit(1)
    
    print("ğŸ”§ Gå› å­æ’åå’Œè¯„åˆ†ä¿®å¤å·¥å…·")
    print("=" * 50)
    print(f"ğŸ• å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    if args.single_date:
        print(f"ğŸ“… ä¿®å¤æ¨¡å¼: å•æ—¥ä¿®å¤")
        print(f"ğŸ“… ç›®æ ‡æ—¥æœŸ: {args.single_date}")
    else:
        print(f"ğŸ“… ä¿®å¤æ¨¡å¼: æ‰¹é‡ä¿®å¤")
        print(f"ğŸ“… æ—¥æœŸèŒƒå›´: {args.start_date} ~ {args.end_date}")
    
    if args.dry_run:
        print("âš ï¸ è¯•è¿è¡Œæ¨¡å¼: ä¸ä¼šå®é™…æ›´æ–°æ•°æ®åº“")
    
    print()
    
    # åˆå§‹åŒ–ç ”ç©¶ä¸Šä¸‹æ–‡
    try:
        context = ResearchContext()
        print("âœ… ç ”ç©¶ä¸Šä¸‹æ–‡åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ç ”ç©¶ä¸Šä¸‹æ–‡åˆå§‹åŒ–å¤±è´¥: {e}")
        sys.exit(1)
    
    # åˆ›å»ºä¿®å¤å™¨
    fixer = GFactorRankingFixer(context)
    
    try:
        if args.single_date:
            # å•æ—¥ä¿®å¤
            result = fixer.fix_rankings_and_scores_for_date(args.single_date)
            
            print(f"\nğŸ‰ å•æ—¥ä¿®å¤å®Œæˆ!")
            print(f"ğŸ“… æ—¥æœŸ: {result['calc_date']}")
            print(f"ğŸ“Š æ€»è®°å½•æ•°: {result['total_records']}")
            print(f"âœ… æ›´æ–°è®°å½•æ•°: {result['updated_records']}")
            print(f"â° å¤„ç†æ—¶é—´: {result['processing_time']:.2f}ç§’")
            print(f"ğŸ“ˆ çŠ¶æ€: {result['status']}")
            
        else:
            # æ‰¹é‡ä¿®å¤
            result = fixer.fix_rankings_and_scores_batch(args.start_date, args.end_date)
            
            print(f"\nğŸ‰ æ‰¹é‡ä¿®å¤å®Œæˆ!")
            print(f"ğŸ“… å¤„ç†æ—¥æœŸæ•°: {result['total_dates']}")
            print(f"ğŸ“Š æ€»è®°å½•æ•°: {result['total_records']}")
            print(f"âœ… æ›´æ–°è®°å½•æ•°: {result['total_updated']}")
            print(f"â° æ€»å¤„ç†æ—¶é—´: {result['total_time']:.2f}ç§’")
            print(f"ğŸ“ˆ çŠ¶æ€: {result['status']}")
            
            if result['total_records'] > 0:
                success_rate = result['total_updated'] / result['total_records'] * 100
                print(f"ğŸ“Š æˆåŠŸç‡: {success_rate:.1f}%")
    
    except Exception as e:
        print(f"âŒ ä¿®å¤è¿‡ç¨‹å¤±è´¥: {e}")
        sys.exit(1)
    
    print(f"\nğŸ• å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    main()
