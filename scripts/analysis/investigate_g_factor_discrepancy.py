#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Gå› å­è®¡ç®—å·®å¼‚è°ƒæŸ¥è„šæœ¬
è°ƒæŸ¥ç”¨æˆ·æŠ¥å‘Šçš„"21ä¸ªå¤±è´¥æ—¥æœŸ"ä¸æ•°æ®åº“å®é™…ç»“æœä¸ä¸€è‡´çš„åŸå› 

ä½¿ç”¨æ–¹æ³•ï¼š
python scripts/analysis/investigate_g_factor_discrepancy.py --year 2015
"""

import sys
import os
import argparse
import pandas as pd
from datetime import datetime, timedelta
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from research.tools.context import ResearchContext


def get_friday_dates_for_year(year: int) -> list:
    """è·å–æŒ‡å®šå¹´ä»½çš„æ‰€æœ‰å‘¨äº”æ—¥æœŸ"""
    fridays = []
    start_date = datetime(year, 1, 1)
    end_date = datetime(year, 12, 31)
    
    current_date = start_date
    while current_date <= end_date:
        if current_date.weekday() == 4:  # å‘¨äº”
            fridays.append(current_date.date())
        current_date += timedelta(days=1)
    
    return fridays


def analyze_calculation_logic_discrepancy(context, year: int):
    """åˆ†æè®¡ç®—é€»è¾‘å·®å¼‚"""
    print(f"ğŸ” åˆ†æ {year} å¹´Gå› å­è®¡ç®—é€»è¾‘å·®å¼‚...")
    print("=" * 60)
    
    # 1. è·å–ç†è®ºå‘¨äº”æ•°
    expected_fridays = get_friday_dates_for_year(year)
    print(f"ğŸ“… ç†è®ºå‘¨äº”æ•°: {len(expected_fridays)}")
    
    # 2. æŸ¥è¯¢æ•°æ®åº“ä¸­çš„å®é™…æ•°æ®
    query = """
    SELECT 
        calc_date,
        COUNT(*) as total_records,
        COUNT(CASE WHEN calculation_status = 'success' THEN 1 END) as success_records,
        COUNT(CASE WHEN calculation_status = 'failed' THEN 1 END) as failed_records,
        COUNT(CASE WHEN calculation_status = 'partial' THEN 1 END) as partial_records,
        COUNT(DISTINCT ts_code) as unique_stocks
    FROM pgs_factors.g_factor 
    WHERE EXTRACT(YEAR FROM calc_date) = %s
    GROUP BY calc_date
    ORDER BY calc_date
    """
    
    try:
        results = context.db_manager.fetch_sync(query, (year,))
        
        if not results:
            print(f"âŒ æ•°æ®åº“ä¸­æœªæ‰¾åˆ° {year} å¹´çš„Gå› å­æ•°æ®")
            return
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(results, columns=[
            'calc_date', 'total_records', 'success_records', 
            'failed_records', 'partial_records', 'unique_stocks'
        ])
        
        print(f"ğŸ“Š æ•°æ®åº“ä¸­çš„è®¡ç®—æ—¥æœŸæ•°: {len(df)}")
        
        # 3. åˆ†ææ¯ä¸ªæ—¥æœŸçš„çŠ¶æ€
        print(f"\nğŸ“‹ å„æ—¥æœŸè¯¦ç»†çŠ¶æ€:")
        print("-" * 80)
        
        total_success_records = 0
        total_failed_records = 0
        dates_with_failures = 0
        dates_with_success = 0
        
        for _, row in df.iterrows():
            calc_date = row['calc_date']
            total_records = row['total_records']
            success_records = row['success_records']
            failed_records = row['failed_records']
            partial_records = row['partial_records']
            unique_stocks = row['unique_stocks']
            
            total_success_records += success_records
            total_failed_records += failed_records
            
            # åˆ¤æ–­æ—¥æœŸçŠ¶æ€
            if failed_records > 0:
                dates_with_failures += 1
                status = "âŒ æœ‰å¤±è´¥"
            elif success_records > 0:
                dates_with_success += 1
                status = "âœ… æˆåŠŸ"
            else:
                status = "âš ï¸ æ— æ•°æ®"
            
            print(f"   {calc_date}: {status} | æ€»è®°å½•:{total_records} æˆåŠŸ:{success_records} å¤±è´¥:{failed_records} éƒ¨åˆ†:{partial_records} è‚¡ç¥¨:{unique_stocks}")
        
        # 4. åˆ†æå·®å¼‚åŸå› 
        print(f"\nğŸ” å·®å¼‚åˆ†æ:")
        print("-" * 40)
        print(f"ğŸ“Š æ•°æ®åº“ç»Ÿè®¡:")
        print(f"   æ€»è®°å½•æ•°: {total_success_records + total_failed_records:,}")
        print(f"   æˆåŠŸè®°å½•æ•°: {total_success_records:,}")
        print(f"   å¤±è´¥è®°å½•æ•°: {total_failed_records:,}")
        print(f"   æœ‰å¤±è´¥çš„æ—¥æœŸæ•°: {dates_with_failures}")
        print(f"   æˆåŠŸçš„æ—¥æœŸæ•°: {dates_with_success}")
        print(f"   è®°å½•æˆåŠŸç‡: {total_success_records/(total_success_records+total_failed_records)*100:.1f}%")
        
        # 5. æ¨¡æ‹Ÿè®¡ç®—å™¨çš„ç»Ÿè®¡é€»è¾‘
        print(f"\nğŸ§® æ¨¡æ‹Ÿè®¡ç®—å™¨ç»Ÿè®¡é€»è¾‘:")
        print("-" * 40)
        
        # æŒ‰ç…§è®¡ç®—å™¨çš„é€»è¾‘ï¼šå¦‚æœæŸæ—¥æœŸæœ‰ä»»ä½•å¤±è´¥è®°å½•ï¼Œå°±ç®—å¤±è´¥æ—¥æœŸ
        simulated_failed_dates = 0
        simulated_successful_dates = 0
        
        for _, row in df.iterrows():
            total_records = row['total_records']
            success_records = row['success_records']
            failed_records = row['failed_records']
            
            if total_records == 0:
                continue  # æ— æ ·æœ¬çš„æ—¥æœŸæ—¢ä¸ç®—æˆåŠŸä¹Ÿä¸ç®—å¤±è´¥
            
            if failed_records == 0 and success_records > 0:
                simulated_successful_dates += 1
            else:
                simulated_failed_dates += 1
        
        print(f"   æ¨¡æ‹ŸæˆåŠŸæ—¥æœŸæ•°: {simulated_successful_dates}")
        print(f"   æ¨¡æ‹Ÿå¤±è´¥æ—¥æœŸæ•°: {simulated_failed_dates}")
        print(f"   æ¨¡æ‹Ÿæ—¥æœŸæˆåŠŸç‡: {simulated_successful_dates/(simulated_successful_dates+simulated_failed_dates)*100:.1f}%")
        
        # 6. åˆ†æç”¨æˆ·æŠ¥å‘Šçš„æ•°æ®
        print(f"\nğŸ“ ç”¨æˆ·æŠ¥å‘Šæ•°æ®åˆ†æ:")
        print("-" * 40)
        print(f"   ç”¨æˆ·æŠ¥å‘Š: æˆåŠŸæ—¥æœŸ 31 ä¸ªï¼Œå¤±è´¥æ—¥æœŸ 21 ä¸ª")
        print(f"   ç”¨æˆ·æŠ¥å‘Š: æˆåŠŸè®¡ç®— 141,606 æ¬¡ï¼Œå¤±è´¥è®¡ç®— 21 æ¬¡")
        print(f"   ç”¨æˆ·æŠ¥å‘Š: æˆåŠŸç‡ 100.0%")
        
        # 7. å…³é”®å‘ç°
        print(f"\nğŸ¯ å…³é”®å‘ç°:")
        print("-" * 40)
        
        if total_failed_records == 0:
            print("âœ… æ•°æ®åº“ä¸­æ‰€æœ‰è®°å½•éƒ½æ˜¯æˆåŠŸçŠ¶æ€ (calculation_status = 'success')")
            print("âŒ ä½†ç”¨æˆ·æŠ¥å‘Šæ˜¾ç¤ºæœ‰21ä¸ªå¤±è´¥æ—¥æœŸ")
            print("ğŸ” å¯èƒ½çš„åŸå› :")
            print("   1. è®¡ç®—è¿‡ç¨‹ä¸­çš„ä¸´æ—¶å¤±è´¥ï¼Œä½†æœ€ç»ˆéƒ½é‡è¯•æˆåŠŸäº†")
            print("   2. è®¡ç®—å™¨ç»Ÿè®¡é€»è¾‘ä¸æ•°æ®åº“å­˜å‚¨é€»è¾‘ä¸ä¸€è‡´")
            print("   3. ç”¨æˆ·çœ‹åˆ°çš„æ˜¯è®¡ç®—è¿‡ç¨‹ä¸­çš„ä¸­é—´çŠ¶æ€ï¼Œè€Œéæœ€ç»ˆç»“æœ")
            print("   4. å¯èƒ½å­˜åœ¨æ•°æ®è¦†ç›–æˆ–é‡æ–°è®¡ç®—çš„æƒ…å†µ")
        
        # 8. éªŒè¯è®¡ç®—å™¨é€»è¾‘
        print(f"\nğŸ”§ è®¡ç®—å™¨é€»è¾‘éªŒè¯:")
        print("-" * 40)
        print("æ ¹æ®ä»£ç åˆ†æï¼Œè®¡ç®—å™¨çš„å¤±è´¥æ—¥æœŸç»Ÿè®¡é€»è¾‘æ˜¯:")
        print("   - å¦‚æœæŸæ—¥æœŸæœ‰ä»»ä½• failed_count > 0ï¼Œå°±ç®—å¤±è´¥æ—¥æœŸ")
        print("   - å¦‚æœæŸæ—¥æœŸ failed_count = 0 ä¸” success_count > 0ï¼Œå°±ç®—æˆåŠŸæ—¥æœŸ")
        print("   - ä½†æ•°æ®åº“ä¸­çš„ calculation_status å­—æ®µé»˜è®¤éƒ½æ˜¯ 'success'")
        print("   - è¿™è¯´æ˜è®¡ç®—è¿‡ç¨‹ä¸­çš„å¤±è´¥æ˜¯ä¸´æ—¶æ€§çš„ï¼Œæœ€ç»ˆéƒ½ä¿å­˜ä¸ºæˆåŠŸçŠ¶æ€")
        
        return {
            'expected_fridays': len(expected_fridays),
            'actual_dates': len(df),
            'total_records': total_success_records + total_failed_records,
            'success_records': total_success_records,
            'failed_records': total_failed_records,
            'dates_with_failures': dates_with_failures,
            'dates_with_success': dates_with_success,
            'simulated_failed_dates': simulated_failed_dates,
            'simulated_successful_dates': simulated_successful_dates
        }
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return None


def analyze_calculation_process(context, year: int):
    """åˆ†æè®¡ç®—è¿‡ç¨‹"""
    print(f"\nğŸ” åˆ†æ {year} å¹´Gå› å­è®¡ç®—è¿‡ç¨‹...")
    print("=" * 60)
    
    # æŸ¥è¯¢è®¡ç®—è¿‡ç¨‹ä¸­çš„è¯¦ç»†ä¿¡æ¯
    query = """
    SELECT 
        calc_date,
        data_source,
        COUNT(*) as records_count,
        COUNT(CASE WHEN calculation_status = 'success' THEN 1 END) as success_count,
        COUNT(CASE WHEN calculation_status = 'failed' THEN 1 END) as failed_count,
        COUNT(CASE WHEN calculation_status = 'partial' THEN 1 END) as partial_count,
        AVG(g_score) as avg_g_score,
        MIN(created_at) as first_created,
        MAX(created_at) as last_created
    FROM pgs_factors.g_factor 
    WHERE EXTRACT(YEAR FROM calc_date) = %s
    GROUP BY calc_date, data_source
    ORDER BY calc_date, data_source
    """
    
    try:
        results = context.db_manager.fetch_sync(query, (year,))
        
        if not results:
            print(f"âŒ æœªæ‰¾åˆ° {year} å¹´çš„è¯¦ç»†è®¡ç®—æ•°æ®")
            return
        
        df = pd.DataFrame(results, columns=[
            'calc_date', 'data_source', 'records_count', 'success_count',
            'failed_count', 'partial_count', 'avg_g_score', 'first_created', 'last_created'
        ])
        
        print(f"ğŸ“Š æŒ‰æ•°æ®æºåˆ†ç»„çš„è®¡ç®—ç»Ÿè®¡:")
        print("-" * 80)
        
        for data_source in df['data_source'].unique():
            source_data = df[df['data_source'] == data_source]
            total_records = source_data['records_count'].sum()
            total_success = source_data['success_count'].sum()
            total_failed = source_data['failed_count'].sum()
            total_partial = source_data['partial_count'].sum()
            
            print(f"   {data_source}:")
            print(f"     æ€»è®°å½•: {total_records:,}")
            print(f"     æˆåŠŸ: {total_success:,}")
            print(f"     å¤±è´¥: {total_failed:,}")
            print(f"     éƒ¨åˆ†: {total_partial:,}")
            print(f"     æˆåŠŸç‡: {total_success/total_records*100:.1f}%")
        
        # åˆ†ææ—¶é—´åˆ†å¸ƒ
        print(f"\nâ° è®¡ç®—æ—¶é—´åˆ†æ:")
        print("-" * 40)
        
        df['first_created'] = pd.to_datetime(df['first_created'])
        df['last_created'] = pd.to_datetime(df['last_created'])
        
        earliest_created = df['first_created'].min()
        latest_created = df['last_created'].max()
        
        print(f"   æœ€æ—©åˆ›å»ºæ—¶é—´: {earliest_created}")
        print(f"   æœ€æ™šåˆ›å»ºæ—¶é—´: {latest_created}")
        print(f"   è®¡ç®—æ—¶é—´è·¨åº¦: {latest_created - earliest_created}")
        
        # åˆ†ææ˜¯å¦æœ‰é‡å¤è®¡ç®—
        date_counts = df.groupby('calc_date').size()
        duplicate_dates = date_counts[date_counts > 1]
        
        if len(duplicate_dates) > 0:
            print(f"\nğŸ”„ å‘ç°é‡å¤è®¡ç®—:")
            print("-" * 40)
            for date, count in duplicate_dates.items():
                print(f"   {date}: {count} æ¬¡è®¡ç®—")
        else:
            print(f"\nâœ… æ²¡æœ‰å‘ç°é‡å¤è®¡ç®—")
        
    except Exception as e:
        print(f"âŒ è¿‡ç¨‹åˆ†æå¤±è´¥: {e}")


def main():
    parser = argparse.ArgumentParser(description='Gå› å­è®¡ç®—å·®å¼‚è°ƒæŸ¥è„šæœ¬')
    parser.add_argument('--year', type=int, default=2015, help='åˆ†æå¹´ä»½ (é»˜è®¤: 2015)')
    
    args = parser.parse_args()
    
    print("ğŸš€ Gå› å­è®¡ç®—å·®å¼‚è°ƒæŸ¥å™¨")
    print("=" * 50)
    print(f"ğŸ“… åˆ†æå¹´ä»½: {args.year}")
    print(f"ğŸ• åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # åˆå§‹åŒ–ä¸Šä¸‹æ–‡
    try:
        context = ResearchContext()
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        sys.exit(1)
    
    # æ‰§è¡Œåˆ†æ
    result = analyze_calculation_logic_discrepancy(context, args.year)
    
    if result:
        analyze_calculation_process(context, args.year)
    
    print("\nâœ… è°ƒæŸ¥å®Œæˆ!")
    print("\nğŸ’¡ ç»“è®º:")
    print("   ç”¨æˆ·æŠ¥å‘Šçš„'21ä¸ªå¤±è´¥æ—¥æœŸ'å¾ˆå¯èƒ½æ˜¯è®¡ç®—è¿‡ç¨‹ä¸­çš„ä¸´æ—¶å¤±è´¥ç»Ÿè®¡ï¼Œ")
    print("   ä½†æœ€ç»ˆæ‰€æœ‰è®¡ç®—éƒ½æˆåŠŸå®Œæˆå¹¶ä¿å­˜åˆ°æ•°æ®åº“ä¸­ã€‚")
    print("   è¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆæ•°æ®åº“æ˜¾ç¤º100%æˆåŠŸç‡ï¼Œè€Œç”¨æˆ·çœ‹åˆ°æœ‰å¤±è´¥æ—¥æœŸã€‚")


if __name__ == "__main__":
    main()
