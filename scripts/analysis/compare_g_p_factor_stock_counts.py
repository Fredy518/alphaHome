#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Gå› å­å’ŒPå› å­è‚¡ç¥¨æ•°é‡å¯¹æ¯”åˆ†æè„šæœ¬
æ¯”è¾ƒæ¯ä¸ªcalc_dateçš„è‚¡ç¥¨æ•°é‡æ˜¯å¦å¯¹åº”ï¼ŒéªŒè¯æ•°æ®ä¸€è‡´æ€§

ä½¿ç”¨æ–¹æ³•ï¼š
python scripts/analysis/compare_g_p_factor_stock_counts.py --start_year 2010 --end_year 2024
"""

import sys
import os
import argparse
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from research.tools.context import ResearchContext

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


def get_g_factor_stock_counts(context, start_year: int, end_year: int):
    """è·å–Gå› å­å„æ—¥æœŸçš„è‚¡ç¥¨æ•°é‡"""
    print("ğŸ“Š è·å–Gå› å­è‚¡ç¥¨æ•°é‡æ•°æ®...")
    
    query = """
    SELECT 
        calc_date,
        EXTRACT(YEAR FROM calc_date) as year,
        COUNT(DISTINCT ts_code) as stock_count,
        COUNT(*) as total_records,
        COUNT(CASE WHEN calculation_status = 'success' THEN 1 END) as success_records,
        COUNT(CASE WHEN calculation_status = 'failed' THEN 1 END) as failed_records
    FROM pgs_factors.g_factor 
    WHERE EXTRACT(YEAR FROM calc_date) BETWEEN %s AND %s
    GROUP BY calc_date, EXTRACT(YEAR FROM calc_date)
    ORDER BY calc_date
    """
    
    try:
        results = context.db_manager.fetch_sync(query, (start_year, end_year))
        
        if not results:
            print("âŒ æœªæ‰¾åˆ°Gå› å­æ•°æ®")
            return None
        
        df = pd.DataFrame(results, columns=[
            'calc_date', 'year', 'stock_count', 'total_records', 
            'success_records', 'failed_records'
        ])
        
        df['calc_date'] = pd.to_datetime(df['calc_date'])
        df['factor_type'] = 'Gå› å­'
        
        print(f"   âœ… Gå› å­æ•°æ®: {len(df)} ä¸ªæ—¥æœŸ")
        return df
        
    except Exception as e:
        print(f"âŒ è·å–Gå› å­æ•°æ®å¤±è´¥: {e}")
        return None


def get_p_factor_stock_counts(context, start_year: int, end_year: int):
    """è·å–På› å­å„æ—¥æœŸçš„è‚¡ç¥¨æ•°é‡"""
    print("ğŸ“Š è·å–På› å­è‚¡ç¥¨æ•°é‡æ•°æ®...")
    
    query = """
    SELECT 
        calc_date,
        EXTRACT(YEAR FROM calc_date) as year,
        COUNT(DISTINCT ts_code) as stock_count,
        COUNT(*) as total_records,
        COUNT(CASE WHEN calculation_status = 'success' THEN 1 END) as success_records,
        COUNT(CASE WHEN calculation_status = 'failed' THEN 1 END) as failed_records
    FROM pgs_factors.p_factor 
    WHERE EXTRACT(YEAR FROM calc_date) BETWEEN %s AND %s
    GROUP BY calc_date, EXTRACT(YEAR FROM calc_date)
    ORDER BY calc_date
    """
    
    try:
        results = context.db_manager.fetch_sync(query, (start_year, end_year))
        
        if not results:
            print("âŒ æœªæ‰¾åˆ°På› å­æ•°æ®")
            return None
        
        df = pd.DataFrame(results, columns=[
            'calc_date', 'year', 'stock_count', 'total_records', 
            'success_records', 'failed_records'
        ])
        
        df['calc_date'] = pd.to_datetime(df['calc_date'])
        df['factor_type'] = 'På› å­'
        
        print(f"   âœ… På› å­æ•°æ®: {len(df)} ä¸ªæ—¥æœŸ")
        return df
        
    except Exception as e:
        print(f"âŒ è·å–På› å­æ•°æ®å¤±è´¥: {e}")
        return None


def compare_stock_counts(g_factor_df: pd.DataFrame, p_factor_df: pd.DataFrame):
    """æ¯”è¾ƒGå› å­å’ŒPå› å­çš„è‚¡ç¥¨æ•°é‡"""
    print("\nğŸ” æ¯”è¾ƒGå› å­å’ŒPå› å­è‚¡ç¥¨æ•°é‡...")
    print("=" * 60)
    
    # åˆå¹¶æ•°æ®
    g_factor_df = g_factor_df.rename(columns={
        'stock_count': 'g_stock_count',
        'total_records': 'g_total_records',
        'success_records': 'g_success_records',
        'failed_records': 'g_failed_records'
    })
    
    p_factor_df = p_factor_df.rename(columns={
        'stock_count': 'p_stock_count',
        'total_records': 'p_total_records',
        'success_records': 'p_success_records',
        'failed_records': 'p_failed_records'
    })
    
    # åˆå¹¶æ•°æ®
    merged_df = pd.merge(
        g_factor_df[['calc_date', 'year', 'g_stock_count', 'g_total_records', 'g_success_records', 'g_failed_records']],
        p_factor_df[['calc_date', 'year', 'p_stock_count', 'p_total_records', 'p_success_records', 'p_failed_records']],
        on=['calc_date', 'year'],
        how='outer'
    )
    
    # å¡«å……ç¼ºå¤±å€¼
    merged_df['g_stock_count'] = merged_df['g_stock_count'].fillna(0)
    merged_df['p_stock_count'] = merged_df['p_stock_count'].fillna(0)
    merged_df['g_total_records'] = merged_df['g_total_records'].fillna(0)
    merged_df['p_total_records'] = merged_df['p_total_records'].fillna(0)
    
    # è®¡ç®—å·®å¼‚
    merged_df['stock_count_diff'] = merged_df['g_stock_count'] - merged_df['p_stock_count']
    merged_df['stock_count_ratio'] = merged_df['g_stock_count'] / merged_df['p_stock_count'].replace(0, np.nan)
    
    # æ ‡è®°åŒ¹é…çŠ¶æ€
    merged_df['is_match'] = merged_df['stock_count_diff'] == 0
    merged_df['has_g_only'] = (merged_df['g_stock_count'] > 0) & (merged_df['p_stock_count'] == 0)
    merged_df['has_p_only'] = (merged_df['g_stock_count'] == 0) & (merged_df['p_stock_count'] > 0)
    merged_df['has_both'] = (merged_df['g_stock_count'] > 0) & (merged_df['p_stock_count'] > 0)
    
    print(f"ğŸ“Š æ•°æ®æ¦‚è§ˆ:")
    print(f"   æ€»æ—¥æœŸæ•°: {len(merged_df)}")
    print(f"   åŒæ—¶æœ‰Gå’ŒPå› å­æ•°æ®: {merged_df['has_both'].sum()} ä¸ªæ—¥æœŸ")
    print(f"   åªæœ‰Gå› å­æ•°æ®: {merged_df['has_g_only'].sum()} ä¸ªæ—¥æœŸ")
    print(f"   åªæœ‰På› å­æ•°æ®: {merged_df['has_p_only'].sum()} ä¸ªæ—¥æœŸ")
    print()
    
    return merged_df


def analyze_matches(merged_df: pd.DataFrame):
    """åˆ†æåŒ¹é…æƒ…å†µ"""
    print("ğŸ“ˆ åŒ¹é…æƒ…å†µåˆ†æ:")
    print("-" * 50)
    
    # åªåˆ†æåŒæ—¶æœ‰Gå’ŒPå› å­æ•°æ®çš„æ—¥æœŸ
    both_data = merged_df[merged_df['has_both']].copy()
    
    if len(both_data) == 0:
        print("âŒ æ²¡æœ‰åŒæ—¶åŒ…å«Gå’ŒPå› å­æ•°æ®çš„æ—¥æœŸ")
        return
    
    # åŸºæœ¬ç»Ÿè®¡
    total_dates = len(both_data)
    perfect_matches = both_data['is_match'].sum()
    match_rate = perfect_matches / total_dates * 100
    
    print(f"ğŸ“Š åŒ¹é…ç»Ÿè®¡:")
    print(f"   åŒæ—¶æœ‰æ•°æ®çš„æ—¥æœŸæ•°: {total_dates}")
    print(f"   å®Œå…¨åŒ¹é…çš„æ—¥æœŸæ•°: {perfect_matches}")
    print(f"   åŒ¹é…ç‡: {match_rate:.1f}%")
    print()
    
    # åˆ†æä¸åŒ¹é…çš„æƒ…å†µ
    mismatches = both_data[~both_data['is_match']].copy()
    
    if len(mismatches) > 0:
        print(f"ğŸš¨ ä¸åŒ¹é…æ—¥æœŸåˆ†æ:")
        print(f"   ä¸åŒ¹é…æ—¥æœŸæ•°: {len(mismatches)}")
        print(f"   ä¸åŒ¹é…ç‡: {len(mismatches)/total_dates*100:.1f}%")
        print()
        
        # è®¡ç®—å·®å¼‚ç»Ÿè®¡
        mismatches['abs_diff'] = abs(mismatches['stock_count_diff'])
        
        print(f"ğŸ“Š å·®å¼‚ç»Ÿè®¡:")
        print(f"   å¹³å‡å·®å¼‚: {mismatches['stock_count_diff'].mean():.1f} åª")
        print(f"   æœ€å¤§å·®å¼‚: {mismatches['stock_count_diff'].max():.0f} åª")
        print(f"   æœ€å°å·®å¼‚: {mismatches['stock_count_diff'].min():.0f} åª")
        print(f"   å¹³å‡ç»å¯¹å·®å¼‚: {mismatches['abs_diff'].mean():.1f} åª")
        print()
        
        # æ˜¾ç¤ºå·®å¼‚æœ€å¤§çš„æ—¥æœŸ
        print(f"ğŸ” å·®å¼‚æœ€å¤§çš„å‰10ä¸ªæ—¥æœŸ:")
        top_mismatches = mismatches.nlargest(10, 'abs_diff')
        for _, row in top_mismatches.iterrows():
            print(f"   {row['calc_date'].strftime('%Y-%m-%d')}: G={row['g_stock_count']:.0f}, P={row['p_stock_count']:.0f}, å·®å¼‚={row['stock_count_diff']:+.0f}")
        
        print()
        
        # åˆ†æå·®å¼‚æ¨¡å¼
        g_more = mismatches[mismatches['stock_count_diff'] > 0]
        p_more = mismatches[mismatches['stock_count_diff'] < 0]
        
        print(f"ğŸ“Š å·®å¼‚æ–¹å‘åˆ†æ:")
        print(f"   Gå› å­è‚¡ç¥¨æ•°æ›´å¤š: {len(g_more)} ä¸ªæ—¥æœŸ ({len(g_more)/len(mismatches)*100:.1f}%)")
        print(f"   På› å­è‚¡ç¥¨æ•°æ›´å¤š: {len(p_more)} ä¸ªæ—¥æœŸ ({len(p_more)/len(mismatches)*100:.1f}%)")
        
        if len(g_more) > 0:
            print(f"   Gå› å­å¹³å‡å¤š: {g_more['stock_count_diff'].mean():.1f} åª")
        if len(p_more) > 0:
            print(f"   På› å­å¹³å‡å¤š: {abs(p_more['stock_count_diff'].mean()):.1f} åª")
        
        return mismatches
    else:
        print("âœ… æ‰€æœ‰æ—¥æœŸéƒ½å®Œå…¨åŒ¹é…!")
        return pd.DataFrame()


def analyze_yearly_patterns(merged_df: pd.DataFrame):
    """åˆ†æå¹´åº¦æ¨¡å¼"""
    print("\nğŸ“… å¹´åº¦æ¨¡å¼åˆ†æ:")
    print("-" * 50)
    
    # åªåˆ†æåŒæ—¶æœ‰Gå’ŒPå› å­æ•°æ®çš„æ—¥æœŸ
    both_data = merged_df[merged_df['has_both']].copy()
    
    if len(both_data) == 0:
        print("âŒ æ²¡æœ‰åŒæ—¶åŒ…å«Gå’ŒPå› å­æ•°æ®çš„æ—¥æœŸ")
        return
    
    yearly_stats = both_data.groupby('year').agg({
        'is_match': ['count', 'sum'],
        'stock_count_diff': ['mean', 'std', 'min', 'max'],
        'g_stock_count': 'mean',
        'p_stock_count': 'mean'
    }).round(2)
    
    yearly_stats.columns = [
        'æ€»æ—¥æœŸæ•°', 'åŒ¹é…æ—¥æœŸæ•°', 'å¹³å‡å·®å¼‚', 'å·®å¼‚æ ‡å‡†å·®', 'æœ€å°å·®å¼‚', 'æœ€å¤§å·®å¼‚',
        'å¹³å‡Gè‚¡ç¥¨æ•°', 'å¹³å‡Pè‚¡ç¥¨æ•°'
    ]
    
    # è®¡ç®—åŒ¹é…ç‡
    yearly_stats['åŒ¹é…ç‡(%)'] = (yearly_stats['åŒ¹é…æ—¥æœŸæ•°'] / yearly_stats['æ€»æ—¥æœŸæ•°'] * 100).round(1)
    
    print("å¹´åº¦åŒ¹é…æƒ…å†µ:")
    print(yearly_stats)
    print()
    
    # è¯†åˆ«é—®é¢˜å¹´ä»½
    low_match_years = yearly_stats[yearly_stats['åŒ¹é…ç‡(%)'] < 90]
    if len(low_match_years) > 0:
        print(f"âš ï¸ åŒ¹é…ç‡ä½äº90%çš„å¹´ä»½:")
        for year, row in low_match_years.iterrows():
            print(f"   {year}å¹´: åŒ¹é…ç‡ {row['åŒ¹é…ç‡(%)']:.1f}%, å¹³å‡å·®å¼‚ {row['å¹³å‡å·®å¼‚']:+.1f} åª")
    else:
        print("âœ… æ‰€æœ‰å¹´ä»½åŒ¹é…ç‡éƒ½åœ¨90%ä»¥ä¸Š")
    
    return yearly_stats


def analyze_2015_specific(merged_df: pd.DataFrame):
    """ä¸“é—¨åˆ†æ2015å¹´"""
    print("\nğŸ” 2015å¹´è¯¦ç»†åˆ†æ:")
    print("=" * 50)
    
    year_2015 = merged_df[merged_df['year'] == 2015].copy()
    
    if len(year_2015) == 0:
        print("âŒ 2015å¹´æ— æ•°æ®")
        return
    
    print(f"ğŸ“Š 2015å¹´åŸºæœ¬ç»Ÿè®¡:")
    print(f"   æ€»æ—¥æœŸæ•°: {len(year_2015)}")
    print(f"   åŒæ—¶æœ‰Gå’ŒPå› å­æ•°æ®: {year_2015['has_both'].sum()} ä¸ªæ—¥æœŸ")
    print(f"   åªæœ‰Gå› å­æ•°æ®: {year_2015['has_g_only'].sum()} ä¸ªæ—¥æœŸ")
    print(f"   åªæœ‰På› å­æ•°æ®: {year_2015['has_p_only'].sum()} ä¸ªæ—¥æœŸ")
    print()
    
    # åˆ†æåŒæ—¶æœ‰æ•°æ®çš„æ—¥æœŸ
    both_2015 = year_2015[year_2015['has_both']].copy()
    
    if len(both_2015) > 0:
        perfect_matches = both_2015['is_match'].sum()
        match_rate = perfect_matches / len(both_2015) * 100
        
        print(f"ğŸ“ˆ 2015å¹´åŒ¹é…æƒ…å†µ:")
        print(f"   åŒæ—¶æœ‰æ•°æ®çš„æ—¥æœŸæ•°: {len(both_2015)}")
        print(f"   å®Œå…¨åŒ¹é…çš„æ—¥æœŸæ•°: {perfect_matches}")
        print(f"   åŒ¹é…ç‡: {match_rate:.1f}%")
        print()
        
        # åˆ†æä¸åŒ¹é…çš„æ—¥æœŸ
        mismatches_2015 = both_2015[~both_2015['is_match']].copy()
        
        if len(mismatches_2015) > 0:
            print(f"ğŸš¨ 2015å¹´ä¸åŒ¹é…æ—¥æœŸè¯¦æƒ…:")
            for _, row in mismatches_2015.iterrows():
                diff = row['stock_count_diff']
                status = "Gå¤š" if diff > 0 else "På¤š"
                print(f"   {row['calc_date'].strftime('%Y-%m-%d')}: G={row['g_stock_count']:.0f}, P={row['p_stock_count']:.0f}, å·®å¼‚={diff:+.0f} ({status})")
        else:
            print("âœ… 2015å¹´æ‰€æœ‰æ—¥æœŸéƒ½å®Œå…¨åŒ¹é…!")
        
        # è®¡ç®—å¹³å‡å·®å¼‚
        avg_diff = both_2015['stock_count_diff'].mean()
        print(f"\nğŸ“Š 2015å¹´å¹³å‡å·®å¼‚: {avg_diff:+.1f} åª")
        
        if abs(avg_diff) > 1:
            if avg_diff > 0:
                print("âš ï¸ Gå› å­å¹³å‡è‚¡ç¥¨æ•°æ¯”På› å­å¤š")
            else:
                print("âš ï¸ På› å­å¹³å‡è‚¡ç¥¨æ•°æ¯”Gå› å­å¤š")
        else:
            print("âœ… å¹³å‡å·®å¼‚å¾ˆå°ï¼ŒåŸºæœ¬ä¸€è‡´")
    
    return both_2015


def generate_visualization(merged_df: pd.DataFrame, output_dir: str = "results"):
    """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
    print(f"\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # åªåˆ†æåŒæ—¶æœ‰Gå’ŒPå› å­æ•°æ®çš„æ—¥æœŸ
    both_data = merged_df[merged_df['has_both']].copy()
    
    if len(both_data) == 0:
        print("   âš ï¸ æ²¡æœ‰åŒæ—¶åŒ…å«Gå’ŒPå› å­æ•°æ®çš„æ—¥æœŸï¼Œè·³è¿‡å¯è§†åŒ–")
        return
    
    # è®¾ç½®å›¾è¡¨æ ·å¼
    plt.style.use('default')
    fig_size = (15, 10)
    
    # 1. è‚¡ç¥¨æ•°é‡å¯¹æ¯”æ—¶é—´åºåˆ—å›¾
    plt.figure(figsize=fig_size)
    
    plt.plot(both_data['calc_date'], both_data['g_stock_count'], 
            label='Gå› å­', color='blue', linewidth=2, alpha=0.8)
    plt.plot(both_data['calc_date'], both_data['p_stock_count'], 
            label='På› å­', color='red', linewidth=2, alpha=0.8)
    
    plt.title('Gå› å­ä¸På› å­è‚¡ç¥¨æ•°é‡å¯¹æ¯”', fontsize=16, fontweight='bold')
    plt.xlabel('è®¡ç®—æ—¥æœŸ', fontsize=12)
    plt.ylabel('è‚¡ç¥¨æ•°é‡', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    plt.tight_layout()
    
    output_file = os.path.join(output_dir, 'g_p_factor_stock_count_comparison.png')
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"   âœ… è‚¡ç¥¨æ•°é‡å¯¹æ¯”å›¾å·²ä¿å­˜: {output_file}")
    plt.close()
    
    # 2. å·®å¼‚åˆ†æå›¾
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    
    # å·®å¼‚æ—¶é—´åºåˆ—
    ax1.plot(both_data['calc_date'], both_data['stock_count_diff'], 
            color='green', linewidth=1, alpha=0.7)
    ax1.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    ax1.set_title('Gå› å­ä¸På› å­è‚¡ç¥¨æ•°é‡å·®å¼‚', fontweight='bold')
    ax1.set_ylabel('å·®å¼‚ (G - P)')
    ax1.grid(True, alpha=0.3)
    
    # å·®å¼‚åˆ†å¸ƒç›´æ–¹å›¾
    ax2.hist(both_data['stock_count_diff'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')
    ax2.axvline(x=0, color='red', linestyle='--', alpha=0.7)
    ax2.set_title('å·®å¼‚åˆ†å¸ƒç›´æ–¹å›¾', fontweight='bold')
    ax2.set_xlabel('å·®å¼‚ (G - P)')
    ax2.set_ylabel('é¢‘æ¬¡')
    ax2.grid(True, alpha=0.3)
    
    # å¹´åº¦åŒ¹é…ç‡
    yearly_stats = both_data.groupby('year').agg({
        'is_match': ['count', 'sum']
    })
    yearly_stats.columns = ['total', 'matches']
    yearly_stats['match_rate'] = yearly_stats['matches'] / yearly_stats['total'] * 100
    
    years = yearly_stats.index
    match_rates = yearly_stats['match_rate']
    
    bars = ax3.bar(years, match_rates, alpha=0.7, color='lightgreen', edgecolor='black')
    ax3.axhline(y=100, color='red', linestyle='--', alpha=0.7, label='100%åŒ¹é…')
    ax3.set_title('å¹´åº¦åŒ¹é…ç‡', fontweight='bold')
    ax3.set_xlabel('å¹´ä»½')
    ax3.set_ylabel('åŒ¹é…ç‡ (%)')
    ax3.set_ylim(0, 105)
    ax3.grid(True, alpha=0.3)
    
    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ˜¾ç¤ºæ•°å€¼
    for bar, rate in zip(bars, match_rates):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{rate:.1f}%', ha='center', va='bottom', fontsize=9)
    
    # æ•£ç‚¹å›¾ï¼šG vs P
    ax4.scatter(both_data['p_stock_count'], both_data['g_stock_count'], 
               alpha=0.6, color='blue', s=20)
    
    # æ·»åŠ y=xå‚è€ƒçº¿
    min_val = min(both_data['p_stock_count'].min(), both_data['g_stock_count'].min())
    max_val = max(both_data['p_stock_count'].max(), both_data['g_stock_count'].max())
    ax4.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.7, label='y=x')
    
    ax4.set_title('Gå› å­ vs På› å­è‚¡ç¥¨æ•°é‡æ•£ç‚¹å›¾', fontweight='bold')
    ax4.set_xlabel('På› å­è‚¡ç¥¨æ•°é‡')
    ax4.set_ylabel('Gå› å­è‚¡ç¥¨æ•°é‡')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    output_file = os.path.join(output_dir, 'g_p_factor_detailed_analysis.png')
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"   âœ… è¯¦ç»†åˆ†æå›¾å·²ä¿å­˜: {output_file}")
    plt.close()


def generate_comparison_report(merged_df: pd.DataFrame, mismatches: pd.DataFrame, yearly_stats: pd.DataFrame):
    """ç”Ÿæˆå¯¹æ¯”åˆ†ææŠ¥å‘Š"""
    print(f"\nğŸ“‹ ç”Ÿæˆå¯¹æ¯”åˆ†ææŠ¥å‘Š...")
    
    report = []
    report.append("# Gå› å­ä¸På› å­è‚¡ç¥¨æ•°é‡å¯¹æ¯”åˆ†ææŠ¥å‘Š")
    report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("")
    
    # æ€»ä½“ç»Ÿè®¡
    both_data = merged_df[merged_df['has_both']].copy()
    total_dates = len(both_data)
    perfect_matches = both_data['is_match'].sum() if len(both_data) > 0 else 0
    match_rate = perfect_matches / total_dates * 100 if total_dates > 0 else 0
    
    report.append("## æ€»ä½“ç»Ÿè®¡")
    report.append(f"- åˆ†æå¹´ä»½èŒƒå›´: {merged_df['year'].min()}-{merged_df['year'].max()}")
    report.append(f"- æ€»æ—¥æœŸæ•°: {len(merged_df)}")
    report.append(f"- åŒæ—¶æœ‰Gå’ŒPå› å­æ•°æ®: {len(both_data)} ä¸ªæ—¥æœŸ")
    report.append(f"- å®Œå…¨åŒ¹é…çš„æ—¥æœŸæ•°: {perfect_matches}")
    report.append(f"- æ€»ä½“åŒ¹é…ç‡: {match_rate:.1f}%")
    report.append("")
    
    # ä¸åŒ¹é…åˆ†æ
    if len(mismatches) > 0:
        report.append("## ä¸åŒ¹é…åˆ†æ")
        report.append(f"- ä¸åŒ¹é…æ—¥æœŸæ•°: {len(mismatches)}")
        report.append(f"- ä¸åŒ¹é…ç‡: {len(mismatches)/total_dates*100:.1f}%")
        report.append(f"- å¹³å‡å·®å¼‚: {mismatches['stock_count_diff'].mean():.1f} åª")
        report.append(f"- æœ€å¤§å·®å¼‚: {mismatches['stock_count_diff'].max():.0f} åª")
        report.append("")
        
        # å·®å¼‚æœ€å¤§çš„æ—¥æœŸ
        report.append("### å·®å¼‚æœ€å¤§çš„å‰10ä¸ªæ—¥æœŸ")
        top_mismatches = mismatches.nlargest(10, 'abs_diff')
        for _, row in top_mismatches.iterrows():
            report.append(f"- {row['calc_date'].strftime('%Y-%m-%d')}: G={row['g_stock_count']:.0f}, P={row['p_stock_count']:.0f}, å·®å¼‚={row['stock_count_diff']:+.0f}")
        report.append("")
    else:
        report.append("## ä¸åŒ¹é…åˆ†æ")
        report.append("âœ… æ‰€æœ‰æ—¥æœŸéƒ½å®Œå…¨åŒ¹é…!")
        report.append("")
    
    # å¹´åº¦åˆ†æ
    if len(yearly_stats) > 0:
        report.append("## å¹´åº¦åŒ¹é…æƒ…å†µ")
        for year, row in yearly_stats.iterrows():
            report.append(f"- {year}å¹´: åŒ¹é…ç‡ {row['åŒ¹é…ç‡(%)']:.1f}%, å¹³å‡å·®å¼‚ {row['å¹³å‡å·®å¼‚']:+.1f} åª")
        report.append("")
    
    # ç»“è®º
    report.append("## ç»“è®º")
    if match_rate >= 95:
        report.append("âœ… Gå› å­å’ŒPå› å­çš„è‚¡ç¥¨æ•°é‡é«˜åº¦ä¸€è‡´ï¼Œæ•°æ®è´¨é‡è‰¯å¥½")
    elif match_rate >= 90:
        report.append("âš ï¸ Gå› å­å’ŒPå› å­çš„è‚¡ç¥¨æ•°é‡åŸºæœ¬ä¸€è‡´ï¼Œå­˜åœ¨å°‘é‡å·®å¼‚")
    else:
        report.append("âŒ Gå› å­å’ŒPå› å­çš„è‚¡ç¥¨æ•°é‡å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥")
    
    # ä¿å­˜æŠ¥å‘Š
    report_content = "\n".join(report)
    report_file = "results/g_p_factor_stock_count_comparison_report.md"
    os.makedirs("results", exist_ok=True)
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"   âœ… å¯¹æ¯”åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")


def main():
    parser = argparse.ArgumentParser(description='Gå› å­å’ŒPå› å­è‚¡ç¥¨æ•°é‡å¯¹æ¯”åˆ†æè„šæœ¬')
    parser.add_argument('--start_year', type=int, default=2010, help='å¼€å§‹å¹´ä»½ (é»˜è®¤: 2010)')
    parser.add_argument('--end_year', type=int, default=2024, help='ç»“æŸå¹´ä»½ (é»˜è®¤: 2024)')
    parser.add_argument('--focus_2015', action='store_true', help='é‡ç‚¹å…³æ³¨2015å¹´åˆ†æ')
    parser.add_argument('--generate_plots', action='store_true', help='ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨')
    
    args = parser.parse_args()
    
    # éªŒè¯å‚æ•°
    if args.start_year > args.end_year:
        print(f"âŒ start_year ({args.start_year}) å¿…é¡»å°äºç­‰äº end_year ({args.end_year})")
        sys.exit(1)
    
    print("ğŸš€ Gå› å­ä¸På› å­è‚¡ç¥¨æ•°é‡å¯¹æ¯”åˆ†æå™¨")
    print("=" * 60)
    print(f"ğŸ“… åˆ†æå¹´ä»½èŒƒå›´: {args.start_year}-{args.end_year}")
    print(f"ğŸ¯ é‡ç‚¹å…³æ³¨2015å¹´: {'æ˜¯' if args.focus_2015 else 'å¦'}")
    print(f"ğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨: {'æ˜¯' if args.generate_plots else 'å¦'}")
    print(f"ğŸ• åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # åˆå§‹åŒ–ä¸Šä¸‹æ–‡
    try:
        context = ResearchContext()
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        sys.exit(1)
    
    # è·å–æ•°æ®
    g_factor_df = get_g_factor_stock_counts(context, args.start_year, args.end_year)
    p_factor_df = get_p_factor_stock_counts(context, args.start_year, args.end_year)
    
    if g_factor_df is None or p_factor_df is None:
        print("âŒ æ•°æ®è·å–å¤±è´¥")
        sys.exit(1)
    
    # æ¯”è¾ƒæ•°æ®
    merged_df = compare_stock_counts(g_factor_df, p_factor_df)
    
    # åˆ†æåŒ¹é…æƒ…å†µ
    mismatches = analyze_matches(merged_df)
    
    # å¹´åº¦æ¨¡å¼åˆ†æ
    yearly_stats = analyze_yearly_patterns(merged_df)
    
    # 2015å¹´è¯¦ç»†åˆ†æ
    if args.focus_2015:
        analyze_2015_specific(merged_df)
    
    # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    if args.generate_plots:
        generate_visualization(merged_df)
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    generate_comparison_report(merged_df, mismatches, yearly_stats)
    
    print("\nâœ… å¯¹æ¯”åˆ†æå®Œæˆ!")


if __name__ == "__main__":
    main()
