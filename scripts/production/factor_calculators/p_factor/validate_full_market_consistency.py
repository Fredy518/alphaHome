#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
På› å­å…¨å¸‚åœºä¸€è‡´æ€§éªŒè¯è„šæœ¬
========================

éšæœºé€‰æ‹©ä¸€ä¸ªå‘¨äº”ï¼Œè®¡ç®—æ‰€æœ‰Aè‚¡çš„På› å­ï¼ŒéªŒè¯ç”Ÿäº§çº§ç‰ˆæœ¬å’Œç ”ç©¶ç›®å½•ç‰ˆæœ¬çš„ä¸€è‡´æ€§ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
python scripts/production/factor_calculators/p_factor/validate_full_market_consistency.py --auto_date
python scripts/production/factor_calculators/p_factor/validate_full_market_consistency.py --test_date 2024-12-13
"""

import sys
import os
import argparse
import time
import pandas as pd
import numpy as np
from datetime import datetime, date, timedelta
from pathlib import Path
import random

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„  
current_file = Path(__file__)
project_root = current_file.parent.parent.parent.parent.parent
sys.path.append(str(project_root))

# å¯¼å…¥ç”Ÿäº§çº§è®¡ç®—å™¨
import importlib.util
spec = importlib.util.spec_from_file_location(
    "production_p_factor_calculator", 
    Path(__file__).parent / "production_p_factor_calculator.py"
)
prod_calc_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(prod_calc_module)
ProductionPFactorCalculator = prod_calc_module.ProductionPFactorCalculator

# å¯¼å…¥ç ”ç©¶ç›®å½•çš„è®¡ç®—å™¨
try:
    # å¯¼å…¥ ResearchContext
    context_spec = importlib.util.spec_from_file_location(
        "research_context", 
        project_root / "research" / "tools" / "context.py"
    )
    context_module = importlib.util.module_from_spec(context_spec)
    context_spec.loader.exec_module(context_module)
    ResearchContext = context_module.ResearchContext
    
    # å¯¼å…¥ç ”ç©¶ç›®å½•çš„ P å› å­è®¡ç®—å™¨
    research_calc_spec = importlib.util.spec_from_file_location(
        "research_p_factor_calculator", 
        project_root / "research" / "pgs_factor" / "processors" / "production_p_factor_calculator.py"
    )
    research_calc_module = importlib.util.module_from_spec(research_calc_spec)
    research_calc_spec.loader.exec_module(research_calc_module)
    ResearchPFactorCalculator = research_calc_module.ProductionPFactorCalculator
    
    RESEARCH_AVAILABLE = True
    print("âœ… ç ”ç©¶ç›®å½•æ¨¡å—å¯¼å…¥æˆåŠŸ")
except Exception as e:
    print(f"âš ï¸ ç ”ç©¶ç›®å½•æ¨¡å—ä¸å¯ç”¨: {e}")
    RESEARCH_AVAILABLE = False
    ResearchContext = None
    ResearchPFactorCalculator = None


def get_random_friday(start_year: int = 2024, months_back: int = 6) -> str:
    """è·å–éšæœºçš„å‘¨äº”æ—¥æœŸ
    
    Args:
        start_year: å¼€å§‹å¹´ä»½
        months_back: å¾€å‰å¤šå°‘ä¸ªæœˆ
    
    Returns:
        å‘¨äº”æ—¥æœŸå­—ç¬¦ä¸²
    """
    # è®¡ç®—å¼€å§‹å’Œç»“æŸæ—¥æœŸ
    end_date = date.today() - timedelta(days=30)  # é¿å…é€‰æ‹©å¤ªè¿‘æœŸçš„æ—¥æœŸ
    start_date = end_date - timedelta(days=months_back * 30)
    
    # æ”¶é›†æ‰€æœ‰å‘¨äº”
    fridays = []
    current = start_date
    
    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå‘¨äº”
    while current.weekday() != 4:  # 4 = å‘¨äº”
        current += timedelta(days=1)
    
    # æ”¶é›†æ‰€æœ‰å‘¨äº”
    while current <= end_date:
        fridays.append(current.strftime('%Y-%m-%d'))
        current += timedelta(days=7)
    
    # éšæœºé€‰æ‹©ä¸€ä¸ª
    if fridays:
        selected_friday = random.choice(fridays)
        print(f"éšæœºé€‰æ‹©çš„å‘¨äº”: {selected_friday}")
        return selected_friday
    else:
        # å›é€€åˆ°å›ºå®šæ—¥æœŸ
        return "2024-12-13"


def get_all_trading_stocks(test_date: str) -> list:
    """è·å–æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰åœ¨äº¤æ˜“Aè‚¡
    
    Args:
        test_date: æµ‹è¯•æ—¥æœŸ
    
    Returns:
        è‚¡ç¥¨ä»£ç åˆ—è¡¨
    """
    try:
        prod_calc = ProductionPFactorCalculator()
        
        # å°è¯•ä»æ•°æ®åº“è·å–
        query = """
        SELECT ts_code
        FROM tushare.stock_basic
        WHERE list_date <= %s
        AND (delist_date IS NULL OR delist_date > %s)
        AND (ts_code LIKE '%.SZ' OR ts_code LIKE '%.SH')
        ORDER BY ts_code
        """
        
        # å…ˆå°è¯•ä»æ•°æ®åº“æŸ¥è¯¢çœŸå®çš„Aè‚¡åˆ—è¡¨
        try:
            results = prod_calc.db_manager.fetch_sync(query, (test_date, test_date))
            
            if results and len(results) > 0:
                stock_codes = [row[0] for row in results if len(row) > 0]
                if stock_codes:
                    print(f"ä»æ•°æ®åº“è·å–åˆ° {len(stock_codes)} åªAè‚¡")
                    return stock_codes
        except Exception as db_error:
            print(f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {db_error}")
        
        # å¦‚æœæ•°æ®åº“æŸ¥è¯¢å¤±è´¥ï¼Œä½¿ç”¨æ‰©å±•çš„é¢„å®šä¹‰è‚¡ç¥¨åˆ—è¡¨è¿›è¡Œæµ‹è¯•
        print("ä½¿ç”¨æ‰©å±•é¢„å®šä¹‰è‚¡ç¥¨åˆ—è¡¨è¿›è¡Œå…¨å¸‚åœºéªŒè¯æµ‹è¯•")
        
        # æ‰©å±•çš„Aè‚¡ä»£è¡¨è‚¡ç¥¨æ± ï¼ˆæ¶µç›–æ›´å¤šè¡Œä¸šå’Œè§„æ¨¡ï¼‰
        extended_stocks = []
        
        # æ·±äº¤æ‰€ä¸»æ¿å’Œä¸­å°æ¿ (000XXX, 002XXX)
        for i in range(1, 100):  # 000001-000099
            extended_stocks.append(f"{i:06d}.SZ")
        for i in range(1, 50):   # 002001-002049  
            extended_stocks.append(f"{2000+i:06d}.SZ")
            
        # ä¸Šäº¤æ‰€ä¸»æ¿ (600XXX, 601XXX)
        for i in range(1, 100):  # 600001-600099
            extended_stocks.append(f"{600000+i:06d}.SH")
        for i in range(1, 50):   # 601001-601049
            extended_stocks.append(f"{601000+i:06d}.SH")
            
        # åˆ›ä¸šæ¿ (300XXX) 
        for i in range(1, 30):   # 300001-300029
            extended_stocks.append(f"{300000+i:06d}.SZ")
        
        print(f"æ‰©å±•è‚¡ç¥¨æ± : {len(extended_stocks)} åªè‚¡ç¥¨ä»£ç ")
        return extended_stocks
    
    except Exception as e:
        print(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        return []


def run_production_full_calculation(test_date: str, stock_codes: list) -> pd.DataFrame:
    """è¿è¡Œç”Ÿäº§çº§å…¨å¸‚åœºPå› å­è®¡ç®—"""
    print(f"\n=== è¿è¡Œç”Ÿäº§çº§å…¨å¸‚åœºPå› å­è®¡ç®— ===")
    print(f"è‚¡ç¥¨æ•°é‡: {len(stock_codes)}")
    
    try:
        calc = ProductionPFactorCalculator()
        
        start_time = time.time()
        result = calc.calculate_p_factors_pit(test_date, stock_codes)
        end_time = time.time()
        
        print(f"ç”Ÿäº§çº§è®¡ç®—ç»“æœ:")
        print(f"  æˆåŠŸ: {result['success_count']}")
        print(f"  å¤±è´¥: {result['failed_count']}")
        print(f"  è€—æ—¶: {end_time - start_time:.2f} ç§’")
        print(f"  ååé‡: {result['success_count']/(end_time - start_time):.1f} åª/ç§’")
        
        if result['success_count'] == 0:
            print("âŒ ç”Ÿäº§çº§è®¡ç®—æœªäº§ç”Ÿä»»ä½•ç»“æœ")
            return pd.DataFrame()
        
        # ä»æ•°æ®åº“æŸ¥è¯¢è®¡ç®—ç»“æœ
        query = """
        SELECT ts_code, p_score, p_rank, gpa, roe_excl, roa_excl, 
               net_margin_ttm, operating_margin_ttm, roi_ttm
        FROM pgs_factors.p_factor
        WHERE calc_date = %s
        ORDER BY p_rank ASC, ts_code
        """
        
        results = calc.db_manager.fetch_sync(query, (test_date,))
        
        if results:
            columns = ['ts_code', 'p_score', 'p_rank', 'gpa', 'roe_excl', 'roa_excl',
                      'net_margin_ttm', 'operating_margin_ttm', 'roi_ttm']
            prod_df = pd.DataFrame(results, columns=columns)
            print(f"  æŸ¥è¯¢åˆ° {len(prod_df)} æ¡ç”Ÿäº§çº§ç»“æœ")
            return prod_df
        else:
            return pd.DataFrame()
        
    except Exception as e:
        print(f"âŒ ç”Ÿäº§çº§è®¡ç®—å¤±è´¥: {e}")
        return pd.DataFrame()


def run_research_full_calculation(test_date: str, stock_codes: list) -> pd.DataFrame:
    """è¿è¡Œç ”ç©¶ç›®å½•å…¨å¸‚åœºPå› å­è®¡ç®—"""
    print(f"\n=== è¿è¡Œç ”ç©¶ç›®å½•å…¨å¸‚åœºPå› å­è®¡ç®— ===")
    
    if not RESEARCH_AVAILABLE:
        print("âŒ ç ”ç©¶ç›®å½•æ¨¡å—ä¸å¯ç”¨")
        return pd.DataFrame()
    
    try:
        context = ResearchContext()
        calc = ResearchPFactorCalculator(context)
        
        start_time = time.time()
        result = calc.calculate_p_factors_pit(test_date, stock_codes)
        end_time = time.time()
        
        print(f"ç ”ç©¶ç›®å½•è®¡ç®—ç»“æœ:")
        print(f"  æˆåŠŸ: {result['success_count']}")
        print(f"  å¤±è´¥: {result['failed_count']}")
        print(f"  è€—æ—¶: {end_time - start_time:.2f} ç§’")
        print(f"  ååé‡: {result['success_count']/(end_time - start_time):.1f} åª/ç§’")
        
        if result['success_count'] == 0:
            print("âŒ ç ”ç©¶ç›®å½•è®¡ç®—æœªäº§ç”Ÿä»»ä½•ç»“æœ")
            return pd.DataFrame()
        
        # ä»æ•°æ®åº“æŸ¥è¯¢è®¡ç®—ç»“æœ
        query = """
        SELECT ts_code, p_score, p_rank, gpa, roe_excl, roa_excl,
               net_margin_ttm, operating_margin_ttm, roi_ttm
        FROM pgs_factors.p_factor
        WHERE calc_date = %s
        ORDER BY p_rank ASC, ts_code
        """
        
        research_df = context.query_dataframe(query, (test_date,))
        
        if research_df is not None and not research_df.empty:
            print(f"  æŸ¥è¯¢åˆ° {len(research_df)} æ¡ç ”ç©¶ç›®å½•ç»“æœ")
            return research_df
        else:
            return pd.DataFrame()
        
    except Exception as e:
        print(f"âŒ ç ”ç©¶ç›®å½•è®¡ç®—å¤±è´¥: {e}")
        return pd.DataFrame()


def analyze_full_market_results(prod_df: pd.DataFrame, research_df: pd.DataFrame) -> dict:
    """åˆ†æå…¨å¸‚åœºè®¡ç®—ç»“æœ"""
    print(f"\n=== å…¨å¸‚åœºè®¡ç®—ç»“æœåˆ†æ ===")
    
    if prod_df.empty or research_df.empty:
        return {'success': False, 'error': 'One or both results are empty'}
    
    # åŸºç¡€ç»Ÿè®¡
    print(f"ç”Ÿäº§çº§ç»“æœ: {len(prod_df)} åªè‚¡ç¥¨")
    print(f"ç ”ç©¶ç›®å½•ç»“æœ: {len(research_df)} åªè‚¡ç¥¨")
    
    # æŒ‰è‚¡ç¥¨ä»£ç åˆå¹¶
    merged = pd.merge(
        prod_df.add_suffix('_prod'), 
        research_df.add_suffix('_research'),
        left_on='ts_code_prod',
        right_on='ts_code_research',
        how='outer',
        indicator=True
    )
    
    common_stocks = len(merged[merged['_merge'] == 'both'])
    only_prod = len(merged[merged['_merge'] == 'left_only'])
    only_research = len(merged[merged['_merge'] == 'right_only'])
    
    print(f"å…±åŒè‚¡ç¥¨: {common_stocks} åª")
    print(f"ä»…ç”Ÿäº§çº§æœ‰: {only_prod} åª")  
    print(f"ä»…ç ”ç©¶ç›®å½•æœ‰: {only_research} åª")
    
    if common_stocks == 0:
        return {'success': False, 'error': 'No common stocks found'}
    
    # åˆ†æå…±åŒè‚¡ç¥¨çš„å·®å¼‚
    common_data = merged[merged['_merge'] == 'both'].copy()
    
    # Pè¯„åˆ†ç»Ÿè®¡
    prod_p_scores = pd.to_numeric(common_data['p_score_prod'], errors='coerce')
    research_p_scores = pd.to_numeric(common_data['p_score_research'], errors='coerce')
    p_score_diff = np.abs(prod_p_scores - research_p_scores)
    
    # æ’åç»Ÿè®¡
    prod_ranks = pd.to_numeric(common_data['p_rank_prod'], errors='coerce')
    research_ranks = pd.to_numeric(common_data['p_rank_research'], errors='coerce')
    rank_diff = np.abs(prod_ranks - research_ranks)
    
    # è¡Œä¸šç‰¹æ®Šå¤„ç†è‚¡ç¥¨åˆ†æ
    financial_stocks_prod = common_data[pd.isna(pd.to_numeric(common_data['gpa_prod'], errors='coerce'))]['ts_code_prod'].tolist()
    financial_stocks_research = common_data[pd.isna(pd.to_numeric(common_data['gpa_research'], errors='coerce'))]['ts_code_research'].tolist()
    
    results = {
        'success': True,
        'total_stocks': {
            'production': len(prod_df),
            'research': len(research_df),
            'common': common_stocks,
            'only_production': only_prod,
            'only_research': only_research
        },
        'p_score_analysis': {
            'max_diff': float(p_score_diff.max()) if not p_score_diff.empty else None,
            'mean_diff': float(p_score_diff.mean()) if not p_score_diff.empty else None,
            'std_diff': float(p_score_diff.std()) if not p_score_diff.empty else None,
            'production_mean': float(prod_p_scores.mean()) if not prod_p_scores.empty else None,
            'research_mean': float(research_p_scores.mean()) if not research_p_scores.empty else None
        },
        'ranking_analysis': {
            'max_rank_diff': float(rank_diff.max()) if not rank_diff.empty else None,
            'mean_rank_diff': float(rank_diff.mean()) if not rank_diff.empty else None,
            'perfect_rank_match': int((rank_diff == 0).sum()) if not rank_diff.empty else 0
        },
        'special_handling': {
            'financial_stocks_prod': len(financial_stocks_prod),
            'financial_stocks_research': len(financial_stocks_research),
            'consistent_financial': len(set(financial_stocks_prod) & set(financial_stocks_research))
        }
    }
    
    # æ‰“å°è¯¦ç»†åˆ†æ
    print(f"\nPè¯„åˆ†åˆ†æ:")
    print(f"  æœ€å¤§å·®å¼‚: {results['p_score_analysis']['max_diff']:.6f}")
    print(f"  å¹³å‡å·®å¼‚: {results['p_score_analysis']['mean_diff']:.6f}")
    print(f"  å·®å¼‚æ ‡å‡†å·®: {results['p_score_analysis']['std_diff']:.6f}")
    print(f"  ç”Ÿäº§çº§å¹³å‡åˆ†: {results['p_score_analysis']['production_mean']:.2f}")
    print(f"  ç ”ç©¶ç›®å½•å¹³å‡åˆ†: {results['p_score_analysis']['research_mean']:.2f}")
    
    print(f"\næ’ååˆ†æ:")
    print(f"  æœ€å¤§æ’åå·®å¼‚: {results['ranking_analysis']['max_rank_diff']}")
    print(f"  å¹³å‡æ’åå·®å¼‚: {results['ranking_analysis']['mean_rank_diff']:.2f}")
    print(f"  å®Œå…¨ç›¸åŒæ’å: {results['ranking_analysis']['perfect_rank_match']} åª")
    
    print(f"\nç‰¹æ®Šå¤„ç†åˆ†æ:")
    print(f"  ç”Ÿäº§çº§é‡‘èè‚¡: {results['special_handling']['financial_stocks_prod']} åª")
    print(f"  ç ”ç©¶ç›®å½•é‡‘èè‚¡: {results['special_handling']['financial_stocks_research']} åª")
    print(f"  ä¸€è‡´çš„é‡‘èè‚¡: {results['special_handling']['consistent_financial']} åª")
    
    # åˆ¤æ–­æ•´ä½“ä¸€è‡´æ€§
    tolerance = 1e-6
    is_consistent = (
        results['p_score_analysis']['max_diff'] is not None and
        results['p_score_analysis']['max_diff'] < tolerance and
        results['total_stocks']['only_production'] == 0 and
        results['total_stocks']['only_research'] == 0
    )
    
    results['is_consistent'] = is_consistent
    
    if is_consistent:
        print(f"\nâœ… å…¨å¸‚åœºè®¡ç®—ç»“æœå®Œå…¨ä¸€è‡´ï¼")
    else:
        print(f"\nâš ï¸ å…¨å¸‚åœºè®¡ç®—ç»“æœå­˜åœ¨å·®å¼‚")
    
    return results


def main():
    parser = argparse.ArgumentParser(description='På› å­å…¨å¸‚åœºä¸€è‡´æ€§éªŒè¯')
    parser.add_argument('--test_date', type=str, help='æŒ‡å®šæµ‹è¯•æ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--auto_date', action='store_true', help='è‡ªåŠ¨é€‰æ‹©éšæœºå‘¨äº”')
    parser.add_argument('--max_stocks', type=int, default=None, help='é™åˆ¶æœ€å¤§è‚¡ç¥¨æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰')
    
    args = parser.parse_args()
    
    # ç¡®å®šæµ‹è¯•æ—¥æœŸ
    if args.auto_date:
        test_date = get_random_friday()
    elif args.test_date:
        test_date = args.test_date
    else:
        test_date = get_random_friday()  # é»˜è®¤éšæœºé€‰æ‹©
    
    print("ğŸ”¬ På› å­å…¨å¸‚åœºä¸€è‡´æ€§éªŒè¯")
    print("=" * 60)
    print(f"æµ‹è¯•æ—¥æœŸ: {test_date}")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # è·å–æ‰€æœ‰è‚¡ç¥¨
    all_stocks = get_all_trading_stocks(test_date)
    if not all_stocks:
        print("âŒ æœªèƒ½è·å–è‚¡ç¥¨åˆ—è¡¨")
        return
    
    # é™åˆ¶è‚¡ç¥¨æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    if args.max_stocks and len(all_stocks) > args.max_stocks:
        all_stocks = random.sample(all_stocks, args.max_stocks)
        print(f"é™åˆ¶ä¸º {args.max_stocks} åªè‚¡ç¥¨è¿›è¡Œæµ‹è¯•")
    
    print(f"æ€»è‚¡ç¥¨æ•°: {len(all_stocks)} åª")
    
    # æ¸…ç†ç°æœ‰æ•°æ®
    print(f"\næ¸…ç†æµ‹è¯•æ—¥æœŸ {test_date} çš„ç°æœ‰På› å­æ•°æ®...")
    try:
        prod_calc = ProductionPFactorCalculator()
        prod_calc.db_manager.execute_sync(
            "DELETE FROM pgs_factors.p_factor WHERE calc_date = %s", 
            (test_date,)
        )
        print("å·²æ¸…ç†æ—§æ•°æ®")
    except Exception as e:
        print(f"æ¸…ç†æ•°æ®å¤±è´¥: {e}")
    
    # è¿è¡Œç”Ÿäº§çº§è®¡ç®—
    prod_df = run_production_full_calculation(test_date, all_stocks)
    
    # å¤‡ä»½ç”Ÿäº§çº§ç»“æœ
    prod_backup = prod_df.copy() if not prod_df.empty else pd.DataFrame()
    
    # æ¸…ç†æ•°æ®å‡†å¤‡ç ”ç©¶ç›®å½•è®¡ç®—
    if not prod_df.empty:
        print(f"\næ¸…ç†æ•°æ®ï¼Œå‡†å¤‡ç ”ç©¶ç›®å½•è®¡ç®—...")
        try:
            prod_calc.db_manager.execute_sync(
                "DELETE FROM pgs_factors.p_factor WHERE calc_date = %s", 
                (test_date,)
            )
        except Exception as e:
            print(f"æ¸…ç†æ•°æ®å¤±è´¥: {e}")
    
    # è¿è¡Œç ”ç©¶ç›®å½•è®¡ç®—
    research_df = run_research_full_calculation(test_date, all_stocks)
    
    # åˆ†æç»“æœ
    if not prod_backup.empty and not research_df.empty:
        analysis = analyze_full_market_results(prod_backup, research_df)
        
        print("\n" + "=" * 60)
        print("ğŸ¯ å…¨å¸‚åœºéªŒè¯ç»“æœæ€»ç»“")
        print("=" * 60)
        
        if analysis.get('is_consistent', False):
            print("ğŸ‰ På› å­å…¨å¸‚åœºè®¡ç®—å®Œå…¨ä¸€è‡´ï¼")
            print("âœ… ç”Ÿäº§ç¯å¢ƒå¯ä»¥å®‰å…¨æŠ•å…¥ä½¿ç”¨")
        else:
            print("âš ï¸ æ£€æµ‹åˆ°å·®å¼‚ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†æ")
        
        print(f"\nå…³é”®æŒ‡æ ‡:")
        print(f"  æµ‹è¯•è‚¡ç¥¨æ•°: {len(all_stocks)}")
        print(f"  æˆåŠŸè®¡ç®—æ•°: {analysis['total_stocks']['common']}")
        print(f"  Pè¯„åˆ†æœ€å¤§å·®å¼‚: {analysis['p_score_analysis']['max_diff']:.8f}")
        print(f"  æ’åæœ€å¤§å·®å¼‚: {analysis['ranking_analysis']['max_rank_diff']}")
        print(f"  å®Œå…¨ç›¸åŒæ’åæ¯”ä¾‹: {analysis['ranking_analysis']['perfect_rank_match']}/{analysis['total_stocks']['common']} ({analysis['ranking_analysis']['perfect_rank_match']/max(analysis['total_stocks']['common'], 1)*100:.1f}%)")
        
    else:
        print("\nâŒ éªŒè¯å¤±è´¥ï¼Œæ— æ³•è·å–æœ‰æ•ˆçš„è®¡ç®—ç»“æœ")
    
    print(f"\nç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    main()
