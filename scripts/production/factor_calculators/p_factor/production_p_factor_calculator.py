#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç”Ÿäº§çº§På› å­è®¡ç®—å™¨ (PITåŸåˆ™ + æ ‡å‡†åŒ–è¿ç»­è¯„åˆ†åˆ¶ + è¡Œä¸šç‰¹æ®Šå¤„ç†)
===============================================================================

ä¸¥æ ¼éµå¾ªPoint-in-TimeåŸåˆ™ï¼Œä½¿ç”¨é¢„è®¡ç®—è´¢åŠ¡æŒ‡æ ‡è¡¨å®ç°é«˜æ€§èƒ½På› å­è®¡ç®—ã€‚
é›†æˆæ ‡å‡†åŒ–è¿ç»­è¯„åˆ†åˆ¶å’Œè¡Œä¸šåˆ†ç±»ç‰¹æ®Šå¤„ç†ï¼Œæå‡è¯„åˆ†ç²¾ç¡®åº¦å’Œåˆç†æ€§ã€‚

ğŸš€ æ ¸å¿ƒä¼˜åŒ– (v2.0):
1. **æ ‡å‡†åŒ–è¿ç»­è¯„åˆ†åˆ¶**: æ›¿æ¢åˆ†æ¡£è¯„åˆ†ï¼Œä½¿ç”¨å¼‚å¸¸å€¼æˆªæ–­+åˆ†ä½æ•°æ’å+æƒé‡åˆæˆ
2. **æ•°æ®æ—¶æ•ˆæ€§ç­›é€‰**: æ’é™¤end_dateè·ç¦»calc_dateè¶…è¿‡10ä¸ªæœˆçš„è‚¡ç¥¨
3. **æ¨ªæˆªé¢æ ‡å‡†åŒ–**: ç¡®ä¿æ‰€æœ‰æ´»è·ƒè‚¡ç¥¨çš„å…¬å¹³æ¯”è¾ƒ
4. **æƒé‡ä¼˜åŒ–**: GPA(40%) + ROE_EXCL(30%) + ROA_EXCL(30%)

ğŸ“Š è¯„åˆ†æœºåˆ¶:
- å¼‚å¸¸å€¼æˆªæ–­: ä½¿ç”¨1%å’Œ99%åˆ†ä½æ•°
- æ ‡å‡†åŒ–æ–¹æ³•: åˆ†ä½æ•°æ’å (0-100ç™¾åˆ†ä½)
- è¯„åˆ†èŒƒå›´: 0-100è¿ç»­è¯„åˆ† (æ›¿ä»£åŸ18æ¡£åˆ†æ¡£åˆ¶)
- é‡‘èè‚¡ç‰¹æ®Šå¤„ç†: GPA=NULLæ—¶ï¼ŒROE(50%)+ROA(50%)

âš¡ æ€§èƒ½å¯¹æ¯”:
- åŸç‰ˆè®¡ç®—å™¨: 133åª/ç§’ (åˆ†æ¡£è¯„åˆ†åˆ¶)
- ç”Ÿäº§çº§ç‰ˆæœ¬: 300-500åª/ç§’ (æ ‡å‡†åŒ–è¿ç»­è¯„åˆ†åˆ¶)

ğŸ¯ PITåŸåˆ™æ ¸å¿ƒ:
1. åœ¨æŒ‡å®šæ—¶ç‚¹(as_of_date)ï¼Œåªèƒ½çœ‹åˆ°è¯¥æ—¶ç‚¹ä¹‹å‰æˆ–å½“æ—¥å…¬å‘Šçš„æ•°æ®
2. ann_dateæ˜¯çœŸå®çš„å…¬å‘Šæ—¥æœŸï¼Œä¸¥æ ¼ä¿æŒä¸å˜
3. æŸ¥è¯¢æ¡ä»¶: ann_date <= as_of_date AND end_date >= (calc_date - 10ä¸ªæœˆ)

ğŸ­ è¡Œä¸šç‰¹æ®Šå¤„ç†:
1. é“¶è¡Œä¸š: GPAè®¾ä¸ºNULL (è¥ä¸šæˆæœ¬ä¸º0å¯¼è‡´GPA=100%è¯¯å¯¼)
2. è¯åˆ¸ä¸š: GPAè®¾ä¸ºNULL (æˆæœ¬ç»“æ„ç‰¹æ®Š)
3. ä¿é™©ä¸š: GPAè®¾ä¸ºNULL (æˆæœ¬ç»“æ„ç‰¹æ®Š)
4. å…¶ä»–è¡Œä¸š: æ ‡å‡†GPAè®¡ç®—

ğŸ”§ æŠ€æœ¯ä¼˜åŒ–:
1. ç›´æ¥æŸ¥è¯¢é¢„è®¡ç®—çš„è´¢åŠ¡æŒ‡æ ‡ï¼Œæ— éœ€å®æ—¶è®¡ç®—TTM
2. å•è¡¨æŸ¥è¯¢æ›¿ä»£å¤šè¡¨JOIN
3. å‘é‡åŒ–æ ‡å‡†åŒ–å¤„ç†å’ŒPè¯„åˆ†è®¡ç®—
4. å‡å°‘æ•°æ®ä¼ è¾“é‡å’Œè®¡ç®—å¤æ‚åº¦
5. é›†æˆPITè¡Œä¸šåˆ†ç±»æŸ¥è¯¢ï¼Œæ”¯æŒè¡Œä¸šç‰¹æ®Šå¤„ç†

Author: AlphaHome Team (è¿ç§»è‡ªresearch/pgs_factor)
Date: 2025-09-17 (è¿ç§»åˆ°ç”Ÿäº§ç¯å¢ƒ)
"""

import sys
import os
import logging
import pandas as pd
import numpy as np
from datetime import datetime
from typing import List, Optional, Dict, Any
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.append(str(project_root))

from alphahome.common.db_manager import DBManager
from alphahome.common.config_manager import ConfigManager


class ProductionPFactorCalculator:
    """ç”Ÿäº§çº§På› å­è®¡ç®—å™¨ (åŸºäºé¢„è®¡ç®—è¡¨çš„é«˜æ€§èƒ½å®ç°)"""
    
    def __init__(self):
        """åˆå§‹åŒ–è®¡ç®—å™¨"""
        self.config_manager = ConfigManager()
        # è·å–æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²
        connection_string = self.config_manager.get_database_url()
        if not connection_string:
            raise ValueError("æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²æœªé…ç½®ï¼Œè¯·è®¾ç½®config.jsonæˆ–ç¯å¢ƒå˜é‡DATABASE_URL")
        self.db_manager = DBManager(connection_string, mode='sync')  # ä½¿ç”¨åŒæ­¥æ¨¡å¼
        self.logger = self._setup_logger()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'query_time': 0,
            'calculation_time': 0,
            'save_time': 0,
            'total_time': 0
        }
    
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger('ProductionPFactorCalculator')
        logger.setLevel(logging.INFO)
        return logger
    
    def calculate_p_factors_pit(
        self,
        as_of_date: str,
        stock_codes: List[str]
    ) -> Dict[str, Any]:
        """åŸºäºPITåŸåˆ™çš„På› å­è®¡ç®—

        Args:
            as_of_date: PITæˆªæ­¢æ—¥æœŸ (åœ¨æ­¤æ—¶ç‚¹èƒ½çœ‹åˆ°çš„æ‰€æœ‰å·²å…¬å‘Šæ•°æ®)
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨

        Returns:
            è®¡ç®—ç»“æœç»Ÿè®¡
        """
        start_time = time.time()

        self.logger.info(f"å¼€å§‹åŸºäºPITåŸåˆ™çš„På› å­è®¡ç®—: {as_of_date}")
        self.logger.info(f"è‚¡ç¥¨æ•°é‡: {len(stock_codes)}")

        # 1. æŸ¥è¯¢é¢„è®¡ç®—çš„è´¢åŠ¡æŒ‡æ ‡ (ä¸¥æ ¼éµå¾ªPITåŸåˆ™)
        query_start = time.time()
        indicators_data = self._get_precomputed_indicators_pit(as_of_date, stock_codes)
        self.stats['query_time'] = time.time() - query_start

        if indicators_data.empty:
            self.logger.warning(f"åœ¨æ—¶ç‚¹ {as_of_date} æœªæ‰¾åˆ°é¢„è®¡ç®—çš„è´¢åŠ¡æŒ‡æ ‡æ•°æ®")
            return {'success_count': 0, 'failed_count': len(stock_codes)}

        self.logger.info(f"æŸ¥è¯¢åˆ° {len(indicators_data)} æ¡é¢„è®¡ç®—æŒ‡æ ‡ (PITæ—¶ç‚¹: {as_of_date})")

        # 2. å¿«é€Ÿè®¡ç®—På› å­ (ä¿æŒann_dateä¸å˜)
        calc_start = time.time()
        p_factors = self._calculate_p_factors_from_indicators_pit(indicators_data, as_of_date)
        self.stats['calculation_time'] = time.time() - calc_start

        # 3. ä¿å­˜På› å­ç»“æœ
        save_start = time.time()
        success_count = 0
        if not p_factors.empty:
            self._save_p_factors(p_factors)
            success_count = len(p_factors)
        self.stats['save_time'] = time.time() - save_start

        # 4. ç»Ÿè®¡ç»“æœ
        self.stats['total_time'] = time.time() - start_time
        failed_count = len(stock_codes) - success_count

        self._log_performance_stats(success_count, failed_count)

        return {
            'success_count': success_count,
            'failed_count': failed_count,
            'total_time': self.stats['total_time'],
            'performance_stats': self.stats.copy()
        }
    
    def calculate_p_factors_batch_pit(
        self,
        start_date: str,
        end_date: str,
        mode: Optional[str] = None
    ) -> Dict[str, Any]:
        """åŸºäºæ—¥æœŸèŒƒå›´çš„æ‰¹é‡På› å­è®¡ç®—

        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            mode: æ‰§è¡Œæ¨¡å¼ ('incremental', 'backfill', Noneä¸ºè‡ªåŠ¨æ£€æµ‹)

        Returns:
            æ‰§è¡Œç»“æœç»Ÿè®¡
        """
        self.logger.info(f"å¼€å§‹æ‰¹é‡På› å­è®¡ç®—: {start_date} ~ {end_date}")

        # 1. æ™ºèƒ½æ¨¡å¼æ£€æµ‹
        if mode:
            execution_mode = mode
            self.logger.info(f"ä½¿ç”¨æŒ‡å®šæ¨¡å¼: {execution_mode}")
        else:
            execution_mode = self.detect_execution_mode(start_date, end_date)

        # 2. ç”Ÿæˆè®¡ç®—æ—¥æœŸåˆ—è¡¨
        calc_dates = self.generate_calculation_dates(start_date, end_date, execution_mode)

        if not calc_dates:
            self.logger.warning("æœªæ‰¾åˆ°éœ€è¦è®¡ç®—çš„æ—¥æœŸ")
            return {
                'success_count': 0,
                'failed_count': 0,
                'total_time': 0,
                'throughput': 0,
                'total_dates': 0,
                'successful_dates': 0,
                'failed_dates': 0,
                'total_stocks_processed': 0,
                'total_records_saved': 0
            }

        self.logger.info(f"å…±éœ€è®¡ç®— {len(calc_dates)} ä¸ªæ—¥æœŸ")

        # 3. æ‰§è¡Œæ‰¹é‡è®¡ç®—
        total_start = time.time()
        total_success = 0
        total_failed = 0
        successful_dates = 0

        for i, calc_date in enumerate(calc_dates, 1):
            self.logger.info(f"\nè¿›åº¦: [{i}/{len(calc_dates)}] å¤„ç†æ—¥æœŸ: {calc_date}")

            try:
                # è·å–åœ¨äº¤æ˜“è‚¡ç¥¨åˆ—è¡¨
                stock_codes = self._get_trading_stock_codes(calc_date)

                if not stock_codes:
                    self.logger.warning(f"{calc_date} æœªæ‰¾åˆ°åœ¨äº¤æ˜“è‚¡ç¥¨")
                    continue

                # æ‰§è¡ŒPå› å­è®¡ç®—
                result = self.calculate_p_factors_pit(calc_date, stock_codes)
                total_success += result['success_count']
                total_failed += result['failed_count']

                if result['success_count'] > 0:
                    successful_dates += 1

                self.logger.info(f"{calc_date} è®¡ç®—å®Œæˆ: æˆåŠŸ {result['success_count']}, å¤±è´¥ {result['failed_count']}")

            except Exception as e:
                self.logger.error(f"{calc_date} è®¡ç®—å¤±è´¥: {e}")
                if 'stock_codes' in locals():
                    total_failed += len(stock_codes)

        total_time = time.time() - total_start

        self.logger.info("=" * 50)
        self.logger.info("æ‰¹é‡På› å­è®¡ç®—å®Œæˆ")
        self.logger.info("=" * 50)
        self.logger.info(f"æ€»è€—æ—¶: {total_time:.2f} ç§’")
        self.logger.info(f"æ€»æˆåŠŸ: {total_success}")
        self.logger.info(f"æ€»å¤±è´¥: {total_failed}")

        if total_time > 0:
            throughput = total_success / total_time
            self.logger.info(f"ååé‡: {throughput:.1f} åª/ç§’")

        return {
            'success_count': total_success,
            'failed_count': total_failed,
            'total_time': total_time,
            'throughput': total_success / total_time if total_time > 0 else 0,
            'total_dates': len(calc_dates),
            'successful_dates': successful_dates,
            'failed_dates': len(calc_dates) - successful_dates,
            'total_stocks_processed': total_success + total_failed,
            'total_records_saved': total_success
        }

    def detect_execution_mode(self, start_date: str, end_date: str) -> str:
        """æ™ºèƒ½æ£€æµ‹æ‰§è¡Œæ¨¡å¼

        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            æ‰§è¡Œæ¨¡å¼ ('incremental' æˆ– 'backfill')
        """
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰çš„På› å­æ•°æ®
            query = """
            SELECT COUNT(*) as count
            FROM pgs_factors.p_factor
            WHERE calc_date BETWEEN %s AND %s
            """

            result = self.db_manager.fetch_one_sync(query, (start_date, end_date))

            if result[0] == 0:
                self.logger.info("æœªå‘ç°ç°æœ‰På› å­æ•°æ®ï¼Œä½¿ç”¨backfillæ¨¡å¼")
                return 'backfill'
            else:
                self.logger.info(f"å‘ç° {result[0]} æ¡ç°æœ‰På› å­æ•°æ®ï¼Œä½¿ç”¨incrementalæ¨¡å¼")
                return 'incremental'

        except Exception as e:
            self.logger.warning(f"æ£€æµ‹æ‰§è¡Œæ¨¡å¼å¤±è´¥: {e}ï¼Œé»˜è®¤ä½¿ç”¨incrementalæ¨¡å¼")
            return 'incremental'

    def generate_calculation_dates(self, start_date: str, end_date: str, mode: str) -> List[str]:
        """ç”Ÿæˆè®¡ç®—æ—¥æœŸåˆ—è¡¨

        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            mode: æ‰§è¡Œæ¨¡å¼

        Returns:
            è®¡ç®—æ—¥æœŸåˆ—è¡¨
        """
        # ç”Ÿæˆæ‰€æœ‰å‘¨äº”æ—¥æœŸ
        all_fridays = self._generate_friday_dates(start_date, end_date)

        if mode == 'backfill':
            # å›å¡«æ¨¡å¼ï¼šè®¡ç®—æ‰€æœ‰æ—¥æœŸ
            return all_fridays
        elif mode == 'incremental':
            # å¢é‡æ¨¡å¼ï¼šåªè®¡ç®—ç¼ºå¤±çš„æ—¥æœŸ
            return self._filter_missing_dates(all_fridays)
        else:
            self.logger.warning(f"æœªçŸ¥æ‰§è¡Œæ¨¡å¼: {mode}ï¼Œä½¿ç”¨å¢é‡æ¨¡å¼")
            return self._filter_missing_dates(all_fridays)

    def _generate_friday_dates(self, start_date: str, end_date: str) -> List[str]:
        """ç”ŸæˆæŒ‡å®šèŒƒå›´å†…çš„æ‰€æœ‰å‘¨äº”æ—¥æœŸ

        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            å‘¨äº”æ—¥æœŸåˆ—è¡¨
        """
        from datetime import datetime, timedelta

        start = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.strptime(end_date, '%Y-%m-%d')

        fridays = []
        current = start

        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå‘¨äº”
        while current.weekday() != 4:  # 4 = å‘¨äº”
            current += timedelta(days=1)
            if current > end:
                break

        # æ”¶é›†æ‰€æœ‰å‘¨äº”
        while current <= end:
            fridays.append(current.strftime('%Y-%m-%d'))
            current += timedelta(days=7)

        return fridays

    def _filter_missing_dates(self, dates: List[str]) -> List[str]:
        """è¿‡æ»¤å‡ºç¼ºå¤±På› å­æ•°æ®çš„æ—¥æœŸ

        Args:
            dates: å€™é€‰æ—¥æœŸåˆ—è¡¨

        Returns:
            ç¼ºå¤±æ•°æ®çš„æ—¥æœŸåˆ—è¡¨
        """
        if not dates:
            return []

        try:
            # æŸ¥è¯¢å·²æœ‰æ•°æ®çš„æ—¥æœŸ
            query = """
            SELECT DISTINCT calc_date
            FROM pgs_factors.p_factor
            WHERE calc_date = ANY(%s)
            """

            results = self.db_manager.fetch_sync(query, (dates,))
            existing_dates = {row[0].strftime('%Y-%m-%d') for row in results}

            missing_dates = [date for date in dates if date not in existing_dates]

            self.logger.info(f"æ€»æ—¥æœŸ: {len(dates)}, å·²æœ‰æ•°æ®: {len(existing_dates)}, ç¼ºå¤±æ•°æ®: {len(missing_dates)}")

            return missing_dates

        except Exception as e:
            self.logger.error(f"è¿‡æ»¤ç¼ºå¤±æ—¥æœŸå¤±è´¥: {e}")
            return dates

    def _get_trading_stock_codes(self, calc_date: str) -> List[str]:
        """è·å–æŒ‡å®šæ—¥æœŸçš„åœ¨äº¤æ˜“è‚¡ç¥¨åˆ—è¡¨

        Args:
            calc_date: è®¡ç®—æ—¥æœŸ

        Returns:
            åœ¨äº¤æ˜“è‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        try:
            query = """
            SELECT ts_code
            FROM tushare.stock_basic
            WHERE list_date <= %s
            AND (delist_date IS NULL OR delist_date > %s)
            ORDER BY ts_code
            """

            results = self.db_manager.fetch_sync(query, (calc_date, calc_date))
            stock_codes = [row[0] for row in results]

            self.logger.info(f"{calc_date} è·å–åˆ° {len(stock_codes)} åªåœ¨äº¤æ˜“è‚¡ç¥¨")
            return stock_codes

        except Exception as e:
            self.logger.error(f"è·å– {calc_date} è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def _get_precomputed_indicators_pit(self, as_of_date: str, stock_codes: List[str]) -> pd.DataFrame:
        """åŸºäºPITåŸåˆ™æŸ¥è¯¢é¢„è®¡ç®—çš„è´¢åŠ¡æŒ‡æ ‡

        Args:
            as_of_date: PITæˆªæ­¢æ—¥æœŸ
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨

        Returns:
            è´¢åŠ¡æŒ‡æ ‡æ•°æ®
        """
        try:
            query = """
            WITH latest_indicators AS (
                SELECT
                    pit.ts_code,
                    pit.end_date,
                    pit.ann_date,
                    pit.data_source,
                    pit.gpa_ttm,
                    pit.roe_excl_ttm,
                    pit.roa_excl_ttm,
                    pit.net_margin_ttm,
                    pit.operating_margin_ttm,
                    pit.roi_ttm,
                    pit.asset_turnover_ttm,
                    pit.equity_multiplier,
                    pit.debt_to_asset_ratio,
                    pit.equity_ratio,
                    pit.revenue_yoy_growth,
                    pit.n_income_yoy_growth,
                    pit.operate_profit_yoy_growth,
                    pit.data_quality,
                    pit.calculation_status,
                    ROW_NUMBER() OVER (PARTITION BY pit.ts_code ORDER BY pit.ann_date DESC, pit.end_date DESC) as rn
                FROM pgs_factors.pit_financial_indicators pit
                INNER JOIN tushare.stock_basic sb ON pit.ts_code = sb.ts_code
                WHERE pit.ann_date <= %s  -- PITåŸåˆ™
                AND pit.ts_code = ANY(%s)
                AND pit.calculation_status = 'success'
                AND pit.data_quality IN ('high', 'normal', 'outlier_high', 'outlier_low')
                AND pit.end_date >= (%s::date - INTERVAL '10 months')
                AND sb.list_date <= %s
                AND (sb.delist_date IS NULL OR sb.delist_date > %s)
            )
            SELECT
                ts_code, end_date, ann_date, data_source,
                gpa_ttm, roe_excl_ttm, roa_excl_ttm,
                net_margin_ttm, operating_margin_ttm, roi_ttm,
                asset_turnover_ttm, equity_multiplier,
                debt_to_asset_ratio, equity_ratio,
                revenue_yoy_growth, n_income_yoy_growth, operate_profit_yoy_growth,
                data_quality, calculation_status
            FROM latest_indicators
            WHERE rn = 1
            ORDER BY ts_code
            """

            # ä½¿ç”¨åŒæ­¥æŸ¥è¯¢æ–¹æ³•
            results = self.db_manager.fetch_sync(query, (
                as_of_date, stock_codes, as_of_date, as_of_date, as_of_date
            ))
            
            if results:
                # è½¬æ¢ä¸ºDataFrame
                columns = [
                    'ts_code', 'end_date', 'ann_date', 'data_source',
                    'gpa_ttm', 'roe_excl_ttm', 'roa_excl_ttm',
                    'net_margin_ttm', 'operating_margin_ttm', 'roi_ttm',
                    'asset_turnover_ttm', 'equity_multiplier',
                    'debt_to_asset_ratio', 'equity_ratio',
                    'revenue_yoy_growth', 'n_income_yoy_growth', 'operate_profit_yoy_growth',
                    'data_quality', 'calculation_status'
                ]
                df = pd.DataFrame(results, columns=columns)
            else:
                df = pd.DataFrame()

            if not df.empty:
                excluded_count = len(stock_codes) - len(df)
                if excluded_count > 0:
                    self.logger.info(f"æ•°æ®ç­›é€‰: æ’é™¤äº† {excluded_count} åªè‚¡ç¥¨")

            return df

        except Exception as e:
            self.logger.error(f"æŸ¥è¯¢é¢„è®¡ç®—æŒ‡æ ‡å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _calculate_p_factors_from_indicators_pit(
        self,
        indicators_data: pd.DataFrame,
        as_of_date: str
    ) -> pd.DataFrame:
        """åŸºäºé¢„è®¡ç®—æŒ‡æ ‡å’ŒPITåŸåˆ™å¿«é€Ÿè®¡ç®—På› å­

        Args:
            indicators_data: é¢„è®¡ç®—çš„è´¢åŠ¡æŒ‡æ ‡æ•°æ®
            as_of_date: PITæˆªæ­¢æ—¥æœŸ

        Returns:
            På› å­ç»“æœDataFrame
        """
        if indicators_data.empty:
            return pd.DataFrame()

        # å¤åˆ¶æ•°æ®é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        df = indicators_data.copy()

        # æ·»åŠ è®¡ç®—æ—¥æœŸ
        df['calc_date'] = as_of_date

        self.logger.info(f"å¼€å§‹æ ‡å‡†åŒ–å¤„ç† {len(df)} åªè‚¡ç¥¨çš„è´¢åŠ¡æŒ‡æ ‡")

        # 1. è´¢åŠ¡æŒ‡æ ‡æ ‡å‡†åŒ–å¤„ç†
        df = self._standardize_financial_indicators(df)

        # 2. å‘é‡åŒ–è®¡ç®—Pè¯„åˆ†
        df['p_score'] = self._calculate_p_score_vectorized(df)

        # 3. è®¡ç®—Pæ’å
        df['p_score'] = df['p_score'].fillna(0)
        df['p_score'] = df['p_score'].replace([np.inf, -np.inf], [100, 0])
        df['p_rank'] = df['p_score'].rank(method='min', ascending=False, na_option='bottom').astype(int)

        # 4. æ˜ å°„è´¢åŠ¡æŒ‡æ ‡åˆ°På› å­è¡¨å­—æ®µ
        df['gpa'] = df['gpa_ttm']
        df['roe_excl'] = df['roe_excl_ttm']
        df['roa_excl'] = df['roa_excl_ttm']

        # 5. åº”ç”¨è¡Œä¸šç‰¹æ®Šå¤„ç†
        df = self._apply_industry_special_handling(df, as_of_date)

        # 6. é‡æ–°è®¡ç®—å—è¡Œä¸šç‰¹æ®Šå¤„ç†å½±å“çš„Pè¯„åˆ†å’Œæ’å
        affected_stocks = df[df['gpa'].isna()]['ts_code'].unique()
        if len(affected_stocks) > 0:
            self.logger.info(f"é‡æ–°è®¡ç®— {len(affected_stocks)} åªé‡‘èè‚¡çš„Pè¯„åˆ† (GPA=NULL)")
            
            # å¯¹äºGPAä¸ºNULLçš„è‚¡ç¥¨ï¼Œé‡æ–°è¿›è¡Œè¯„åˆ†è®¡ç®—
            mask_null_gpa = df['gpa'].isna()
            
            for idx in df[mask_null_gpa].index:
                roe_score = df.loc[idx, 'roe_excl_ttm_standardized'] if 'roe_excl_ttm_standardized' in df.columns else 0
                roa_score = df.loc[idx, 'roa_excl_ttm_standardized'] if 'roa_excl_ttm_standardized' in df.columns else 0
                
                # é‡‘èè‚¡Pè¯„åˆ† = ROE(50%) + ROA(50%)
                df.loc[idx, 'p_score'] = (roe_score * 0.5 + roa_score * 0.5)
            
            # é‡æ–°è®¡ç®—æ’å
            df['p_score'] = df['p_score'].fillna(0)
            df['p_score'] = df['p_score'].replace([np.inf, -np.inf], [100, 0])
            df['p_rank'] = df['p_score'].rank(method='min', ascending=False, na_option='bottom').astype(int)

        # é€‰æ‹©è¾“å‡ºåˆ—
        output_columns = [
            'ts_code', 'calc_date', 'ann_date', 'end_date', 'data_source',
            'p_score', 'p_rank',
            'gpa', 'roe_excl', 'roa_excl',
            'net_margin_ttm', 'operating_margin_ttm', 'roi_ttm',
            'asset_turnover_ttm', 'equity_multiplier',
            'debt_to_asset_ratio', 'equity_ratio',
            'revenue_yoy_growth', 'n_income_yoy_growth', 'operate_profit_yoy_growth',
            'data_quality', 'calculation_status'
        ]

        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
        for col in output_columns:
            if col not in df.columns:
                df[col] = None

        self.logger.info(f"På› å­è®¡ç®—å®Œæˆ: å¹³å‡è¯„åˆ† {df['p_score'].mean():.2f}")

        return df[output_columns]

    def _apply_industry_special_handling(self, df: pd.DataFrame, as_of_date: str) -> pd.DataFrame:
        """åº”ç”¨è¡Œä¸šç‰¹æ®Šå¤„ç†é€»è¾‘"""
        if df.empty:
            return df

        try:
            # è·å–æ‰€æœ‰è‚¡ç¥¨çš„è¡Œä¸šåˆ†ç±»ä¿¡æ¯
            stock_codes = df['ts_code'].unique().tolist()
            industry_info = self._get_industry_classification_pit(stock_codes, as_of_date)

            if industry_info.empty:
                self.logger.warning(f"æœªæ‰¾åˆ°è‚¡ç¥¨çš„è¡Œä¸šåˆ†ç±»ä¿¡æ¯ï¼Œè·³è¿‡ç‰¹æ®Šå¤„ç†")
                return df

            # åˆå¹¶è¡Œä¸šä¿¡æ¯
            df_with_industry = df.merge(
                industry_info[['ts_code', 'requires_special_gpa_handling', 'gpa_calculation_method']],
                on='ts_code',
                how='left'
            )

            # åº”ç”¨GPAç‰¹æ®Šå¤„ç†
            mask_special_gpa = df_with_industry['requires_special_gpa_handling'] == True
            mask_null_gpa = df_with_industry['gpa_calculation_method'] == 'null'

            # å¯¹éœ€è¦ç‰¹æ®Šå¤„ç†çš„è‚¡ç¥¨ï¼Œå°†GPAè®¾ä¸ºNULL
            df_with_industry.loc[mask_special_gpa & mask_null_gpa, 'gpa'] = None

            # è®°å½•ç‰¹æ®Šå¤„ç†çš„è‚¡ç¥¨
            special_stocks = df_with_industry[mask_special_gpa & mask_null_gpa]['ts_code'].unique()
            if len(special_stocks) > 0:
                self.logger.info(f"å¯¹ {len(special_stocks)} åªé‡‘èè‚¡åº”ç”¨GPAç‰¹æ®Šå¤„ç†: {list(special_stocks)}")

            # ç§»é™¤ä¸´æ—¶åˆ—
            df_result = df_with_industry.drop(['requires_special_gpa_handling', 'gpa_calculation_method'], axis=1)

            return df_result

        except Exception as e:
            self.logger.error(f"åº”ç”¨è¡Œä¸šç‰¹æ®Šå¤„ç†å¤±è´¥: {e}")
            return df

    def _get_industry_classification_pit(self, stock_codes: List[str], as_of_date: str) -> pd.DataFrame:
        """è·å–PITè¡Œä¸šåˆ†ç±»ä¿¡æ¯ (ä¸ç ”ç©¶ç›®å½•ç‰ˆæœ¬ä¸€è‡´)"""
        try:
            # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“ä¸­çš„è¡Œä¸šåˆ†ç±»æ•°æ®
            try:
                # å°è¯•ä½¿ç”¨ä¼˜åŒ–åçš„æ‰¹é‡PITæŸ¥è¯¢å‡½æ•° (ç”³ä¸‡æ•°æ®)
                query = """
                SELECT * FROM get_industry_classification_batch_pit_optimized(%s, %s, 'sw')
                """
                
                results = self.db_manager.fetch_sync(query, (stock_codes, as_of_date))
                
                if results:
                    columns = ['ts_code', 'industry_level1', 'industry_level2', 'industry_level3', 
                              'data_source', 'obs_date']
                    df = pd.DataFrame(results, columns=columns)
                    
                    # åº”ç”¨ä¸ç ”ç©¶ç›®å½•ç‰ˆæœ¬ç›¸åŒçš„é‡‘èè¡Œä¸šè¯†åˆ«é€»è¾‘
                    def is_financial_industry(l1: str, l2: str) -> bool:
                        text = f"{l1 or ''} {l2 or ''}"
                        keywords = ['é“¶è¡Œ', 'è¯åˆ¸', 'ä¿é™©', 'ä¿¡æ‰˜', 'æœŸè´§', 'åŸºé‡‘', 'é‡‘è', 'æŠ•èµ„', 'èµ„äº§ç®¡ç†', 'è´¢åŠ¡å…¬å¸']
                        return any(k in text for k in keywords)
                    
                    df['requires_special_gpa_handling'] = df.apply(
                        lambda r: is_financial_industry(r.get('industry_level1'), r.get('industry_level2')), axis=1
                    )
                    df['gpa_calculation_method'] = df['requires_special_gpa_handling'].apply(
                        lambda x: 'null' if x else 'standard'
                    )
                    
                    self.logger.info(f"ä»æ•°æ®åº“è·å–è¡Œä¸šåˆ†ç±»: {len(df)} åªè‚¡ç¥¨")
                    return df
                    
            except Exception as db_error:
                self.logger.warning(f"æ•°æ®åº“è¡Œä¸šåˆ†ç±»æŸ¥è¯¢å¤±è´¥: {db_error}")
            
            # å›é€€åˆ°åŸºäºTushareè¡Œä¸šæˆå‘˜è¡¨çš„æŸ¥è¯¢
            try:
                query_fallback = """
                SELECT DISTINCT
                    t.ts_code,
                    COALESCE(t.industry_name, 'å…¶ä»–') AS industry_level1,
                    COALESCE(t.industry_name, 'å…¶ä»–') AS industry_level2,
                    COALESCE(t.industry_name, 'å…¶ä»–') AS industry_level3,
                    'tushare' AS data_source,
                    %s AS obs_date
                FROM tushare.index_member t
                WHERE t.ts_code = ANY(%s)
                AND t.out_date IS NULL
                """
                
                results = self.db_manager.fetch_sync(query_fallback, (as_of_date, stock_codes))
                
                if results:
                    columns = ['ts_code', 'industry_level1', 'industry_level2', 'industry_level3', 
                              'data_source', 'obs_date']
                    df = pd.DataFrame(results, columns=columns)
                    
                    # åº”ç”¨é‡‘èè¡Œä¸šè¯†åˆ«é€»è¾‘
                    def is_financial_industry(l1: str, l2: str) -> bool:
                        text = f"{l1 or ''} {l2 or ''}"
                        keywords = ['é“¶è¡Œ', 'è¯åˆ¸', 'ä¿é™©', 'ä¿¡æ‰˜', 'æœŸè´§', 'åŸºé‡‘', 'é‡‘è', 'æŠ•èµ„', 'èµ„äº§ç®¡ç†', 'è´¢åŠ¡å…¬å¸']
                        return any(k in text for k in keywords)
                    
                    df['requires_special_gpa_handling'] = df.apply(
                        lambda r: is_financial_industry(r.get('industry_level1'), r.get('industry_level2')), axis=1
                    )
                    df['gpa_calculation_method'] = df['requires_special_gpa_handling'].apply(
                        lambda x: 'null' if x else 'standard'
                    )
                    
                    self.logger.info(f"ä»Tushareè·å–è¡Œä¸šåˆ†ç±»: {len(df)} åªè‚¡ç¥¨")
                    return df
                    
            except Exception as fallback_error:
                self.logger.warning(f"Tushareè¡Œä¸šåˆ†ç±»æŸ¥è¯¢å¤±è´¥: {fallback_error}")
            
            # æœ€ç»ˆå›é€€ï¼šåŸºäºè‚¡ç¥¨ä»£ç å’Œåç§°çš„å¯å‘å¼è¯†åˆ«
            financial_stocks = []
            for stock in stock_codes:
                # åŸºäºè‚¡ç¥¨ä»£ç å¯å‘å¼è¯†åˆ«é‡‘èè‚¡
                is_financial = self._is_financial_stock_by_code(stock)
                
                financial_stocks.append({
                    'ts_code': stock,
                    'obs_date': as_of_date,
                    'data_source': 'heuristic',
                    'industry_level1': 'é‡‘èä¸š' if is_financial else 'å…¶ä»–',
                    'industry_level2': 'é‡‘èä¸š' if is_financial else 'å…¶ä»–', 
                    'industry_level3': 'é‡‘èä¸š' if is_financial else 'å…¶ä»–',
                    'requires_special_gpa_handling': is_financial,
                    'gpa_calculation_method': 'null' if is_financial else 'standard'
                })
            
            if financial_stocks:
                df = pd.DataFrame(financial_stocks)
                self.logger.warning(f"ä½¿ç”¨å¯å‘å¼æ–¹æ³•è¯†åˆ«è¡Œä¸šåˆ†ç±»: {len(df)} åªè‚¡ç¥¨")
                return df
            else:
                return pd.DataFrame()

        except Exception as e:
            self.logger.error(f"è·å–è¡Œä¸šåˆ†ç±»å¤±è´¥: {e}")
            return pd.DataFrame()

    def _is_financial_stock_by_code(self, stock_code: str) -> bool:
        """åŸºäºè‚¡ç¥¨ä»£ç å¯å‘å¼è¯†åˆ«é‡‘èè‚¡"""
        # å¸¸è§é‡‘èè‚¡ä»£ç ï¼ˆé“¶è¡Œã€ä¿é™©ã€åˆ¸å•†ï¼‰
        financial_codes = {
            # å››å¤§è¡Œ
            '601398.SH', '601939.SH', '601988.SH', '601328.SH',
            # è‚¡ä»½åˆ¶é“¶è¡Œ
            '000001.SZ', '600000.SH', '600036.SH', '601166.SH', '600015.SH', '600016.SH',
            # åŸå•†è¡Œ
            '600054.SH', '600919.SH', '601169.SH', '002142.SZ',
            # ä¿é™©
            '601318.SH', '601601.SH', '601336.SH',
            # åˆ¸å•†  
            '600030.SH', '000166.SZ', '600999.SH', '600837.SH', '601377.SH',
            '600053.SH', '601009.SH', '000783.SZ', '600958.SH'
        }
        return stock_code in financial_codes

    def _standardize_financial_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """è´¢åŠ¡æŒ‡æ ‡æ ‡å‡†åŒ–å¤„ç†"""
        if df.empty:
            return df

        df_result = df.copy()
        indicators = ['gpa_ttm', 'roe_excl_ttm', 'roa_excl_ttm']

        for indicator in indicators:
            if indicator not in df.columns:
                continue

            try:
                df[indicator] = pd.to_numeric(df[indicator], errors='coerce')
                valid_data = df[indicator].dropna()
            except Exception:
                df_result[f'{indicator}_standardized'] = np.nan
                continue

            if len(valid_data) == 0:
                df_result[f'{indicator}_standardized'] = np.nan
                continue

            # å¼‚å¸¸å€¼æˆªæ–­
            p1 = float(valid_data.quantile(0.01))
            p99 = float(valid_data.quantile(0.99))
            clipped_values = df[indicator].clip(lower=p1, upper=p99)

            # åˆ†ä½æ•°æ’åæ ‡å‡†åŒ–
            ranks = clipped_values.rank(method='average', na_option='keep')
            max_rank = ranks.max()

            if max_rank > 1:
                percentile_scores = (ranks - 1) / (max_rank - 1) * 100
            else:
                percentile_scores = pd.Series(50.0, index=df.index)

            df_result[f'{indicator}_standardized'] = percentile_scores

        return df_result

    def _calculate_p_score_vectorized(self, df: pd.DataFrame) -> pd.Series:
        """å‘é‡åŒ–è®¡ç®—Pè¯„åˆ†"""
        if df.empty:
            return pd.Series(dtype=float)

        weights = {
            'gpa_ttm_standardized': 0.40,
            'roe_excl_ttm_standardized': 0.30,
            'roa_excl_ttm_standardized': 0.30
        }

        p_scores = pd.Series(0.0, index=df.index)
        total_weight = 0.0

        for indicator, weight in weights.items():
            if indicator in df.columns:
                indicator_scores = df[indicator].fillna(0)
                p_scores += indicator_scores * weight
                total_weight += weight

        if total_weight > 0 and total_weight != 1.0:
            p_scores = p_scores / total_weight

        p_scores = p_scores.clip(lower=0, upper=100)
        return p_scores
    
    def _save_p_factors(self, p_factors: pd.DataFrame) -> None:
        """å¿«é€Ÿä¿å­˜På› å­ç»“æœ"""
        if p_factors.empty:
            return

        calc_date = p_factors['calc_date'].iloc[0]

        # å…ˆåˆ é™¤æ—§æ•°æ®
        delete_sql = """
        DELETE FROM pgs_factors.p_factor
        WHERE calc_date = %s
        """

        # å…ˆåˆ é™¤æ—§æ•°æ®
        self.db_manager.execute_sync(delete_sql, (calc_date,))
        
        # æ‰¹é‡æ’å…¥æ–°æ•°æ®
        insert_query = """
        INSERT INTO pgs_factors.p_factor (
            ts_code, calc_date, ann_date, end_date, data_source,
            p_score, p_rank,
            gpa, roe_excl, roa_excl,
            net_margin_ttm, operating_margin_ttm, roi_ttm,
            asset_turnover_ttm, equity_multiplier,
            debt_to_asset_ratio, equity_ratio,
            revenue_yoy_growth, n_income_yoy_growth, operate_profit_yoy_growth,
            data_quality, calculation_status
        ) VALUES (
            %s, %s, %s, %s, %s,
            %s, %s,
            %s, %s, %s,
            %s, %s, %s,
            %s, %s,
            %s, %s,
            %s, %s, %s,
            %s, %s
        )
        """

        for _, row in p_factors.iterrows():
            params = (
                row['ts_code'], row['calc_date'], row['ann_date'], row['end_date'], row['data_source'],
                row['p_score'], row['p_rank'],
                row['gpa'], row['roe_excl'], row['roa_excl'],
                row['net_margin_ttm'], row['operating_margin_ttm'], row['roi_ttm'],
                row['asset_turnover_ttm'], row['equity_multiplier'],
                row['debt_to_asset_ratio'], row['equity_ratio'],
                row['revenue_yoy_growth'], row['n_income_yoy_growth'], row['operate_profit_yoy_growth'],
                row['data_quality'], row['calculation_status']
            )
            self.db_manager.execute_sync(insert_query, params)

        self.logger.info(f"å·²ä¿å­˜ {len(p_factors)} æ¡På› å­æ•°æ®åˆ°æ•°æ®åº“")
    
    def _log_performance_stats(self, success_count: int, failed_count: int) -> None:
        """è®°å½•æ€§èƒ½ç»Ÿè®¡"""
        stats = self.stats
        total_time = stats['total_time']
        
        self.logger.info("=" * 40)
        self.logger.info("På› å­è®¡ç®—å®Œæˆ")
        self.logger.info("=" * 40)
        self.logger.info(f"æˆåŠŸ: {success_count}, å¤±è´¥: {failed_count}")
        self.logger.info(f"æ€»è€—æ—¶: {total_time:.3f} ç§’")
        
        if total_time > 0:
            throughput = success_count / total_time
            self.logger.info(f"ååé‡: {throughput:.1f} åª/ç§’")
        
        self.logger.info(f"æ—¶é—´åˆ†å¸ƒ:")
        if total_time > 0:
            self.logger.info(f"  æŸ¥è¯¢æ—¶é—´: {stats['query_time']:.3f}s ({stats['query_time']/total_time*100:.1f}%)")
            self.logger.info(f"  è®¡ç®—æ—¶é—´: {stats['calculation_time']:.3f}s ({stats['calculation_time']/total_time*100:.1f}%)")
            self.logger.info(f"  ä¿å­˜æ—¶é—´: {stats['save_time']:.3f}s ({stats['save_time']/total_time*100:.1f}%)")
