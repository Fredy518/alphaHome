#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
å…¨å¸‚åœºå›æµ‹æ•ˆç‡åŸºå‡†æµ‹è¯•

æµ‹è¯•æŒ‡æ ‡ï¼š
1. æ•°æ®åŠ è½½é€Ÿåº¦
2. å†…å­˜ä½¿ç”¨æƒ…å†µ
3. å›æµ‹æ‰§è¡Œæ—¶é—´
4. ä¸åŒè‚¡ç¥¨æ•°é‡çš„æ€§èƒ½å¯¹æ¯”
"""

import sys
import os
import time
import psutil
from datetime import date, datetime
import backtrader as bt
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from alphahome.backtesting.strategies.examples.dual_moving_average import DualMovingAverageStrategy
from alphahome.common.sync_db_manager import SyncDBManager
from alphahome.common.config_manager import get_database_url, get_backtesting_config
from examples.final_sync_backtest_demo import SyncPostgreSQLDataFeed


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.process = psutil.Process()
        self.start_time = None
        self.start_memory = None
    
    def start(self):
        """å¼€å§‹ç›‘æ§"""
        self.start_time = time.time()
        self.start_memory = self.process.memory_info().rss / 1024 / 1024  # MB
        return self
    
    def get_stats(self):
        """è·å–å½“å‰ç»Ÿè®¡"""
        current_time = time.time()
        current_memory = self.process.memory_info().rss / 1024 / 1024  # MB
        
        return {
            'elapsed_time': current_time - self.start_time,
            'current_memory_mb': current_memory,
            'memory_increase_mb': current_memory - self.start_memory,
            'cpu_percent': self.process.cpu_percent()
        }


def get_available_stocks(sync_db_manager, table='tushare_stock_daily', limit=None):
    """è·å–å¯ç”¨çš„è‚¡ç¥¨åˆ—è¡¨"""
    print("ğŸ“‹ è·å–å¯ç”¨è‚¡ç¥¨åˆ—è¡¨...")
    
    sql = f"""
    SELECT ts_code, COUNT(*) as record_count
    FROM {table} 
    WHERE trade_date >= '2023-01-01' AND trade_date <= '2023-12-31'
    GROUP BY ts_code 
    HAVING COUNT(*) >= 200
    ORDER BY ts_code
    """
    
    if limit:
        sql += f" LIMIT {limit}"
    
    records = sync_db_manager.fetch(sql)
    stocks = [(r['ts_code'], r['record_count']) for r in records]
    
    print(f"âœ… æ‰¾åˆ° {len(stocks)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
    return stocks


def benchmark_data_loading(sync_db_manager, stocks, table='tushare_stock_daily'):
    """åŸºå‡†æµ‹è¯•ï¼šæ•°æ®åŠ è½½"""
    print(f"\nğŸ“Š æ•°æ®åŠ è½½åŸºå‡†æµ‹è¯• ({len(stocks)} åªè‚¡ç¥¨)")
    print("-" * 50)
    
    monitor = PerformanceMonitor().start()
    
    # æ‰¹é‡æ•°æ®åŠ è½½æµ‹è¯•
    start_date = date(2023, 1, 1)
    end_date = date(2023, 12, 31)
    
    total_records = 0
    successful_loads = 0
    
    for i, (ts_code, expected_count) in enumerate(stocks, 1):
        try:
            sql = f"""
            SELECT COUNT(*) as count
            FROM {table} 
            WHERE ts_code = $1 AND trade_date BETWEEN $2 AND $3
            """
            result = sync_db_manager.fetch_one(sql, ts_code, start_date, end_date)
            count = result['count'] if result else 0
            
            if count > 0:
                total_records += count
                successful_loads += 1
            
            # æ¯100åªè‚¡ç¥¨æŠ¥å‘Šä¸€æ¬¡è¿›åº¦
            if i % 100 == 0:
                stats = monitor.get_stats()
                print(f"   è¿›åº¦: {i}/{len(stocks)} ({i/len(stocks)*100:.1f}%) "
                      f"æ—¶é—´: {stats['elapsed_time']:.1f}s "
                      f"å†…å­˜: {stats['current_memory_mb']:.1f}MB")
                
        except Exception as e:
            print(f"   âŒ {ts_code}: {e}")
    
    final_stats = monitor.get_stats()
    
    print(f"\nğŸ“ˆ æ•°æ®åŠ è½½ç»“æœ:")
    print(f"   æˆåŠŸåŠ è½½: {successful_loads}/{len(stocks)} åªè‚¡ç¥¨")
    print(f"   æ€»æ•°æ®é‡: {total_records:,} æ¡è®°å½•")
    print(f"   æ€»è€—æ—¶: {final_stats['elapsed_time']:.2f} ç§’")
    print(f"   å¹³å‡é€Ÿåº¦: {len(stocks)/final_stats['elapsed_time']:.1f} è‚¡ç¥¨/ç§’")
    print(f"   æ•°æ®åå: {total_records/final_stats['elapsed_time']:,.0f} è®°å½•/ç§’")
    print(f"   å†…å­˜ä½¿ç”¨: {final_stats['current_memory_mb']:.1f} MB")
    print(f"   å†…å­˜å¢é•¿: {final_stats['memory_increase_mb']:.1f} MB")
    
    return {
        'successful_loads': successful_loads,
        'total_records': total_records,
        'elapsed_time': final_stats['elapsed_time'],
        'memory_mb': final_stats['current_memory_mb']
    }


def benchmark_backtest_execution(sync_db_manager, stocks, max_stocks=None):
    """åŸºå‡†æµ‹è¯•ï¼šå›æµ‹æ‰§è¡Œ"""
    if max_stocks:
        stocks = stocks[:max_stocks]
    
    print(f"\nğŸš€ å›æµ‹æ‰§è¡ŒåŸºå‡†æµ‹è¯• ({len(stocks)} åªè‚¡ç¥¨)")
    print("-" * 50)
    
    monitor = PerformanceMonitor().start()
    
    try:
        # åˆ›å»ºCerebroå¼•æ“
        cerebro = bt.Cerebro()
        cerebro.broker.setcash(1000000)  # 100ä¸‡åˆå§‹èµ„é‡‘
        cerebro.broker.setcommission(commission=0.001)
        
        # æ·»åŠ åˆ†æå™¨
        cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trades')
        
        # æ·»åŠ æ•°æ®æº
        print("ğŸ“ˆ æ·»åŠ æ•°æ®æº...")
        added_feeds = 0
        
        for ts_code, _ in stocks:
            try:
                data_feed = SyncPostgreSQLDataFeed(
                    ts_code=ts_code,
                    sync_db_manager=sync_db_manager,
                    start_date=date(2023, 1, 1),
                    end_date=date(2023, 12, 31),
                    table_name='tushare_stock_daily'
                )
                cerebro.adddata(data_feed, name=ts_code)
                added_feeds += 1
                
                # æ¯50åªè‚¡ç¥¨æŠ¥å‘Šä¸€æ¬¡è¿›åº¦
                if added_feeds % 50 == 0:
                    stats = monitor.get_stats()
                    print(f"   å·²æ·»åŠ : {added_feeds} åªè‚¡ç¥¨ "
                          f"æ—¶é—´: {stats['elapsed_time']:.1f}s "
                          f"å†…å­˜: {stats['current_memory_mb']:.1f}MB")
                    
            except Exception as e:
                print(f"   âš ï¸  {ts_code}: è·³è¿‡ - {e}")
        
        print(f"âœ… æˆåŠŸæ·»åŠ  {added_feeds} åªè‚¡ç¥¨æ•°æ®æº")
        
        # æ·»åŠ ç­–ç•¥
        cerebro.addstrategy(DualMovingAverageStrategy, fast_period=5, slow_period=20, printlog=False)
        
        # è¿è¡Œå›æµ‹
        print("\nğŸ¯ æ‰§è¡Œå›æµ‹...")
        backtest_start = time.time()
        results = cerebro.run()
        backtest_end = time.time()
        
        backtest_time = backtest_end - backtest_start
        final_stats = monitor.get_stats()
        
        # åˆ†æç»“æœ
        strategy = results[0] if results else None
        final_value = cerebro.broker.getvalue()
        
        print(f"\nğŸ“Š å›æµ‹æ‰§è¡Œç»“æœ:")
        print(f"   è‚¡ç¥¨æ•°é‡: {added_feeds}")
        print(f"   å›æµ‹è€—æ—¶: {backtest_time:.2f} ç§’")
        print(f"   æ€»è€—æ—¶: {final_stats['elapsed_time']:.2f} ç§’")
        print(f"   å¹³å‡æ¯è‚¡: {backtest_time/added_feeds*1000:.1f} æ¯«ç§’") if added_feeds > 0 else None
        print(f"   æœ€ç»ˆä»·å€¼: {final_value:,.2f}")
        print(f"   å†…å­˜å³°å€¼: {final_stats['current_memory_mb']:.1f} MB")
        
        # äº¤æ˜“ç»Ÿè®¡
        if strategy:
            try:
                trades = strategy.analyzers.trades.get_analysis()
                total_trades = trades.get('total', {}).get('total', 0)
                print(f"   æ€»äº¤æ˜“æ•°: {total_trades}")
            except:
                print("   äº¤æ˜“ç»Ÿè®¡: è·å–å¤±è´¥")
        
        return {
            'stocks_count': added_feeds,
            'backtest_time': backtest_time,
            'total_time': final_stats['elapsed_time'],
            'final_value': final_value,
            'memory_mb': final_stats['current_memory_mb']
        }
        
    except Exception as e:
        print(f"âŒ å›æµ‹æ‰§è¡Œå¤±è´¥: {e}")
        return None


def run_scale_tests(sync_db_manager):
    """è¿è¡Œä¸åŒè§„æ¨¡çš„æµ‹è¯•"""
    print("\nğŸ”¬ è§„æ¨¡åŒ–æµ‹è¯•")
    print("=" * 60)
    
    # è·å–è‚¡ç¥¨åˆ—è¡¨
    all_stocks = get_available_stocks(sync_db_manager, limit=1000)  # é™åˆ¶1000åªä»¥é˜²å†…å­˜æº¢å‡º
    
    # ä¸åŒè§„æ¨¡çš„æµ‹è¯•
    test_scales = [10, 50, 100, 200, 500]
    results = []
    
    for scale in test_scales:
        if scale > len(all_stocks):
            print(f"âš ï¸  è·³è¿‡æµ‹è¯•è§„æ¨¡ {scale} (å¯ç”¨è‚¡ç¥¨ä¸è¶³)")
            continue
            
        print(f"\nğŸ“ æµ‹è¯•è§„æ¨¡: {scale} åªè‚¡ç¥¨")
        print("-" * 30)
        
        test_stocks = all_stocks[:scale]
        
        # æ•°æ®åŠ è½½æµ‹è¯•
        load_result = benchmark_data_loading(sync_db_manager, test_stocks)
        
        # å›æµ‹æ‰§è¡Œæµ‹è¯•ï¼ˆè¾ƒå°è§„æ¨¡ï¼‰
        if scale <= 100:
            backtest_result = benchmark_backtest_execution(sync_db_manager, test_stocks)
            
            results.append({
                'scale': scale,
                'load_time': load_result['elapsed_time'],
                'load_memory': load_result['memory_mb'],
                'backtest_time': backtest_result['backtest_time'] if backtest_result else None,
                'backtest_memory': backtest_result['memory_mb'] if backtest_result else None
            })
        else:
            results.append({
                'scale': scale,
                'load_time': load_result['elapsed_time'],
                'load_memory': load_result['memory_mb'],
                'backtest_time': None,
                'backtest_memory': None
            })
    
    # æ±‡æ€»æŠ¥å‘Š
    print(f"\nğŸ“ˆ è§„æ¨¡åŒ–æµ‹è¯•æ±‡æ€»")
    print("=" * 60)
    print(f"{'è§„æ¨¡':<8} {'åŠ è½½æ—¶é—´':<10} {'åŠ è½½å†…å­˜':<10} {'å›æµ‹æ—¶é—´':<10} {'å›æµ‹å†…å­˜':<10}")
    print("-" * 60)
    
    for result in results:
        scale = result['scale']
        load_time = f"{result['load_time']:.1f}s"
        load_memory = f"{result['load_memory']:.0f}MB"
        backtest_time = f"{result['backtest_time']:.1f}s" if result['backtest_time'] else "N/A"
        backtest_memory = f"{result['backtest_memory']:.0f}MB" if result['backtest_memory'] else "N/A"
        
        print(f"{scale:<8} {load_time:<10} {load_memory:<10} {backtest_time:<10} {backtest_memory:<10}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ AlphaHome å…¨å¸‚åœºå›æµ‹æ•ˆç‡åŸºå‡†æµ‹è¯•")
    print("=" * 60)
    print("ğŸ¯ æµ‹è¯•ç›®æ ‡: è¯„ä¼°å…¨å¸‚åœºå›æµ‹çš„æ€§èƒ½è¡¨ç°")
    print()
    
    try:
        # åˆå§‹åŒ–
        connection_string = get_database_url()
        if not connection_string:
            print("âŒ æœªæ‰¾åˆ°æ•°æ®åº“é…ç½®")
            return
        
        sync_db_manager = SyncDBManager(connection_string)
        
        if not sync_db_manager.test_connection():
            print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
            return
        
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        # è¿è¡Œæµ‹è¯•
        run_scale_tests(sync_db_manager)
        
        print(f"\nğŸ‰ åŸºå‡†æµ‹è¯•å®Œæˆï¼")
        print(f"\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
        print(f"   ğŸ”¹ å°è§„æ¨¡å›æµ‹ (â‰¤50è‚¡): æ€§èƒ½ä¼˜å¼‚")
        print(f"   ğŸ”¹ ä¸­è§„æ¨¡å›æµ‹ (50-200è‚¡): å¯æ¥å—")
        print(f"   ğŸ”¹ å¤§è§„æ¨¡å›æµ‹ (>200è‚¡): å»ºè®®åˆ†æ‰¹å¤„ç†")
        print(f"   ğŸ”¹ å…¨å¸‚åœºå›æµ‹: å»ºè®®ä½¿ç”¨å¹¶è¡Œå¤„ç†å’Œæ•°æ®é¢„åŠ è½½")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 