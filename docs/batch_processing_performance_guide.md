# æ‰¹å¤„ç†æ€§èƒ½ä¼˜åŒ–æŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—æä¾›æ‰¹å¤„ç†ç³»ç»Ÿçš„æ€§èƒ½ç›‘æ§ã€åˆ†æå’Œä¼˜åŒ–å»ºè®®ï¼Œå¸®åŠ©å¼€å‘è€…å’Œè¿ç»´äººå‘˜æœ€å¤§åŒ–æ‰¹å¤„ç†æ•ˆç‡ã€‚

## ğŸ“Š æ€§èƒ½ç›‘æ§ä½“ç³»

### æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡

#### 1. æ‰¹æ¬¡æ•ˆç‡æŒ‡æ ‡
```python
# æ‰¹æ¬¡æ•°é‡ä¼˜åŒ–ç‡
reduction_rate = (original_batches - optimized_batches) / original_batches * 100

# æ‰¹æ¬¡å¤§å°åˆ†å¸ƒ
batch_sizes = [len(batch.get("items", [])) for batch in batches]
avg_batch_size = sum(batch_sizes) / len(batch_sizes)

# æ—¶é—´è·¨åº¦æ•ˆç‡
time_span_days = (end_date - start_date).days
batches_per_day = len(batches) / time_span_days
```

#### 2. ç³»ç»Ÿèµ„æºæŒ‡æ ‡
```python
import psutil
import time

def monitor_batch_generation():
    start_time = time.time()
    start_memory = psutil.Process().memory_info().rss
    
    # æ‰¹æ¬¡ç”Ÿæˆè¿‡ç¨‹
    batches = await generate_batches()
    
    end_time = time.time()
    end_memory = psutil.Process().memory_info().rss
    
    return {
        "generation_time": end_time - start_time,
        "memory_usage": end_memory - start_memory,
        "batch_count": len(batches),
        "efficiency": len(batches) / (end_time - start_time)
    }
```

#### 3. APIè°ƒç”¨æ•ˆç‡æŒ‡æ ‡
```python
class APICallMonitor:
    def __init__(self):
        self.call_count = 0
        self.total_time = 0
        self.error_count = 0
    
    async def monitored_api_call(self, api_func, *args, **kwargs):
        start_time = time.time()
        try:
            result = await api_func(*args, **kwargs)
            self.call_count += 1
            return result
        except Exception as e:
            self.error_count += 1
            raise
        finally:
            self.total_time += time.time() - start_time
    
    def get_stats(self):
        return {
            "total_calls": self.call_count,
            "total_time": self.total_time,
            "avg_call_time": self.total_time / max(self.call_count, 1),
            "error_rate": self.error_count / max(self.call_count, 1),
            "calls_per_second": self.call_count / max(self.total_time, 0.001)
        }
```

### ç›‘æ§å®ç°ç¤ºä¾‹

#### é›†æˆç›‘æ§çš„ä»»åŠ¡å®ç°
```python
from alphahome.common.planning import create_smart_time_planner
import time
import psutil

class MonitoredTask(TushareTask):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.performance_stats = {}
    
    async def get_batch_list(self, **kwargs):
        """å¸¦æ€§èƒ½ç›‘æ§çš„æ‰¹æ¬¡ç”Ÿæˆ"""
        monitor_start = time.time()
        start_memory = psutil.Process().memory_info().rss
        
        try:
            # åˆ›å»ºæ™ºèƒ½æ—¶é—´æ‰¹å¤„ç†è§„åˆ’å™¨
            planner = create_smart_time_planner(
                start_date=kwargs.get("start_date"),
                end_date=kwargs.get("end_date"),
                enable_stats=True
            )
            
            batches = await planner.generate()
            stats = planner.get_stats()
            
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            generation_time = time.time() - monitor_start
            memory_used = psutil.Process().memory_info().rss - start_memory
            
            # è®°å½•æ€§èƒ½ç»Ÿè®¡
            self.performance_stats = {
                "batch_count": len(batches),
                "generation_time": generation_time,
                "memory_usage_mb": memory_used / 1024 / 1024,
                "batches_per_second": len(batches) / generation_time,
                "optimization_stats": stats.get("smart_time_optimization", {}),
                "timestamp": time.time()
            }
            
            # æ€§èƒ½æ—¥å¿—
            self.log_performance_stats()
            
            return batches
            
        except Exception as e:
            self.logger.error(f"æ‰¹æ¬¡ç”Ÿæˆå¤±è´¥: {e}")
            self.performance_stats["error"] = str(e)
            raise
    
    def log_performance_stats(self):
        """è®°å½•æ€§èƒ½ç»Ÿè®¡æ—¥å¿—"""
        stats = self.performance_stats
        opt_stats = stats.get("optimization_stats", {})
        
        self.logger.info(
            f"æ‰¹æ¬¡ç”Ÿæˆæ€§èƒ½ç»Ÿè®¡ - "
            f"æ‰¹æ¬¡æ•°: {stats['batch_count']}, "
            f"è€—æ—¶: {stats['generation_time']:.3f}s, "
            f"å†…å­˜: {stats['memory_usage_mb']:.1f}MB, "
            f"æ•ˆç‡: {stats['batches_per_second']:.1f} batches/s, "
            f"ä¼˜åŒ–ç‡: {opt_stats.get('reduction_rate', 0):.1f}%"
        )
```

## ğŸš€ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 1. æ™ºèƒ½æ‰¹æ¬¡å¤§å°ä¼˜åŒ–

#### åŠ¨æ€æ‰¹æ¬¡å¤§å°è°ƒæ•´
```python
class AdaptiveBatchPlanner:
    def __init__(self):
        self.performance_history = []
    
    def calculate_optimal_batch_size(self, data_size, historical_performance):
        """æ ¹æ®å†å²æ€§èƒ½è®¡ç®—æœ€ä¼˜æ‰¹æ¬¡å¤§å°"""
        if not historical_performance:
            return min(1000, data_size // 10)  # é»˜è®¤ç­–ç•¥
        
        # åˆ†æå†å²æ€§èƒ½æ•°æ®
        best_performance = max(historical_performance, 
                             key=lambda x: x['throughput'])
        
        optimal_size = best_performance['batch_size']
        
        # æ ¹æ®æ•°æ®è§„æ¨¡è°ƒæ•´
        scale_factor = data_size / best_performance['data_size']
        adjusted_size = int(optimal_size * scale_factor ** 0.5)
        
        return max(100, min(5000, adjusted_size))
    
    async def generate_adaptive_batches(self, data, target_batch_count=None):
        """ç”Ÿæˆè‡ªé€‚åº”æ‰¹æ¬¡"""
        if target_batch_count:
            batch_size = len(data) // target_batch_count
        else:
            batch_size = self.calculate_optimal_batch_size(
                len(data), self.performance_history
            )
        
        batches = []
        for i in range(0, len(data), batch_size):
            batches.append(data[i:i + batch_size])
        
        return batches
```

#### æ—¶é—´åºåˆ—æ•°æ®ä¼˜åŒ–
```python
def optimize_time_series_batching(start_date, end_date, data_frequency="daily"):
    """ä¼˜åŒ–æ—¶é—´åºåˆ—æ•°æ®çš„æ‰¹æ¬¡ç­–ç•¥"""
    time_span = (end_date - start_date).days
    
    # æ ¹æ®æ•°æ®é¢‘ç‡å’Œæ—¶é—´è·¨åº¦é€‰æ‹©ç­–ç•¥
    if data_frequency == "daily":
        if time_span <= 31:
            return "single"  # å•æ‰¹æ¬¡
        elif time_span <= 365:
            return "monthly"  # æœˆåº¦æ‰¹æ¬¡
        elif time_span <= 1825:  # 5å¹´
            return "quarterly"  # å­£åº¦æ‰¹æ¬¡
        else:
            return "yearly"  # å¹´åº¦æ‰¹æ¬¡
    
    elif data_frequency == "monthly":
        if time_span <= 365:
            return "single"
        elif time_span <= 1825:
            return "yearly"
        else:
            return "multi_year"
    
    return "adaptive"  # è‡ªé€‚åº”ç­–ç•¥
```

### 2. å†…å­˜ä¼˜åŒ–

#### æµå¼æ‰¹æ¬¡å¤„ç†
```python
class StreamingBatchProcessor:
    def __init__(self, batch_size=1000):
        self.batch_size = batch_size
    
    async def process_stream(self, data_generator):
        """æµå¼å¤„ç†å¤§æ•°æ®é›†"""
        batch = []
        
        async for item in data_generator:
            batch.append(item)
            
            if len(batch) >= self.batch_size:
                yield batch
                batch = []  # é‡Šæ”¾å†…å­˜
        
        # å¤„ç†æœ€åä¸€ä¸ªä¸å®Œæ•´çš„æ‰¹æ¬¡
        if batch:
            yield batch
    
    async def process_large_dataset(self, data_source):
        """å¤„ç†å¤§æ•°æ®é›†è€Œä¸å ç”¨è¿‡å¤šå†…å­˜"""
        total_processed = 0
        
        async for batch in self.process_stream(data_source):
            await self.process_batch(batch)
            total_processed += len(batch)
            
            # å†…å­˜æ¸…ç†
            if total_processed % 10000 == 0:
                import gc
                gc.collect()
```

#### å†…å­˜ä½¿ç”¨ç›‘æ§
```python
import tracemalloc

class MemoryMonitor:
    def __init__(self):
        self.snapshots = []
    
    def start_monitoring(self):
        """å¼€å§‹å†…å­˜ç›‘æ§"""
        tracemalloc.start()
        self.snapshots.append(tracemalloc.take_snapshot())
    
    def take_snapshot(self, label=""):
        """è·å–å†…å­˜å¿«ç…§"""
        snapshot = tracemalloc.take_snapshot()
        self.snapshots.append((label, snapshot))
        return snapshot
    
    def analyze_memory_growth(self):
        """åˆ†æå†…å­˜å¢é•¿"""
        if len(self.snapshots) < 2:
            return None
        
        current = self.snapshots[-1][1] if isinstance(self.snapshots[-1], tuple) else self.snapshots[-1]
        previous = self.snapshots[-2][1] if isinstance(self.snapshots[-2], tuple) else self.snapshots[-2]
        
        top_stats = current.compare_to(previous, 'lineno')
        
        return {
            "top_differences": top_stats[:10],
            "total_memory_mb": sum(stat.size for stat in current.statistics('filename')) / 1024 / 1024
        }
```

### 3. å¹¶å‘ä¼˜åŒ–

#### å¹¶å‘æ‰¹æ¬¡å¤„ç†
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class ConcurrentBatchProcessor:
    def __init__(self, max_concurrent=5):
        self.max_concurrent = max_concurrent
        self.semaphore = asyncio.Semaphore(max_concurrent)
    
    async def process_batch_concurrent(self, batch):
        """å¹¶å‘å¤„ç†å•ä¸ªæ‰¹æ¬¡"""
        async with self.semaphore:
            # æ¨¡æ‹Ÿæ‰¹æ¬¡å¤„ç†
            await asyncio.sleep(0.1)  # æ›¿æ¢ä¸ºå®é™…å¤„ç†é€»è¾‘
            return f"Processed {len(batch)} items"
    
    async def process_all_batches(self, batches):
        """å¹¶å‘å¤„ç†æ‰€æœ‰æ‰¹æ¬¡"""
        tasks = [
            self.process_batch_concurrent(batch) 
            for batch in batches
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸
        successful = [r for r in results if not isinstance(r, Exception)]
        failed = [r for r in results if isinstance(r, Exception)]
        
        return {
            "successful": len(successful),
            "failed": len(failed),
            "results": successful,
            "errors": failed
        }
```

#### è‡ªé€‚åº”å¹¶å‘æ§åˆ¶
```python
class AdaptiveConcurrencyController:
    def __init__(self, initial_concurrency=3):
        self.current_concurrency = initial_concurrency
        self.performance_history = []
        self.adjustment_threshold = 5  # è°ƒæ•´é˜ˆå€¼
    
    async def adaptive_process(self, batches):
        """è‡ªé€‚åº”å¹¶å‘å¤„ç†"""
        start_time = time.time()
        
        # ä½¿ç”¨å½“å‰å¹¶å‘åº¦å¤„ç†
        semaphore = asyncio.Semaphore(self.current_concurrency)
        
        async def process_with_semaphore(batch):
            async with semaphore:
                return await self.process_batch(batch)
        
        tasks = [process_with_semaphore(batch) for batch in batches]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # è®°å½•æ€§èƒ½
        processing_time = time.time() - start_time
        throughput = len(batches) / processing_time
        
        self.performance_history.append({
            "concurrency": self.current_concurrency,
            "throughput": throughput,
            "processing_time": processing_time,
            "batch_count": len(batches)
        })
        
        # è°ƒæ•´å¹¶å‘åº¦
        self.adjust_concurrency()
        
        return results
    
    def adjust_concurrency(self):
        """æ ¹æ®æ€§èƒ½å†å²è°ƒæ•´å¹¶å‘åº¦"""
        if len(self.performance_history) < self.adjustment_threshold:
            return
        
        recent_performance = self.performance_history[-self.adjustment_threshold:]
        avg_throughput = sum(p["throughput"] for p in recent_performance) / len(recent_performance)
        
        # å¦‚æœæ€§èƒ½ä¸‹é™ï¼Œå‡å°‘å¹¶å‘åº¦
        if len(self.performance_history) > self.adjustment_threshold:
            previous_avg = sum(
                p["throughput"] for p in 
                self.performance_history[-self.adjustment_threshold*2:-self.adjustment_threshold]
            ) / self.adjustment_threshold
            
            if avg_throughput < previous_avg * 0.9:  # æ€§èƒ½ä¸‹é™10%
                self.current_concurrency = max(1, self.current_concurrency - 1)
            elif avg_throughput > previous_avg * 1.1:  # æ€§èƒ½æå‡10%
                self.current_concurrency = min(10, self.current_concurrency + 1)
```

## ğŸ“ˆ æ€§èƒ½åˆ†æå·¥å…·

### æ‰¹æ¬¡æ€§èƒ½åˆ†æå™¨
```python
class BatchPerformanceAnalyzer:
    def __init__(self):
        self.metrics = []
    
    def analyze_batch_distribution(self, batches):
        """åˆ†ææ‰¹æ¬¡åˆ†å¸ƒ"""
        batch_sizes = [len(batch.get("items", [])) for batch in batches]
        
        return {
            "total_batches": len(batches),
            "avg_batch_size": sum(batch_sizes) / len(batch_sizes),
            "min_batch_size": min(batch_sizes),
            "max_batch_size": max(batch_sizes),
            "size_variance": self.calculate_variance(batch_sizes),
            "distribution": self.get_size_distribution(batch_sizes)
        }
    
    def calculate_variance(self, values):
        """è®¡ç®—æ–¹å·®"""
        mean = sum(values) / len(values)
        return sum((x - mean) ** 2 for x in values) / len(values)
    
    def get_size_distribution(self, sizes):
        """è·å–å¤§å°åˆ†å¸ƒ"""
        from collections import Counter
        return dict(Counter(sizes))
    
    def generate_performance_report(self, task_name, metrics):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        report = {
            "task_name": task_name,
            "timestamp": time.time(),
            "summary": {
                "total_batches": sum(m.get("batch_count", 0) for m in metrics),
                "avg_generation_time": sum(m.get("generation_time", 0) for m in metrics) / len(metrics),
                "total_memory_usage": sum(m.get("memory_usage_mb", 0) for m in metrics),
                "avg_optimization_rate": sum(
                    m.get("optimization_stats", {}).get("reduction_rate", 0) 
                    for m in metrics
                ) / len(metrics)
            },
            "recommendations": self.generate_recommendations(metrics)
        }
        
        return report
    
    def generate_recommendations(self, metrics):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        avg_time = sum(m.get("generation_time", 0) for m in metrics) / len(metrics)
        if avg_time > 1.0:
            recommendations.append("æ‰¹æ¬¡ç”Ÿæˆæ—¶é—´è¾ƒé•¿ï¼Œè€ƒè™‘ä¼˜åŒ–åˆ†åŒºç­–ç•¥")
        
        avg_memory = sum(m.get("memory_usage_mb", 0) for m in metrics) / len(metrics)
        if avg_memory > 100:
            recommendations.append("å†…å­˜ä½¿ç”¨è¾ƒé«˜ï¼Œè€ƒè™‘ä½¿ç”¨æµå¼å¤„ç†")
        
        avg_optimization = sum(
            m.get("optimization_stats", {}).get("reduction_rate", 0) 
            for m in metrics
        ) / len(metrics)
        if avg_optimization < 50:
            recommendations.append("æ‰¹æ¬¡ä¼˜åŒ–æ•ˆæœä¸ä½³ï¼Œæ£€æŸ¥æ—¶é—´è·¨åº¦å’Œåˆ†åŒºç­–ç•¥")
        
        return recommendations
```

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–æ£€æŸ¥æ¸…å•

### å¼€å‘é˜¶æ®µ
- [ ] é€‰æ‹©åˆé€‚çš„æ‰¹å¤„ç†ç­–ç•¥
- [ ] å®ç°æ€§èƒ½ç›‘æ§
- [ ] æ·»åŠ å†…å­˜ä½¿ç”¨ç›‘æ§
- [ ] è®¾ç½®åˆç†çš„å¹¶å‘é™åˆ¶
- [ ] å®ç°é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

### æµ‹è¯•é˜¶æ®µ
- [ ] è¿›è¡Œä¸åŒæ•°æ®è§„æ¨¡çš„æ€§èƒ½æµ‹è¯•
- [ ] éªŒè¯å†…å­˜ä½¿ç”¨æ˜¯å¦åˆç†
- [ ] æµ‹è¯•å¹¶å‘å¤„ç†çš„ç¨³å®šæ€§
- [ ] éªŒè¯æ‰¹æ¬¡ä¼˜åŒ–æ•ˆæœ
- [ ] æµ‹è¯•è¾¹ç•Œæ¡ä»¶å’Œå¼‚å¸¸æƒ…å†µ

### ç”Ÿäº§é˜¶æ®µ
- [ ] ç›‘æ§æ‰¹æ¬¡ç”Ÿæˆæ€§èƒ½
- [ ] å®šæœŸåˆ†ææ€§èƒ½è¶‹åŠ¿
- [ ] æ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µè°ƒæ•´å‚æ•°
- [ ] å»ºç«‹æ€§èƒ½å‘Šè­¦æœºåˆ¶
- [ ] å®šæœŸè¿›è¡Œæ€§èƒ½ä¼˜åŒ–

## ğŸ“Š æ€§èƒ½åŸºå‡†

### æ¨èæ€§èƒ½æŒ‡æ ‡
| æŒ‡æ ‡ | ä¼˜ç§€ | è‰¯å¥½ | éœ€è¦ä¼˜åŒ– |
|------|------|------|----------|
| æ‰¹æ¬¡ç”Ÿæˆæ—¶é—´ | <0.1s | <1s | >1s |
| å†…å­˜ä½¿ç”¨ | <50MB | <100MB | >100MB |
| æ‰¹æ¬¡ä¼˜åŒ–ç‡ | >80% | >50% | <50% |
| APIè°ƒç”¨æ•ˆç‡ | >10 calls/s | >5 calls/s | <5 calls/s |
| é”™è¯¯ç‡ | <1% | <5% | >5% |

### æ€§èƒ½ç›®æ ‡è®¾å®š
```python
PERFORMANCE_TARGETS = {
    "batch_generation_time": 0.5,  # ç§’
    "memory_usage_mb": 75,          # MB
    "optimization_rate": 70,        # ç™¾åˆ†æ¯”
    "throughput": 100,              # batches/minute
    "error_rate": 0.02              # 2%
}

def check_performance_targets(metrics):
    """æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ€§èƒ½ç›®æ ‡"""
    results = {}
    
    for metric, target in PERFORMANCE_TARGETS.items():
        actual = metrics.get(metric, 0)
        
        if metric == "error_rate":
            results[metric] = actual <= target
        else:
            results[metric] = actual >= target if metric in ["optimization_rate", "throughput"] else actual <= target
    
    return results
```

é€šè¿‡éµå¾ªæœ¬æŒ‡å—çš„æ€§èƒ½ä¼˜åŒ–ç­–ç•¥å’Œç›‘æ§å»ºè®®ï¼Œå¯ä»¥æ˜¾è‘—æå‡æ‰¹å¤„ç†ç³»ç»Ÿçš„æ•ˆç‡å’Œç¨³å®šæ€§ã€‚
