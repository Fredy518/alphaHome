#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
å®Œæ•´çš„ç«¯åˆ°ç«¯ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ä¸‰å±‚æ¶æ„åˆ›å»ºå’Œæ‰§è¡Œæ•°æ®å¤„ç†ä»»åŠ¡
"""

import asyncio
import pandas as pd
import numpy as np
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath('../../..'))

from alphahome.processors import Operation, OperationPipeline, ProcessorTaskBase, ProcessorEngine, task_register
from alphahome.common.db_manager import DBManager
from alphahome.common.task_system import UnifiedTaskFactory
from alphahome.common.config_manager import get_database_url


# æ­¥éª¤1: åˆ›å»ºè‡ªå®šä¹‰æ“ä½œ
class DataCleaningOperation(Operation):
    """æ•°æ®æ¸…æ´—æ“ä½œï¼šç§»é™¤ç©ºå€¼å’Œå¼‚å¸¸å€¼"""
    
    def __init__(self, name: str = "DataCleaning"):
        super().__init__(name)
    
    async def apply(self, data: pd.DataFrame, **kwargs) -> pd.DataFrame:
        """æ‰§è¡Œæ•°æ®æ¸…æ´—"""
        result = data.copy()
        
        # ç§»é™¤ç©ºå€¼
        original_count = len(result)
        result = result.dropna()
        
        # ç§»é™¤å¼‚å¸¸å€¼ï¼ˆç¤ºä¾‹ï¼šç§»é™¤è¶…å‡º3ä¸ªæ ‡å‡†å·®çš„å€¼ï¼‰
        if 'value' in result.columns:
            mean = result['value'].mean()
            std = result['value'].std()
            result = result[abs(result['value'] - mean) <= 3 * std]
        
        self.logger.info(f"æ•°æ®æ¸…æ´—å®Œæˆï¼š{original_count} -> {len(result)} è¡Œ")
        return result


class FeatureEngineeringOperation(Operation):
    """ç‰¹å¾å·¥ç¨‹æ“ä½œï¼šåˆ›å»ºæ–°ç‰¹å¾"""
    
    def __init__(self, name: str = "FeatureEngineering"):
        super().__init__(name)
    
    async def apply(self, data: pd.DataFrame, **kwargs) -> pd.DataFrame:
        """æ‰§è¡Œç‰¹å¾å·¥ç¨‹"""
        result = data.copy()
        
        # åˆ›å»ºæ–°ç‰¹å¾
        if 'value' in result.columns:
            result['value_squared'] = result['value'] ** 2
            result['value_log'] = result['value'].apply(lambda x: np.log(x) if x > 0 else 0)
            result['value_normalized'] = (result['value'] - result['value'].mean()) / result['value'].std()
        
        new_features = len(result.columns) - len(data.columns)
        self.logger.info(f"ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œæ–°å¢ {new_features} ä¸ªç‰¹å¾")
        return result


# æ­¥éª¤2: åˆ›å»ºè‡ªå®šä¹‰ä»»åŠ¡
@task_register()
class CompleteExampleTask(ProcessorTaskBase):
    """å®Œæ•´ç¤ºä¾‹ä»»åŠ¡"""
    
    name = "complete_example_task"
    table_name = "complete_example_result"
    description = "å®Œæ•´çš„æ•°æ®å¤„ç†ç¤ºä¾‹ä»»åŠ¡"
    
    async def fetch_data(self, **kwargs) -> pd.DataFrame:
        """è·å–æ•°æ®"""
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        np.random.seed(42)  # ç¡®ä¿ç»“æœå¯é‡ç°
        
        data = pd.DataFrame({
            'id': range(1, 101),
            'value': np.random.normal(100, 15, 100),
            'category': np.random.choice(['A', 'B', 'C'], 100),
            'timestamp': pd.date_range('2023-01-01', periods=100, freq='D')
        })
        
        # äººä¸ºæ·»åŠ ä¸€äº›ç©ºå€¼å’Œå¼‚å¸¸å€¼
        data.loc[5:10, 'value'] = np.nan  # æ·»åŠ ç©ºå€¼
        data.loc[95, 'value'] = 1000  # æ·»åŠ å¼‚å¸¸å€¼
        
        self.logger.info(f"è·å–åˆ° {len(data)} è¡Œæ¨¡æ‹Ÿæ•°æ®")
        return data
    
    async def process_data(self, data: pd.DataFrame, **kwargs) -> pd.DataFrame:
        """å¤„ç†æ•°æ®"""
        # åˆ›å»ºæ“ä½œæµæ°´çº¿
        pipeline = OperationPipeline("CompleteExamplePipeline")
        
        # æ·»åŠ æ“ä½œåˆ°æµæ°´çº¿
        pipeline.add_operation(DataCleaningOperation())
        pipeline.add_operation(FeatureEngineeringOperation())
        
        # æ‰§è¡Œæµæ°´çº¿
        processed_data = await pipeline.apply(data, **kwargs)
        
        self.logger.info(f"æ•°æ®å¤„ç†å®Œæˆï¼Œæœ€ç»ˆæ•°æ®å½¢çŠ¶: {processed_data.shape}")
        return processed_data
    
    async def save_result(self, data: pd.DataFrame, **kwargs):
        """ä¿å­˜ç»“æœ"""
        # åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œè¿™é‡Œä¼šä¿å­˜åˆ°æ•°æ®åº“
        # è¿™é‡Œåªæ˜¯æ‰“å°ç»“æœä½œä¸ºç¤ºä¾‹
        self.logger.info(f"ä¿å­˜ {len(data)} è¡Œæ•°æ®åˆ°è¡¨ {self.table_name}")
        
        print(f"\n=== å¤„ç†ç»“æœé¢„è§ˆ ===")
        print(f"æ•°æ®å½¢çŠ¶: {data.shape}")
        print(f"åˆ—å: {data.columns.tolist()}")
        print("\nå‰5è¡Œæ•°æ®:")
        print(data.head())
        
        print(f"\næ•°æ®ç»Ÿè®¡:")
        print(data.describe())


# æ­¥éª¤3: æ‰§è¡Œç¤ºä¾‹
async def run_complete_example():
    """è¿è¡Œå®Œæ•´ç¤ºä¾‹"""
    print("=== AlphaHome æ•°æ®å¤„ç†æ¨¡å—å®Œæ•´ç¤ºä¾‹ ===\n")
    
    db_manager = None
    engine = None
    
    try:
        # 1. åˆå§‹åŒ–æ•°æ®åº“è¿æ¥ï¼ˆå¦‚æœæœ‰é…ç½®ï¼‰
        db_url = get_database_url()
        if db_url:
            print("ä½¿ç”¨é…ç½®çš„æ•°æ®åº“è¿æ¥...")
            db_manager = DBManager(db_url)
            await db_manager.connect()
        else:
            print("æœªé…ç½®æ•°æ®åº“ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®åº“ç®¡ç†å™¨...")
            # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„æ•°æ®åº“ç®¡ç†å™¨ç”¨äºæ¼”ç¤º
            class MockDBManager:
                async def connect(self): pass
                async def close(self): pass
            db_manager = MockDBManager()
        
        # 2. åˆå§‹åŒ–ä»»åŠ¡å·¥å‚
        if db_url:
            await UnifiedTaskFactory.initialize(db_url=db_url)
        else:
            # æ¨¡æ‹Ÿåˆå§‹åŒ–
            print("æ¨¡æ‹Ÿä»»åŠ¡å·¥å‚åˆå§‹åŒ–...")
        
        # 3. åˆ›å»ºå¤„ç†å¼•æ“
        engine = ProcessorEngine(db_manager=db_manager, max_workers=2)
        
        # 4. æ‰§è¡Œä»»åŠ¡
        print("å¼€å§‹æ‰§è¡Œå®Œæ•´ç¤ºä¾‹ä»»åŠ¡...")
        result = await engine.execute_task("complete_example_task")
        
        # 5. æ£€æŸ¥ç»“æœ
        print(f"\n=== æ‰§è¡Œç»“æœ ===")
        print(f"ä»»åŠ¡çŠ¶æ€: {result['status']}")
        print(f"å¤„ç†è¡Œæ•°: {result.get('rows', 0)}")
        
        if 'engine_metadata' in result:
            metadata = result['engine_metadata']
            print(f"æ‰§è¡Œæ—¶é—´: {metadata.get('execution_time', 0):.2f}ç§’")
            print(f"å¼€å§‹æ—¶é—´: {metadata.get('start_time', 'N/A')}")
            print(f"ç»“æŸæ—¶é—´: {metadata.get('end_time', 'N/A')}")
        
        # 6. æ˜¾ç¤ºå¼•æ“ç»Ÿè®¡
        if hasattr(engine, 'get_stats'):
            stats = engine.get_stats()
            print(f"\n=== å¼•æ“ç»Ÿè®¡ ===")
            print(f"æ€»ä»»åŠ¡æ•°: {stats.get('total_tasks', 0)}")
            print(f"æˆåŠŸä»»åŠ¡æ•°: {stats.get('successful_tasks', 0)}")
            print(f"å¤±è´¥ä»»åŠ¡æ•°: {stats.get('failed_tasks', 0)}")
            print(f"æˆåŠŸç‡: {stats.get('success_rate', 0):.2%}")
        
        print(f"\nğŸ‰ å®Œæ•´ç¤ºä¾‹æ‰§è¡ŒæˆåŠŸï¼")
        
    except Exception as e:
        print(f"âŒ ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # 7. æ¸…ç†èµ„æº
        if engine and hasattr(engine, 'shutdown'):
            engine.shutdown()
            print("å¼•æ“å·²å…³é—­")
        
        if db_manager and hasattr(db_manager, 'close'):
            await db_manager.close()
            print("æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    return True


if __name__ == "__main__":
    print("è¿è¡ŒAlphaHomeæ•°æ®å¤„ç†æ¨¡å—å®Œæ•´ç¤ºä¾‹...")
    success = asyncio.run(run_complete_example())
    
    if success:
        print("\nâœ… ç¤ºä¾‹è¿è¡ŒæˆåŠŸï¼")
        print("\nğŸ“š æ›´å¤šä¿¡æ¯è¯·å‚è€ƒ:")
        print("- README.md: è¯¦ç»†çš„å¼€å‘æŒ‡å—")
        print("- usage_example.py: åŸºç¡€ä½¿ç”¨ç¤ºä¾‹")
        print("- é¡¹ç›®æ–‡æ¡£: å®Œæ•´çš„APIæ–‡æ¡£")
    else:
        print("\nâŒ ç¤ºä¾‹è¿è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
    
    sys.exit(0 if success else 1)
