# Design Document: Processors Data Layering

## Overview

æœ¬è®¾è®¡æ–‡æ¡£æè¿° alphahome/processors æ¨¡å—çš„æ•°æ®åˆ†å±‚æ¶æ„ã€‚é‡æ„ç›®æ ‡æ˜¯å»ºç«‹æ¸…æ™°çš„"å¤„ç†å±‚ï¼ˆCleanï¼‰vs ç‰¹å¾å±‚ï¼ˆFeatureï¼‰"åˆ†å±‚è§„èŒƒï¼Œä½¿æ•°æ®å¤„ç†å’Œç‰¹å¾è®¡ç®—èŒè´£åˆ†ç¦»ã€‚

### Scope Summary (ä¸éœ€æ±‚æ–‡æ¡£å¯¹é½)

| èŒƒå›´ | å†…å®¹ |
|------|------|
| èŒƒå›´å†… | å¤„ç†å±‚ç»„ä»¶ã€ç‰¹å¾å±‚æ¥å£å¥‘çº¦ã€ä»»åŠ¡å±‚å¢å¼ºã€ç°æœ‰ä»»åŠ¡åˆ†ç±» |
| èŒƒå›´å¤– | ç­–ç•¥çº§ alpha è¯„ä¼°ã€å…·ä½“é‡æ„ä»£ç å®ç°ã€çº¿ä¸ŠæœåŠ¡éƒ¨ç½² |

### Success Criteria (éªŒæ”¶ç‚¹)

| éªŒæ”¶ç‚¹ | éªŒè¯æ–¹å¼ |
|--------|----------|
| Clean Layer ç»„ä»¶å®ç° | DataValidator/Aligner/Standardizer/LineageTracker/Writer å•å…ƒæµ‹è¯•é€šè¿‡ |
| 18 ä¸ªæ­£ç¡®æ€§å±æ€§ | å±æ€§æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼ˆè§ Property Test Coverage Matrixï¼‰ |
| clean schema è¡¨åˆ›å»º | DDL æ‰§è¡ŒæˆåŠŸï¼Œè¡¨ç»“æ„ç¬¦åˆè®¾è®¡ |
| ä»»åŠ¡åˆ†ç±»è¡¨å®Œæˆ | è¦†ç›–æ‰€æœ‰ç°æœ‰ä»»åŠ¡ï¼Œè¯„å®¡é€šè¿‡ |
| æ€§èƒ½ SLA | é«˜ä¼˜å…ˆçº§ä»»åŠ¡ T+1 09:00 å‰å®Œæˆï¼›ä½ä¼˜å…ˆçº§ä»»åŠ¡ T+1 æ”¶ç›˜å‰å®Œæˆ |

### è®¾è®¡ç›®æ ‡

1. **æ¸…æ™°çš„åˆ†å±‚è¾¹ç•Œ**: å¤„ç†å±‚è´Ÿè´£æ•°æ®æ¸…æ´—å’Œæ ‡å‡†åŒ–ï¼Œç‰¹å¾å±‚è´Ÿè´£è¡ç”Ÿè®¡ç®—
2. **ç»Ÿä¸€çš„æ•°æ®å¥‘çº¦**: clean schema ä½œä¸ºæ‰€æœ‰ä¸‹æ¸¸æ¶ˆè´¹è€…çš„ç»Ÿä¸€è¾“å…¥
3. **å¯è¿½æº¯çš„æ•°æ®è¡€ç¼˜**: æ¯æ¡è®°å½•éƒ½æœ‰æ¥æºå’Œå¤„ç†æ—¶é—´æˆ³
4. **å¹‚ç­‰çš„æ•°æ®å…¥åº“**: æ”¯æŒå®‰å…¨é‡è¯•å’Œå¢é‡æ›´æ–°

### è®¾è®¡åŸåˆ™

- **å•ä¸€èŒè´£**: å¤„ç†å±‚åªåšæ¸…æ´—ï¼Œç‰¹å¾å±‚åªåšè®¡ç®—
- **çº¯å‡½æ•°è®¾è®¡**: ç‰¹å¾å‡½æ•°æ— å‰¯ä½œç”¨ï¼Œæ˜“äºæµ‹è¯•å’Œç¼“å­˜
- **é˜²å¾¡æ€§ç¼–ç¨‹**: å¤„ç†ç©ºæ•°æ®ã€é›¶æ–¹å·®ã€é™¤é›¶ç­‰è¾¹ç•Œæƒ…å†µ
- **æ˜¾å¼ä¼˜äºéšå¼**: è¡€ç¼˜å­—æ®µå†…è”ï¼Œä¸ä¾èµ–å¤–éƒ¨å…ƒæ•°æ®è¡¨
- **Best-effort ç­–ç•¥**: å¯¹é½å’Œæ ‡å‡†åŒ–é‡‡ç”¨å°½åŠ›è€Œä¸ºç­–ç•¥ï¼Œè®°å½•è­¦å‘Šä½†ä¸é˜»æ–­æµç¨‹

### å®ç°çŠ¶æ€è¯´æ˜

**å·²å®Œæˆ**:
- âœ… Clean Layer æ ¸å¿ƒç»„ä»¶ï¼ˆValidator, Aligner, Standardizer, LineageTrackerï¼‰
- âœ… Feature Layer æ¥å£å¥‘çº¦å’Œçº¯å‡½æ•°å®ç°
- âœ… Task Layer å¢å¼ºï¼ˆfetch â†’ clean â†’ feature â†’ save æµç¨‹ï¼‰
- âœ… 18 ä¸ªæ­£ç¡®æ€§å±æ€§çš„å±æ€§æµ‹è¯•
- âœ… Clean schema DDL å®šä¹‰
- âœ… ä»»åŠ¡åˆ†ç±»è¡¨å’Œç‰¹å¾å…¥åº“ç™½åå•

**å ä½å®ç°**ï¼ˆéœ€ç”Ÿäº§ç¯å¢ƒè¦†ç›–ï¼‰:
- âš ï¸ `ProcessorTaskBase._save_to_clean()` - å½“å‰ä»…è®¡æ•°+æ—¥å¿—ï¼Œæœªå®é™…å†™å…¥æ•°æ®åº“
  - ç”Ÿäº§ç¯å¢ƒéœ€è¦†ç›–æ­¤æ–¹æ³•æˆ–å¼•å…¥ CleanLayerWriter é€‚é… DBManager
  - å‚è€ƒå®ç°è§æ–¹æ³• docstring

**å¾…å®ç°**ï¼ˆæ‰©å±•ç‚¹ï¼‰:
- ğŸ”„ `ProcessorEngine._check_dependencies()` - ä¾èµ–æ£€æŸ¥åŠŸèƒ½
  - å½“å‰ä»…è®°å½•æ—¥å¿—ï¼Œä¸æ‰§è¡Œå®é™…éªŒè¯
  - ä¸­é•¿æœŸå¯æŒ‚æ¥åˆ°ç»Ÿä¸€ä»»åŠ¡çŠ¶æ€è¡¨
  - å‚è€ƒå®ç°è§æ–¹æ³• docstring

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           Source Data                                    â”‚
â”‚  tushare.*, akshare.*, etc.                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Clean Layer (å¤„ç†å±‚)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Validator  â”‚  â”‚  Aligner    â”‚  â”‚ Standardizerâ”‚  â”‚  Lineage    â”‚    â”‚
â”‚  â”‚  - ç±»å‹æ ¡éªŒ  â”‚  â”‚  - æ—¥æœŸå¯¹é½  â”‚  â”‚  - å•ä½è½¬æ¢  â”‚  â”‚  - è¡€ç¼˜è®°å½•  â”‚    â”‚
â”‚  â”‚  - ç¼ºåˆ—æ£€æµ‹  â”‚  â”‚  - æ ‡çš„æ˜ å°„  â”‚  â”‚  - å¤æƒå¤„ç†  â”‚  â”‚  - ç‰ˆæœ¬è¿½è¸ª  â”‚    â”‚
â”‚  â”‚  - é‡å¤å»é‡  â”‚  â”‚  - ä¸»é”®æ„å»º  â”‚  â”‚  - å¸ç§ç»Ÿä¸€  â”‚  â”‚  - ä»»åŠ¡ID   â”‚    â”‚
â”‚  â”‚  - ç©ºå€¼æ£€æµ‹  â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚    â”‚
â”‚  â”‚  - èŒƒå›´æ ¡éªŒ  â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                    â”‚                                     â”‚
â”‚                                    â–¼                                     â”‚
â”‚                          clean schema (PostgreSQL)                       â”‚
â”‚                          - clean.index_valuation_base                    â”‚
â”‚                          - clean.index_volatility_base                   â”‚
â”‚                          - clean.industry_base                           â”‚
â”‚                          - clean.market_technical_base                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Feature Layer (ç‰¹å¾å±‚)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    operations/transforms.py                      â”‚    â”‚
â”‚  â”‚  - rolling_percentile, rolling_zscore, rolling_slope            â”‚    â”‚
â”‚  â”‚  - winsorize, quantile_bins                                     â”‚    â”‚
â”‚  â”‚  - price_acceleration, trend_strength_index                     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                    â”‚                                     â”‚
â”‚                                    â–¼                                     â”‚
â”‚                          Feature Tables (å¯é€‰å…¥åº“ï¼Œç¤ºä¾‹)                 â”‚
â”‚                          - processor_index_valuation                     â”‚
â”‚                          - processor_index_volatility                    â”‚
â”‚                          - (å®Œæ•´åˆ—è¡¨è§ä»»åŠ¡åˆ†ç±»è¡¨)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Task Layer (ä»»åŠ¡å±‚)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  ProcessorTaskBase                                               â”‚    â”‚
â”‚  â”‚  - fetch_data() â†’ clean_data() â†’ compute_features() â†’ save()    â”‚    â”‚
â”‚  â”‚  - feature_dependencies: List[str]                              â”‚    â”‚
â”‚  â”‚  - skip_features: bool                                          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Components and Interfaces

### 1. Clean Layer Components

#### 1.1 DataValidator

**æ³¨æ„ï¼šä»¥ä¸‹ä¸ºæ¥å£è§„èŒƒï¼Œéå®ç°ä»£ç ã€‚**

```python
@dataclass
class TableSchema:
    """è¡¨ schema å®šä¹‰"""
    required_columns: List[str]  # å¿…éœ€åˆ—
    column_types: Dict[str, type]  # åˆ—ç±»å‹æ˜ å°„
    nullable_columns: List[str]  # å¯ç©ºåˆ—
    value_ranges: Dict[str, Tuple[float, float]]  # å€¼åŸŸèŒƒå›´

@dataclass
class ValidationResult:
    """æ ¡éªŒç»“æœ"""
    is_valid: bool
    missing_columns: List[str]
    type_errors: Dict[str, str]  # {column: "expected X, got Y"}
    null_fields: List[str]
    out_of_range_rows: pd.Index
    dropped_columns: List[str]  # æ£€æµ‹åˆ°çš„è¢«ä¸¢å¼ƒåˆ—ï¼ˆåº”ä¸ºç©ºï¼‰

class DataValidator:
    """
    æ•°æ®æ ¡éªŒå™¨
    
    å…³é”®çº¦æŸï¼š
    - ä¸å¾— silent drop/rename åˆ—
    - schema é…ç½®æ¥æºäº TableSchema å®šä¹‰
    - æ ¡éªŒå¤±è´¥æ—¶æŠ›å‡º ValidationError
    """
    
    def __init__(self, schema: TableSchema):
        self.schema = schema
    
    def validate(self, df: pd.DataFrame) -> ValidationResult:
        """
        æ ¡éªŒ DataFrame æ˜¯å¦ç¬¦åˆ schema
        
        Raises:
            ValidationError: å½“æ ¡éªŒå¤±è´¥æ—¶
        """
        pass
    
    def validate_column_types(self, df: pd.DataFrame) -> Dict[str, str]:
        """æ ¡éªŒåˆ—ç±»å‹ï¼Œè¿”å›ç±»å‹ä¸åŒ¹é…çš„åˆ—åŠæœŸæœ›ç±»å‹"""
        pass
    
    def detect_missing_columns(self, df: pd.DataFrame) -> List[str]:
        """æ£€æµ‹ç¼ºå¤±çš„å¿…éœ€åˆ—"""
        pass
    
    def detect_duplicates(self, df: pd.DataFrame, keys: List[str]) -> pd.DataFrame:
        """æ£€æµ‹é‡å¤è®°å½•ï¼Œè¿”å›é‡å¤çš„è¡Œ"""
        pass
    
    def detect_nulls(self, df: pd.DataFrame, required_cols: List[str]) -> List[str]:
        """æ£€æµ‹å¿…éœ€åˆ—ä¸­çš„ç©ºå€¼"""
        pass
    
    def detect_out_of_range(self, df: pd.DataFrame, ranges: Dict[str, Tuple]) -> pd.Index:
        """æ£€æµ‹è¶…å‡ºæœ‰æ•ˆèŒƒå›´çš„è®°å½•"""
        pass
    
    def detect_dropped_columns(self, input_cols: List[str], output_cols: List[str]) -> List[str]:
        """æ£€æµ‹è¢«ä¸¢å¼ƒçš„åˆ—ï¼ˆåº”è¿”å›ç©ºåˆ—è¡¨ï¼‰"""
        pass
```

#### 1.2 DataAligner

**æ³¨æ„ï¼šä»¥ä¸‹ä¸ºæ¥å£è§„èŒƒï¼Œéå®ç°ä»£ç ã€‚**

```python
class DataAligner:
    """
    æ•°æ®å¯¹é½å™¨
    
    ä¾èµ–ï¼š
    - security_master è¡¨ç”¨äºæ ‡çš„æ˜ å°„
    
    Fallback ç­–ç•¥ï¼š
    - æ˜ å°„å¤±è´¥æ—¶è®°å½•æ—¥å¿—å¹¶ä¿ç•™åŸå€¼ï¼Œæ·»åŠ  _mapping_failed æ ‡è®°
    """
    
    def __init__(self, security_master_loader: Callable):
        """
        Args:
            security_master_loader: åŠ è½½ security_master è¡¨çš„å‡½æ•°
        """
        self.security_master = None  # å»¶è¿ŸåŠ è½½
    
    def align_date(self, df: pd.DataFrame, source_col: str) -> pd.DataFrame:
        """
        å°†æ—¥æœŸåˆ—å¯¹é½åˆ° trade_date æ ‡å‡†æ ¼å¼
        
        æ”¯æŒçš„æºæ ¼å¼ï¼š
        - YYYY-MM-DD, YYYYMMDD, datetime, timestamp
        
        è¾“å‡ºæ ¼å¼ï¼šYYYYMMDD (int) æˆ– datetime
        
        çº¦æŸï¼šä¸æ”¹å˜è¡Œé¡ºåº
        """
        pass
    
    def align_identifier(self, df: pd.DataFrame, source_col: str) -> pd.DataFrame:
        """
        å°†æ ‡çš„æ ‡è¯†ç¬¦å¯¹é½åˆ° ts_code æ ¼å¼
        
        æ”¯æŒçš„æºæ ¼å¼ï¼š
        - 000001 â†’ 000001.SZ (æ ¹æ®ä»£ç è§„åˆ™æ¨æ–­äº¤æ˜“æ‰€)
        - sh600000 â†’ 600000.SH
        - symbol â†’ æŸ¥è¯¢ security_master
        
        è¾“å‡ºæ ¼å¼ï¼š000001.SZ
        
        Fallbackï¼šæ˜ å°„å¤±è´¥æ—¶ä¿ç•™åŸå€¼ï¼Œæ·»åŠ  _mapping_failed=True
        
        æ˜ å°„å¤±è´¥å¤„ç†ç­–ç•¥ï¼š
        - é»˜è®¤ï¼ˆstrict_mapping=Falseï¼‰ï¼šå…è®¸å…¥åº“ï¼Œä½†æ ‡è®° _mapping_failed=True
        - ä¸¥æ ¼æ¨¡å¼ï¼ˆstrict_mapping=Trueï¼‰ï¼šé˜»æ–­å†™å…¥ï¼ŒæŠ›å‡º ValidationError
        """
        pass
    
    def build_primary_key(self, df: pd.DataFrame, keys: List[str]) -> pd.DataFrame:
        """æ„å»ºå¤åˆä¸»é”®ï¼Œç¡®ä¿å”¯ä¸€æ€§"""
        pass
```

#### 1.3 DataStandardizer

**æ³¨æ„ï¼šä»¥ä¸‹ä¸ºæ¥å£è§„èŒƒï¼Œéå®ç°ä»£ç ã€‚**

```python
class DataStandardizer:
    """
    æ•°æ®æ ‡å‡†åŒ–å™¨
    
    çº¦æŸï¼š
    - è½¬æ¢åä¿ç•™åŸå•ä½åˆ—ï¼ˆæ·»åŠ  _åŸå•ä½ åç¼€ï¼‰
    - è®°å½•è½¬æ¢æ—¥å¿—
    """
    
    # å•ä½è½¬æ¢å› å­
    UNIT_CONVERSIONS = {
        'ä¸‡å…ƒ': 10000,
        'äº¿å…ƒ': 100000000,
        'æ‰‹': 100,
    }
    
    def convert_monetary(
        self, 
        df: pd.DataFrame, 
        col: str, 
        source_unit: str,
        preserve_original: bool = True,
    ) -> pd.DataFrame:
        """
        å°†è´§å¸åˆ—è½¬æ¢ä¸ºå…ƒ
        
        Args:
            preserve_original: æ˜¯å¦ä¿ç•™åŸå•ä½åˆ—ï¼ˆé»˜è®¤ Trueï¼‰
            
        Side effects:
            - è®°å½•è½¬æ¢æ—¥å¿—ï¼ˆé€šè¿‡ logger.infoï¼‰ï¼š{col}: {source_unit} â†’ å…ƒ, factor={factor}
        """
        pass
    
    def convert_volume(
        self, 
        df: pd.DataFrame, 
        col: str, 
        source_unit: str,
        preserve_original: bool = True,
    ) -> pd.DataFrame:
        """
        å°†æˆäº¤é‡åˆ—è½¬æ¢ä¸ºè‚¡
        
        Args:
            preserve_original: æ˜¯å¦ä¿ç•™åŸå•ä½åˆ—ï¼ˆé»˜è®¤ Trueï¼‰
        """
        pass
    
    def preserve_unadjusted(self, df: pd.DataFrame, price_cols: List[str]) -> pd.DataFrame:
        """ä¿ç•™æœªå¤æƒä»·æ ¼åˆ—ï¼ˆæ·»åŠ  _unadj åç¼€ï¼‰"""
        pass
```

#### 1.4 LineageTracker

```python
class LineageTracker:
    """è¡€ç¼˜è¿½è¸ªå™¨"""
    
    def add_lineage(
        self, 
        df: pd.DataFrame, 
        source_tables: List[str],
        job_id: str,
        data_version: str = None,
    ) -> pd.DataFrame:
        """
        æ·»åŠ è¡€ç¼˜å…ƒæ•°æ®åˆ—
        
        æ·»åŠ çš„åˆ—ï¼š
        - _source_table: æºè¡¨åï¼ˆé€—å·åˆ†éš”ï¼‰
        - _processed_at: å¤„ç†æ—¶é—´æˆ³ï¼ˆUTCï¼‰
        - _data_version: æ•°æ®ç‰ˆæœ¬
        - _ingest_job_id: ä»»åŠ¡æ‰§è¡ŒID
        """
        pass
```

#### 1.5 CleanLayerWriter

**æ³¨æ„ï¼šä»¥ä¸‹ä¸ºæ¥å£è§„èŒƒï¼Œéå®ç°ä»£ç ã€‚**

```python
class CleanLayerWriter:
    """
    Clean å±‚æ•°æ®å†™å…¥å™¨
    
    é»˜è®¤é…ç½®ï¼š
    - batch_size: 10000ï¼ˆå¯é…ç½®ï¼‰
    - max_retries: 3ï¼ˆå¯é…ç½®ï¼‰
    - conflict_strategy: 'replace'ï¼ˆé»˜è®¤å…¨é‡è¦†ç›–ï¼‰
    
    çº¦æŸï¼š
    - ä½¿ç”¨æ•°æ®åº“äº‹åŠ¡ä¿è¯åŸå­æ€§
    - å¤±è´¥æ—¶æ•´æ‰¹å›æ»š
    - æ”¯æŒæŒ‡æ•°é€€é¿é‡è¯•
    """
    
    def __init__(
        self, 
        db_connection, 
        batch_size: int = 10000, 
        max_retries: int = 3,
        retry_delay_base: float = 2.0,
    ):
        self.db = db_connection
        self.batch_size = batch_size
        self.max_retries = max_retries
        self.retry_delay_base = retry_delay_base
    
    async def upsert(
        self, 
        df: pd.DataFrame, 
        table_name: str, 
        primary_keys: List[str],
        conflict_strategy: str = 'replace',
    ) -> int:
        """
        å¹‚ç­‰å†™å…¥æ•°æ®
        
        Args:
            df: è¦å†™å…¥çš„æ•°æ®
            table_name: ç›®æ ‡è¡¨åï¼ˆclean schemaï¼‰
            primary_keys: ä¸»é”®åˆ—
            conflict_strategy: å†²çªç­–ç•¥
                - 'replace': å…¨é‡è¦†ç›–ï¼ˆé»˜è®¤ï¼Œæ¨èï¼‰
                - 'merge': ä»…æ›´æ–°éç©ºåˆ—ï¼ˆé»˜è®¤ç¦ç”¨ï¼Œéœ€æ˜¾å¼å¯ç”¨å¹¶æä¾›åˆ—çº§ç­–ç•¥ï¼‰
                  æ³¨ï¼šmerge ç­–ç•¥éœ€æ˜ç¡®å®šä¹‰å“ªäº›åˆ—å…è®¸åˆå¹¶ï¼Œå¦åˆ™å¯èƒ½å¯¼è‡´æ•°æ®ä¸ä¸€è‡´
                  å¯ç”¨æ–¹å¼ï¼šconflict_strategy='merge', merge_columns=['col1', 'col2']
            
        Returns:
            å†™å…¥çš„è¡Œæ•°
            
        Raises:
            WriteError: é‡è¯•è€—å°½åä»å¤±è´¥
        """
        pass
```

### 2. Feature Layer Interface

ç‰¹å¾å±‚å‡½æ•°å·²åœ¨ `alphahome/processors/operations/transforms.py` ä¸­å®ç°ï¼Œæœ¬è®¾è®¡æ–‡æ¡£å®šä¹‰å…¶æ¥å£å¥‘çº¦ï¼š

```python
# æ‰€æœ‰ç‰¹å¾å‡½æ•°å¿…é¡»éµå¾ªçš„æ¥å£å¥‘çº¦

def feature_function(
    data: pd.Series | pd.DataFrame,
    window: int = ...,
    min_periods: int = None,  # é»˜è®¤ç­‰äº window
    **kwargs,
) -> pd.Series | pd.DataFrame:
    """
    ç‰¹å¾å‡½æ•°æ¥å£å¥‘çº¦
    
    çº¦æŸï¼š
    1. ä¸ä¿®æ”¹è¾“å…¥æ•°æ®ï¼ˆimmutableï¼‰
    2. ä¸è®¿é—®å¤–éƒ¨çŠ¶æ€ï¼ˆpure functionï¼‰
    3. è¾“å‡ºç´¢å¼•ä¸è¾“å…¥å¯¹é½ï¼ˆä¸æ”¹å˜æ’åºï¼‰
    4. NaN è¾“å…¥äº§ç”Ÿ NaN è¾“å‡ºï¼ˆNaN preservationï¼‰
    5. é™¤é›¶è¿”å› NaNï¼ˆnot inf, not 0ï¼‰
    6. ä¸è¶³çª—å£è¿”å› NaNï¼ˆnot fill with 0ï¼‰
    7. min_periods é»˜è®¤ç­‰äº window
    8. inf å€¼ç»Ÿä¸€è½¬æ¢ä¸º NaN
    
    è¾“å‡ºåˆ—å‘½åè§„èŒƒï¼š
    - æ ¼å¼ï¼š{base_name}_{window}D_{transform}
    - ç¤ºä¾‹ï¼šRV_20D_Pctl, PE_10Y_ZScore
    - å•ä½/é¢‘åº¦/æ»åæ€§åœ¨ docstring ä¸­è¯´æ˜
    """
    pass
```

#### ç‰¹å¾å…¥åº“ä¸ç‰ˆæœ¬ç®¡ç†

| é…ç½®é¡¹ | è¯´æ˜ |
|--------|------|
| ç‰ˆæœ¬å­—æ®µ | `_feature_version` åˆ—ï¼ˆv1, v2, ...ï¼‰ |
| åˆ†åŒºç­–ç•¥ | æŒ‰ trade_date æœˆåˆ†åŒº |
| å›å¡«è§¦å‘ | æ•°æ®ä¿®æ­£ã€å‚æ•°å˜æ›´ã€ç®—æ³•å‡çº§ |
| é‡ç®—æµç¨‹ | 1) æ–°å»ºç‰ˆæœ¬å· 2) å…¨é‡è®¡ç®— 3) éªŒè¯ 4) åˆ‡æ¢ |
| SLA | æ—¥å¸¸æ›´æ–° T+1 09:00 å‰å®Œæˆ |
| é»˜è®¤æŸ¥è¯¢ç‰ˆæœ¬ | æœ€æ–°ç‰ˆæœ¬ï¼ˆå¯é€šè¿‡å‚æ•°æŒ‡å®šå†å²ç‰ˆæœ¬ï¼‰ |
| æ—§ç‰ˆæœ¬æ¸…ç† | ä¿ç•™æœ€è¿‘ 2 ä¸ªç‰ˆæœ¬ï¼Œè¶…æœŸæ•°æ®æŒ‰æœˆå½’æ¡£åˆ°å†·å­˜å‚¨ |

#### ç‰¹å¾å…ƒæ•°æ®è½ç›˜æ–¹å¼

| å…ƒæ•°æ®ç±»å‹ | è½ç›˜æ–¹å¼ |
|------------|----------|
| å•ä½ | åˆ—æ³¨é‡Šï¼ˆCOMMENT ON COLUMNï¼‰ |
| é¢‘åº¦ | è¡¨ååç¼€ï¼ˆ_daily, _weekly, _monthlyï¼‰æˆ– _freq åˆ— |
| æ»åæ€§ | docstring æ–‡æ¡£çº¦å®š |
| çª—å£å‚æ•° | åˆ—ååŒ…å«ï¼ˆå¦‚ _20D, _252Dï¼‰ |

*æ³¨ï¼šéæ—¥é¢‘ç‰¹å¾ï¼ˆå‘¨/æœˆ/åˆ†é’Ÿï¼‰éœ€åœ¨è¡¨åæˆ– _freq åˆ—ä¸­æ˜ç¡®æ ‡æ³¨ã€‚ä¼˜å…ˆä½¿ç”¨è¡¨ååç¼€ï¼Œ_freq åˆ—ä½œä¸ºè¡¥å……ã€‚*

### 3. Task Layer Enhancement

æ‰©å±•ç°æœ‰ `ProcessorTaskBase` ä»¥æ”¯æŒåˆ†å±‚æ¶æ„ï¼š

```python
class ProcessorTaskBase(BaseTask, ABC):
    """å¤„ç†ä»»åŠ¡åŸºç±»ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    
    # ç°æœ‰å±æ€§
    task_type: str = "processor"
    source_tables: List[str] = []
    table_name: str = ""
    primary_keys: List[str] = ["trade_date"]
    
    # æ–°å¢å±æ€§
    clean_table: str = ""  # clean schema ç›®æ ‡è¡¨
    feature_dependencies: List[str] = []  # ä¾èµ–çš„ç‰¹å¾å‡½æ•°
    skip_features: bool = False  # æ˜¯å¦è·³è¿‡ç‰¹å¾è®¡ç®—
    
    async def run(self, **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œä»»åŠ¡ï¼ˆå¢å¼ºç‰ˆæµç¨‹ï¼‰
        
        æµç¨‹ï¼šfetch â†’ clean â†’ feature (optional) â†’ save
        
        ä¿å­˜ç›®æ ‡ï¼š
        - skip_features=True: ä¿å­˜åˆ° clean_tableï¼ˆå¤„ç†å±‚ï¼‰
        - skip_features=False: ä¿å­˜åˆ° table_nameï¼ˆç‰¹å¾å±‚ï¼‰
        """
        # 1. è·å–æ•°æ®
        raw_data = await self.fetch_data(**kwargs)
        
        # 2. æ¸…æ´—æ•°æ®ï¼ˆæ–°å¢ï¼‰
        clean_data = await self.clean_data(raw_data, **kwargs)
        
        # 3. ä¿å­˜ clean æ•°æ®ï¼ˆå¦‚æœé…ç½®äº† clean_tableï¼‰
        if self.clean_table:
            await self._save_to_clean(clean_data, **kwargs)
        
        # 4. è®¡ç®—ç‰¹å¾ï¼ˆå¯é€‰ï¼‰
        if not self.skip_features:
            result = await self.compute_features(clean_data, **kwargs)
            # 5. ä¿å­˜ç‰¹å¾ç»“æœ
            await self.save_result(result, **kwargs)
        else:
            result = clean_data
        
        return {"status": "success", "rows": len(result)}
    
    async def clean_data(self, data: pd.DataFrame, **kwargs) -> pd.DataFrame:
        """
        æ¸…æ´—æ•°æ®ï¼ˆæ–°å¢æ–¹æ³•ï¼‰
        
        é»˜è®¤å®ç°ç»„åˆä»¥ä¸‹ç»„ä»¶ï¼š
        1. DataValidator.validate() - æ ¡éªŒ
        2. DataAligner.align_date() + align_identifier() - å¯¹é½ï¼ˆbest-effortï¼‰
        3. DataStandardizer.convert_*() - æ ‡å‡†åŒ–ï¼ˆbest-effortï¼‰
        4. LineageTracker.add_lineage() - æ·»åŠ è¡€ç¼˜
        
        **å¼‚å¸¸è¯­ä¹‰**ï¼š
        å¯¹é½å’Œæ ‡å‡†åŒ–é‡‡ç”¨ best-effort ç­–ç•¥ï¼š
        - é‡åˆ°æœªçŸ¥æ ¼å¼/å•ä½æˆ–éƒ¨åˆ†åˆ—ç¼ºå¤±æ—¶è®°å½• warning
        - å°½é‡å®Œæˆå¯å¤„ç†çš„éƒ¨åˆ†
        - ä¸æŠ›å‡ºè‡´å‘½å¼‚å¸¸ï¼ˆé™¤éæ˜¾å¼é…ç½® strict æ¨¡å¼ï¼‰
        
        å­ç±»å¯è¦†ç›–ä»¥è‡ªå®šä¹‰æ¸…æ´—é€»è¾‘
        """
        pass
    
    async def _save_to_clean(self, data: pd.DataFrame, **kwargs) -> int:
        """
        ä¿å­˜æ•°æ®åˆ° clean schema è¡¨
        
        **é‡è¦æç¤º**ï¼š
        å½“å‰å®ç°ä»…ä¸ºå ä½ç¬¦ï¼ˆè®¡æ•°+æ—¥å¿—ï¼‰ï¼Œä¸æ‰§è¡ŒçœŸæ­£çš„æ•°æ®åº“å†™å…¥ã€‚
        
        **ç”Ÿäº§ç¯å¢ƒä½¿ç”¨è¦æ±‚**ï¼š
        å­ç±»å¿…é¡»è¦†ç›–æ­¤æ–¹æ³•ä»¥å®ç°çœŸæ­£çš„æ•°æ®åº“å†™å…¥é€»è¾‘ï¼Œæ¨èæ–¹æ¡ˆï¼š
        1. å¼•å…¥ CleanLayerWriter é€‚é… DBManager
        2. ä» clean_table è§£æ schema/table åç§°
        3. è°ƒç”¨ writer.upsert() æ‰§è¡Œå¹‚ç­‰å†™å…¥
        
        **ä¸­é•¿æœŸæ”¹è¿›æ–¹å‘**ï¼š
        æä¾›åŸºäº CleanLayerWriter + DBManager çš„é»˜è®¤å®ç°
        
        Returns:
            int: ä¿å­˜çš„è¡Œæ•°ï¼ˆå½“å‰ä»…è¿”å›è®¡æ•°ï¼Œæœªå®é™…å†™å…¥ï¼‰
        """
        pass
    
    async def compute_features(self, data: pd.DataFrame, **kwargs) -> pd.DataFrame:
        """
        è®¡ç®—ç‰¹å¾ï¼ˆæ–°å¢æ–¹æ³•ï¼‰
        
        å­ç±»å®ç°ï¼Œè°ƒç”¨ operations/transforms.py ä¸­çš„å‡½æ•°
        
        çº¦æŸï¼š
        - å¿…é¡»é€šè¿‡ feature_dependencies å£°æ˜ä¾èµ–çš„ç‰¹å¾å‡½æ•°
        - ä¸å¾—å†…åµŒç‰¹å¾è®¡ç®—é€»è¾‘
        """
        return data  # é»˜è®¤ä¸è®¡ç®—ç‰¹å¾
    
    def _validate_feature_dependencies(self):
        """æ ¡éªŒ feature_dependencies ä¸­çš„å‡½æ•°æ˜¯å¦å­˜åœ¨äº operations æ¨¡å—"""
        from ..operations import transforms
        for dep in self.feature_dependencies:
            if not hasattr(transforms, dep):
                raise ValueError(f"Unknown feature dependency: {dep}")
```

#### Task Layer å®ç°çŠ¶æ€

| ç»„ä»¶ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| `run()` æµç¨‹ | âœ… å·²å®ç° | fetch â†’ clean â†’ feature â†’ save |
| `clean_data()` | âœ… å·²å®ç° | ç»„åˆ Clean Layer ç»„ä»¶ï¼Œbest-effort ç­–ç•¥ |
| `_save_to_clean()` | âš ï¸ å ä½å®ç° | ä»…è®¡æ•°+æ—¥å¿—ï¼Œç”Ÿäº§ç¯å¢ƒéœ€è¦†ç›– |
| `compute_features()` | âœ… å·²å®ç° | é»˜è®¤ä¸è®¡ç®—ï¼Œå­ç±»è¦†ç›– |
| `_validate_feature_dependencies()` | âœ… å·²å®ç° | æ ¡éªŒç‰¹å¾å‡½æ•°å­˜åœ¨æ€§ |

## Data Models

### 1. Clean Schema Table Structure

æ‰€æœ‰ clean è¡¨å…±äº«çš„åŸºç¡€ç»“æ„ï¼š

| Column | Type | Description | Required |
|--------|------|-------------|----------|
| trade_date | INTEGER/DATETIME | äº¤æ˜“æ—¥æœŸï¼ˆä¸»é”®ï¼‰ | Yes |
| ts_code | VARCHAR(20) | æ ‡çš„ä»£ç ï¼ˆä¸»é”®ï¼Œè‚¡ç¥¨çº§è¡¨ï¼‰ | Conditional |
| _source_table | VARCHAR(255) | æºè¡¨å | Yes |
| _processed_at | TIMESTAMP | å¤„ç†æ—¶é—´ï¼ˆUTCï¼‰ | Yes |
| _data_version | VARCHAR(50) | æ•°æ®ç‰ˆæœ¬ | Yes |
| _ingest_job_id | VARCHAR(100) | ä»»åŠ¡æ‰§è¡ŒID | Yes |
| _validation_flag | INTEGER | æ ¡éªŒæ ‡è®°ï¼ˆ0=æ­£å¸¸ï¼‰ | Optional |

### 2. Clean Table Definitions

*æ³¨ï¼šä»¥ä¸‹ä¸ºæ ¸å¿ƒè¡¨ç¤ºä¾‹ï¼Œå®Œæ•´è¡¨å®šä¹‰è¯¦è§ä»»åŠ¡åˆ†ç±»è¡¨ã€‚*

#### clean.index_valuation_base

| Column | Type | Nullable | Unit | Description |
|--------|------|----------|------|-------------|
| trade_date | INTEGER | No | YYYYMMDD | äº¤æ˜“æ—¥æœŸï¼ˆPKï¼‰ |
| ts_code | VARCHAR(20) | No | - | æŒ‡æ•°ä»£ç ï¼ˆPKï¼‰ |
| pe_ttm | FLOAT | Yes | å€ | å¸‚ç›ˆç‡TTM |
| pb | FLOAT | Yes | å€ | å¸‚å‡€ç‡ |
| _source_table | VARCHAR(255) | No | - | æºè¡¨å |
| _processed_at | TIMESTAMP | No | UTC | å¤„ç†æ—¶é—´ |
| _data_version | VARCHAR(50) | No | - | æ•°æ®ç‰ˆæœ¬ |
| _ingest_job_id | VARCHAR(100) | No | - | ä»»åŠ¡æ‰§è¡ŒID |

**ä¸»é”®**: (trade_date, ts_code)  
**åˆ†åŒº**: æŒ‰ trade_date æœˆåˆ†åŒº  
**ç´¢å¼•**: ts_code

#### clean.index_volatility_base

| Column | Type | Nullable | Unit | Description |
|--------|------|----------|------|-------------|
| trade_date | INTEGER | No | YYYYMMDD | äº¤æ˜“æ—¥æœŸï¼ˆPKï¼‰ |
| ts_code | VARCHAR(20) | No | - | æŒ‡æ•°ä»£ç ï¼ˆPKï¼‰ |
| close | FLOAT | Yes | å…ƒ | æ”¶ç›˜ä»·ï¼ˆå¤æƒï¼‰ |
| close_unadj | FLOAT | Yes | å…ƒ | æœªå¤æƒæ”¶ç›˜ä»· |
| _adj_method | VARCHAR(20) | Yes | - | å¤æƒæ–¹å¼ |

**ä¸»é”®**: (trade_date, ts_code)

#### clean.industry_base

| Column | Type | Nullable | Unit | Description |
|--------|------|----------|------|-------------|
| trade_date | INTEGER | No | YYYYMMDD | äº¤æ˜“æ—¥æœŸï¼ˆPKï¼‰ |
| ts_code | VARCHAR(20) | No | - | è¡Œä¸šä»£ç ï¼ˆPKï¼‰ |
| close | FLOAT | Yes | ç‚¹ | è¡Œä¸šæŒ‡æ•°æ”¶ç›˜ä»· |

**ä¸»é”®**: (trade_date, ts_code)

#### å…¶ä»– Clean è¡¨ï¼ˆç®€è¦å®šä¹‰ï¼‰

*æ³¨ï¼šä»¥ä¸‹è¡¨éœ€åŒ…å«æ ‡å‡†è¡€ç¼˜åˆ—ï¼ˆ_source_table, _processed_at, _data_version, _ingest_job_idï¼‰*

| è¡¨å | ä¸»é”® | æ ¸å¿ƒåˆ— | è¯´æ˜ |
|------|------|--------|------|
| clean.futures_base | trade_date, ts_code | close, settle, oi | æœŸè´§åŸºç¡€æ•°æ® |
| clean.option_iv_base | trade_date, ts_code | iv, delta, gamma | æœŸæƒéšå«æ³¢åŠ¨ç‡ |
| clean.style_base | trade_date, ts_code | close | é£æ ¼æŒ‡æ•°åŸºç¡€æ•°æ® |

*æ‰©å±•è¯´æ˜ï¼šå…¶ä½™ clean è¡¨éœ€éµå¾ª"åŸºç¡€ç»“æ„ï¼ˆtrade_date/ä¸»é”®ï¼‰+ ä¸šåŠ¡åˆ— + è¡€ç¼˜åˆ—"çš„æ¨¡å¼ã€‚*

#### clean.money_flow_base

| Column | Type | Nullable | Unit | Description |
|--------|------|----------|------|-------------|
| trade_date | INTEGER | No | YYYYMMDD | äº¤æ˜“æ—¥æœŸï¼ˆPKï¼‰ |
| total_net_mf_amount | FLOAT | Yes | å…ƒ | ä¸»åŠ›å‡€æµå…¥é‡‘é¢ |
| total_circ_mv | FLOAT | Yes | å…ƒ | æµé€šå¸‚å€¼ |

**ä¸»é”®**: (trade_date)

#### clean.market_technical_base

| Column | Type | Nullable | Unit | Description |
|--------|------|----------|------|-------------|
| trade_date | INTEGER | No | YYYYMMDD | äº¤æ˜“æ—¥æœŸï¼ˆPKï¼‰ |
| ts_code | VARCHAR(20) | No | - | è‚¡ç¥¨ä»£ç ï¼ˆPKï¼‰ |
| close | FLOAT | Yes | å…ƒ | æ”¶ç›˜ä»· |
| vol | FLOAT | Yes | è‚¡ | æˆäº¤é‡ |
| turnover_rate | FLOAT | Yes | % | æ¢æ‰‹ç‡ |

**ä¸»é”®**: (trade_date, ts_code)

### 3. Task Classification Table

| ä»»åŠ¡ | è¾“å…¥è¡¨ | è¾“å‡ºè¡¨ | ä¸»é”® | æ—¶é—´åˆ— | ç‰¹å¾åˆ— | åˆ†ç±» | ç›®æ ‡ clean è¡¨ | å¾…æå–ç‰¹å¾å‡½æ•° |
|------|--------|--------|------|--------|--------|------|---------------|----------------|
| index_valuation | tushare.index_dailybasic, akshare.macro_bond_rate | processor_index_valuation | trade_date | trade_date | *_Pctl_10Y, *_Pctl_12M, *_ERP | æ··åˆéœ€æ‹†åˆ† | clean.index_valuation_base | rolling_percentile |
| index_volatility | tushare.index_factor_pro | processor_index_volatility | trade_date | trade_date | *_RV_*, *_Pctl, *_Ratio | æ··åˆéœ€æ‹†åˆ† | clean.index_volatility_base | rolling_percentile |
| industry_return | tushare.index_swdaily | processor_industry_return | trade_date | trade_date | SW_* (pct_change) | å¤„ç†å±‚ä¿ç•™ | clean.industry_base | - |
| industry_breadth | tushare.index_swdaily | processor_industry_breadth | trade_date | trade_date | *_Ratio, *_Std, *_Skew, *_5D | ç‰¹å¾ä¸‹æ²‰ | clean.industry_base | rolling mean |
| market_money_flow | tushare.stock_moneyflow, stock_dailybasic | processor_market_money_flow | trade_date | trade_date | *_ZScore, *_Pctl | æ··åˆéœ€æ‹†åˆ† | clean.money_flow_base | rolling_zscore, rolling_percentile |
| market_technical | tushare.stock_factor_pro | processor_market_technical | trade_date | trade_date | *_ZScore, *_Pctl | æ··åˆéœ€æ‹†åˆ† | clean.market_technical_base | rolling_zscore, rolling_percentile |
| style_index | - | processor_style_index | trade_date | trade_date | å¤šå‘¨æœŸæ”¶ç›Š | ç‰¹å¾ä¸‹æ²‰ | - | diff_pct |
| futures | tushare.fut_* | processor_futures | trade_date | trade_date | åŸºå·®åˆ†ä½ | æ··åˆéœ€æ‹†åˆ† | clean.futures_base | rolling_percentile |
| option_iv | - | processor_option_iv | trade_date | trade_date | IVæœŸé™ç»“æ„ | æ··åˆéœ€æ‹†åˆ† | clean.option_iv_base | - |



## Correctness Properties

*A property is a characteristic or behavior that should hold true across all valid executions of a system-essentially, a formal statement about what the system should do. Properties serve as the bridge between human-readable specifications and machine-verifiable correctness guarantees.*

### Property 1: Column type validation
*For any* DataFrame with columns that don't match the expected schema types, the DataValidator SHALL identify all type mismatches and return them in the validation result.
**Validates: Requirements 1.1**

### Property 2: Missing column detection
*For any* DataFrame missing required columns, the DataValidator SHALL raise an exception containing the complete list of missing column names.
**Validates: Requirements 1.2**

### Property 3: Duplicate key deduplication
*For any* DataFrame with duplicate primary keys, the deduplication process SHALL keep exactly one record per key (the latest) and the output length SHALL equal the number of unique keys.
**Validates: Requirements 1.3**

### Property 4: Null value rejection
*For any* DataFrame with null values in required fields, the DataValidator SHALL reject the batch and report all field names containing nulls.
**Validates: Requirements 1.4**

### Property 5: Range validation flagging
*For any* DataFrame with values outside valid ranges, the DataValidator SHALL add a `_validation_flag` column marking the out-of-range records.
**Validates: Requirements 1.5**

### Property 6: Column preservation
*For any* DataFrame processed by the Clean Layer, the output columns SHALL be a superset of input columns (plus lineage columns), with no columns silently dropped or renamed.
**Validates: Requirements 1.6**

### Property 7: Date format standardization
*For any* date value in supported formats (YYYY-MM-DD, YYYYMMDD, datetime), the DataAligner SHALL convert it to the standard trade_date format.
**Validates: Requirements 2.1, 2.4**

### Property 8: Identifier mapping
*For any* security identifier in supported formats (000001, sh600000), the DataAligner SHALL map it to the correct ts_code format (e.g., 000001.SZ).
**Validates: Requirements 2.2, 2.5**

### Property 9: Primary key uniqueness enforcement
*For any* DataFrame written to clean schema, the CleanLayerWriter SHALL enforce primary key uniqueness via UPSERT, with no duplicate keys in the final table.
**Validates: Requirements 2.6, 5.1**

### Property 10: Unit conversion correctness
*For any* monetary value in ä¸‡å…ƒ or äº¿å…ƒ, the DataStandardizer SHALL convert to å…ƒ using the correct conversion factor. *For any* volume in æ‰‹, the DataStandardizer SHALL convert to è‚¡.
**Validates: Requirements 3.1, 3.2, 3.5**

### Property 11: Unadjusted price preservation
*For any* price column that undergoes adjustment, the DataStandardizer SHALL preserve the original value in a column with `_unadj` suffix.
**Validates: Requirements 3.4**

### Property 12: Lineage metadata completeness
*For any* DataFrame processed by the Clean Layer, the output SHALL contain all lineage columns (_source_table, _processed_at, _data_version, _ingest_job_id) with non-null values.
**Validates: Requirements 4.1, 4.2, 4.3, 4.4, 4.5**

### Property 13: Feature function immutability
*For any* feature function call, the input DataFrame SHALL remain unchanged after the function returns.
**Validates: Requirements 6.1, 6.3**

### Property 14: Index alignment preservation
*For any* feature function call, the output index SHALL exactly match the input index.
**Validates: Requirements 6.4**

### Property 15: NaN preservation
*For any* input Series with NaN values, feature functions SHALL preserve NaN at the same positions in the output (NaN in â†’ NaN out).
**Validates: Requirements 6.5**

### Property 16: Division by zero handling
*For any* feature function that involves division, when the divisor is zero, the function SHALL return NaN (not infinity, not zero).
**Validates: Requirements 6.6**

### Property 17: min_periods default behavior
*For any* rolling feature function called without explicit min_periods, the function SHALL use window size as the default min_periods.
**Validates: Requirements 6.7**

### Property 18: Insufficient window NaN handling
*For any* rolling calculation with fewer than min_periods observations, the function SHALL return NaN (not fill with 0 or other values).
**Validates: Requirements 6.8**

## Error Handling

### 1. Validation Errors

```python
class ValidationError(Exception):
    """æ•°æ®æ ¡éªŒé”™è¯¯"""
    def __init__(self, message: str, details: ValidationResult):
        super().__init__(message)
        self.details = details

# ä½¿ç”¨ç¤ºä¾‹
try:
    result = validator.validate(df)
    if not result.is_valid:
        if result.missing_columns:
            raise ValidationError(
                f"Missing required columns: {result.missing_columns}",
                result
            )
        if result.null_fields:
            raise ValidationError(
                f"Null values in required fields: {result.null_fields}",
                result
            )
except ValidationError as e:
    logger.error(f"Validation failed: {e.details}")
    raise
```

### 2. Write Errors

```python
class WriteError(Exception):
    """æ•°æ®å†™å…¥é”™è¯¯"""
    pass

async def upsert_with_retry(self, df, table_name, primary_keys):
    for attempt in range(self.max_retries):
        try:
            async with self.db.transaction():
                return await self._do_upsert(df, table_name, primary_keys)
        except Exception as e:
            if attempt == self.max_retries - 1:
                raise WriteError(f"Failed after {self.max_retries} attempts: {e}")
            logger.warning(f"Write attempt {attempt + 1} failed, retrying...")
            await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
```

### 3. Feature Calculation Errors

ç‰¹å¾å‡½æ•°ä¸åº”æŠ›å‡ºå¼‚å¸¸ï¼Œè€Œæ˜¯è¿”å› NaNï¼š

```python
def safe_divide(numerator: pd.Series, denominator: pd.Series) -> pd.Series:
    """å®‰å…¨é™¤æ³•ï¼Œé™¤é›¶è¿”å› NaN"""
    with np.errstate(divide='ignore', invalid='ignore'):
        result = numerator / denominator
        result = result.replace([np.inf, -np.inf], np.nan)
    return result
```

## Testing Strategy

### Unit Testing

ä½¿ç”¨ pytest è¿›è¡Œå•å…ƒæµ‹è¯•ï¼š

- æµ‹è¯• DataValidator çš„å„ç§æ ¡éªŒåœºæ™¯
- æµ‹è¯• DataAligner çš„æ ¼å¼è½¬æ¢
- æµ‹è¯• DataStandardizer çš„å•ä½è½¬æ¢
- æµ‹è¯• LineageTracker çš„å…ƒæ•°æ®æ·»åŠ 
- æµ‹è¯• CleanLayerWriter çš„ UPSERT è¡Œä¸º

### Property-Based Testing

ä½¿ç”¨ **hypothesis** åº“è¿›è¡Œå±æ€§æµ‹è¯•ï¼ŒéªŒè¯è®¾è®¡æ–‡æ¡£ä¸­å®šä¹‰çš„æ­£ç¡®æ€§å±æ€§ï¼š

```python
from hypothesis import given, strategies as st
import hypothesis.extra.pandas as pdst

@given(pdst.data_frames([
    pdst.column('trade_date', dtype=int),
    pdst.column('ts_code', dtype=str),
    pdst.column('value', dtype=float),
]))
def test_column_preservation(df):
    """
    **Feature: processors-data-layering, Property 6: Column preservation**
    **Validates: Requirements 1.6**
    """
    original_cols = set(df.columns)
    result = clean_layer.process(df)
    result_cols = set(result.columns)
    
    # è¾“å‡ºåˆ—åº”åŒ…å«æ‰€æœ‰è¾“å…¥åˆ—
    assert original_cols.issubset(result_cols)
    # æ–°å¢çš„åªèƒ½æ˜¯è¡€ç¼˜åˆ—
    new_cols = result_cols - original_cols
    assert new_cols.issubset({'_source_table', '_processed_at', '_data_version', '_ingest_job_id', '_validation_flag'})


@given(st.floats(allow_nan=False, allow_infinity=False))
def test_unit_conversion_correctness(value):
    """
    **Feature: processors-data-layering, Property 10: Unit conversion correctness**
    **Validates: Requirements 3.1, 3.2, 3.5**
    """
    # ä¸‡å…ƒ â†’ å…ƒ
    result = standardizer.convert_monetary(pd.Series([value]), 'amount', 'ä¸‡å…ƒ')
    assert result.iloc[0] == value * 10000
    
    # äº¿å…ƒ â†’ å…ƒ
    result = standardizer.convert_monetary(pd.Series([value]), 'amount', 'äº¿å…ƒ')
    assert result.iloc[0] == value * 100000000


@given(pdst.series(dtype=float, min_size=1))
def test_feature_immutability(series):
    """
    **Feature: processors-data-layering, Property 13: Feature function immutability**
    **Validates: Requirements 6.1, 6.3**
    """
    original = series.copy()
    _ = rolling_zscore(series, window=5)
    pd.testing.assert_series_equal(series, original)


@given(pdst.series(dtype=float, min_size=10))
def test_index_alignment(series):
    """
    **Feature: processors-data-layering, Property 14: Index alignment preservation**
    **Validates: Requirements 6.4**
    """
    result = rolling_percentile(series, window=5)
    pd.testing.assert_index_equal(result.index, series.index)
```

### Test Organization

```
alphahome/processors/tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conftest.py
â”œâ”€â”€ test_clean_layer/
â”‚   â”œâ”€â”€ test_validator.py          # Property 1-5
â”‚   â”œâ”€â”€ test_aligner.py            # Property 7-9
â”‚   â”œâ”€â”€ test_standardizer.py       # Property 10-11
â”‚   â”œâ”€â”€ test_lineage.py            # Property 12
â”‚   â””â”€â”€ test_writer.py             # Property 6, 9
â”œâ”€â”€ test_feature_layer/
â”‚   â”œâ”€â”€ test_transforms_properties.py  # Property 13-18
â”‚   â””â”€â”€ test_transforms_unit.py        # å•å…ƒæµ‹è¯•
â””â”€â”€ test_task_layer/
    â”œâ”€â”€ test_task_base.py
    â””â”€â”€ test_task_classification.py
```

### Property Test Coverage Matrix

| Property | æµ‹è¯•æ–‡ä»¶ | æµ‹è¯•å‡½æ•° |
|----------|----------|----------|
| 1. Column type validation | test_validator.py | test_column_type_validation |
| 2. Missing column detection | test_validator.py | test_missing_column_detection |
| 3. Duplicate key deduplication | test_validator.py | test_duplicate_deduplication |
| 4. Null value rejection | test_validator.py | test_null_value_rejection |
| 5. Range validation flagging | test_validator.py | test_range_validation_flagging |
| 6. Column preservation | test_writer.py | test_column_preservation |
| 7. Date format standardization | test_aligner.py | test_date_format_standardization |
| 8. Identifier mapping | test_aligner.py | test_identifier_mapping |
| 9. Primary key uniqueness | test_aligner.py, test_writer.py | test_primary_key_uniqueness |
| 10. Unit conversion | test_standardizer.py | test_unit_conversion_correctness |
| 11. Unadjusted price preservation | test_standardizer.py | test_unadjusted_preservation |
| 12. Lineage metadata | test_lineage.py | test_lineage_metadata_completeness |
| 13. Feature immutability | test_transforms_properties.py | test_feature_immutability |
| 14. Index alignment | test_transforms_properties.py | test_index_alignment |
| 15. NaN preservation | test_transforms_properties.py | test_nan_preservation |
| 16. Division by zero | test_transforms_properties.py | test_division_by_zero |
| 17. min_periods default | test_transforms_properties.py | test_min_periods_default |
| 18. Insufficient window NaN | test_transforms_properties.py | test_insufficient_window_nan |

### Property Test Annotations

æ¯ä¸ªå±æ€§æµ‹è¯•å¿…é¡»æ ‡æ³¨å¯¹åº”çš„è®¾è®¡æ–‡æ¡£å±æ€§ï¼š

```python
def test_duplicate_deduplication():
    """
    **Feature: processors-data-layering, Property 3: Duplicate key deduplication**
    **Validates: Requirements 1.3**
    """
    # test implementation
```

## Migration Plan

### Phase 1: åŸºç¡€è®¾æ–½å»ºç«‹

1. åˆ›å»º clean schema
2. å®ç° DataValidator, DataAligner, DataStandardizer, LineageTracker
3. å®ç° CleanLayerWriter
4. ç¼–å†™å±æ€§æµ‹è¯•

### Phase 2: ä»»åŠ¡è¿ç§»

æŒ‰ä¼˜å…ˆçº§è¿ç§»ç°æœ‰ä»»åŠ¡ï¼š

| ä¼˜å…ˆçº§ | ä»»åŠ¡ | ç›®æ ‡ clean è¡¨ | å®Œæˆæ ‡å‡† |
|--------|------|---------------|----------|
| é«˜ | index_valuation | clean.index_valuation_base | clean è¡¨åˆ›å»º + æ•°æ®è¿ç§» + æµ‹è¯•é€šè¿‡ |
| é«˜ | index_volatility | clean.index_volatility_base | clean è¡¨åˆ›å»º + æ•°æ®è¿ç§» + æµ‹è¯•é€šè¿‡ |
| ä¸­ | industry_return | clean.industry_base | clean è¡¨åˆ›å»º + æ•°æ®è¿ç§» + æµ‹è¯•é€šè¿‡ |
| ä¸­ | market_money_flow | clean.money_flow_base | clean è¡¨åˆ›å»º + æ•°æ®è¿ç§» + æµ‹è¯•é€šè¿‡ |
| ä½ | style_index | - | ç‰¹å¾ä¸‹æ²‰ + æµ‹è¯•é€šè¿‡ |
| ä½ | futures | clean.futures_base | clean è¡¨åˆ›å»º + ç‰¹å¾ä¸‹æ²‰ + æµ‹è¯•é€šè¿‡ |
| ä½ | option_iv | clean.option_iv_base | clean è¡¨åˆ›å»º + ç‰¹å¾ä¸‹æ²‰ + æµ‹è¯•é€šè¿‡ |

**"æ··åˆéœ€æ‹†åˆ†"ä»»åŠ¡çš„è¿ç§»æµç¨‹ï¼š**
1. åˆ›å»º clean_base è¡¨
2. å®ç° clean_data() æ–¹æ³•ï¼Œè¾“å‡ºåˆ° clean_base
3. å°†ç‰¹å¾è®¡ç®—é€»è¾‘æå–åˆ° operations/transforms.py
4. æ›´æ–° compute_features() è°ƒç”¨æå–çš„å‡½æ•°
5. éªŒè¯è¾“å‡ºä¸åŸä»»åŠ¡ä¸€è‡´

### Phase 3: ç‰¹å¾ä¸‹æ²‰

1. å°†ä»»åŠ¡ä¸­çš„ç‰¹å¾è®¡ç®—é€»è¾‘æå–åˆ° operations/transforms.py
2. ä»»åŠ¡ä»…è°ƒç”¨ç‰¹å¾å‡½æ•°ï¼Œä¸å†…åµŒè®¡ç®—é€»è¾‘
3. æ›´æ–°ä»»åŠ¡çš„ feature_dependencies å±æ€§
4. éªŒè¯ç‰¹å¾è¾“å‡ºä¸åŸå®ç°ä¸€è‡´

### å¢é‡æ›´æ–°è¾¹ç•Œå¤„ç†çº¦å®š

åœ¨ä»»åŠ¡å±‚å¢é‡è®¡ç®—æ—¶ï¼Œå¿…é¡»éµå¾ªä»¥ä¸‹çº¦å®šï¼š

```python
# å¢é‡æ›´æ–°æ—¶çš„å›æº¯çª—å£è®¡ç®—
lookback_days = max(
    feature_func.window for feature_func in self.feature_dependencies
)
actual_start_date = requested_start_date - timedelta(days=lookback_days)
```

è¿™ç¡®ä¿æ»šåŠ¨çª—å£ç‰¹å¾åœ¨è¾¹ç•Œå¤„ä¸ä¼šå¤±çœŸã€‚

## Open Questions

| é—®é¢˜ | å»ºè®®æ–¹å‘ | å¾…å†³ç­–äºº | ç›®æ ‡æ—¶é—´ |
|------|----------|----------|----------|
| è¡€ç¼˜å…ƒæ•°æ®çš„æŸ¥è¯¢æ¥å£ | æš‚ä¸æä¾› APIï¼Œé€šè¿‡ SQL ç›´æ¥æŸ¥è¯¢ _source_table ç­‰å­—æ®µ | Tech Lead | Phase 1 |
| ç‰¹å¾ç‰ˆæœ¬ç®¡ç† | ä½¿ç”¨ _feature_version åˆ— + åˆ†åŒºç­–ç•¥ï¼Œä¿ç•™æœ€è¿‘ 2 ä¸ªç‰ˆæœ¬ | Tech Lead | Phase 2 |
| å¢é‡æ›´æ–°çš„è¾¹ç•Œå¤„ç† | å›æº¯ max(window) å¤©æ•°æ®é‡ç®—ï¼Œç¡®ä¿çª—å£å®Œæ•´ï¼ˆå›ºåŒ–åˆ°ä»»åŠ¡å±‚çº¦å®šï¼‰ | Data Engineer | Phase 2 |
| clean schema çš„æƒé™ç®¡ç† | ç”Ÿäº§é™åˆ¶ç›´æ¥å†™å…¥ï¼›dev/staging å…è®¸å†™å…¥ä½†éœ€å®¡è®¡æ—¥å¿— | DevOps | Phase 3 |
